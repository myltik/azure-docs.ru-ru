---
title: Обзор функций пакетной службы Azure для разработчиков | Документация Майкрософт
description: Ознакомьтесь с функциями пакетной службы и ее API-интерфейсов с точки зрения разработки.
services: batch
documentationcenter: .net
author: dlepow
manager: jeconnoc
editor: ''
ms.assetid: 416b95f8-2d7b-4111-8012-679b0f60d204
ms.service: batch
ms.devlang: multiple
ms.topic: get-started-article
ms.tgt_pltfrm: na
ms.workload: big-compute
ms.date: 04/06/2018
ms.author: danlep
ms.custom: H1Hack27Feb2017
ms.openlocfilehash: 1a202efd08de69e6e766c9c42047c01a03be4d96
ms.sourcegitcommit: 1362e3d6961bdeaebed7fb342c7b0b34f6f6417a
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/18/2018
---
# <a name="develop-large-scale-parallel-compute-solutions-with-batch"></a>Разработка решений для крупномасштабных параллельных вычислений с использованием пакетной службы

В этом обзоре рассматриваются основные функции и ресурсы пакетной службы Azure, которые могут использовать разработчики при создании решений для крупномасштабных параллельных вычислительных нагрузок.

Как при разработке распределенного вычислительного приложения или службы, которая отправляет прямые вызовы [REST API][batch_rest_api], так и при использовании одного из [пакетов SDK для пакетной службы](batch-apis-tools.md#azure-accounts-for-batch-development) вам понадобятся многие ресурсы и функции, описанные в этой статье.

> [!TIP]
> Дополнительные сведения о пакетной службе Azure см. в [этой статье](batch-technical-overview.md). Также см. последние [обновления пакетной службы](https://azure.microsoft.com/updates/?product=batch).
>
>

## <a name="batch-service-workflow"></a>Рабочий процесс пакетной службы
Далее приводится обобщенная схема рабочего процесса практически для всех приложений и служб, использующих пакетную службу для обработки параллельных рабочих нагрузок.

1. Отправьте **файлы данных**, которые необходимо обработать, в учетную запись [службы хранилища Azure][azure_storage]. В пакетную службу встроена поддержка доступа к хранилищу BLOB-объектов Azure, и эти файлы могут быть скачаны на [вычислительные узлы](#compute-node) в ходе выполнения задач.
2. Отправьте **файлы приложения**, которые будут выполнять задачи. Это могут быть двоичные файлы или сценарии и их зависимости. Они выполняются с помощью задач в заданиях. Эти файлы можно скачать из учетной записи службы хранения. Либо можно использовать [пакеты приложений](#application-packages) пакетной службы для развертывания приложений и управления ими.
3. Создайте [пул](#pool) вычислительных узлов. При создании пула указывается количество вычислительных узлов, их размер и операционная система. Каждая задача в задании выполняется на одном из узлов в пуле.
4. Создайте [задание](#job). Задание — это набор задач. Каждое задание назначается конкретному пулу, в котором будут выполняться задачи этого задания.
5. Добавьте [задачи](#task) в задание. Каждая задача выполняет приложение или сценарий, загруженные для обработки файлов данных, скачанных из учетной записи службы хранилища. Выходные данные каждой задачи после ее завершения могут быть отправлены в службу хранилища Azure.
6. Отслеживайте ход выполнения заданий и получайте выходные данные задач из службы хранилища Azure.

В следующих разделах рассматриваются эти и другие ресурсы пакетной службы, которые позволяют использовать распределенные вычисления.

> [!NOTE]
> Для использования пакетной службы вам потребуется [учетная запись пакетной службы](#account). Кроме того, большинство решений пакетной службы предполагают наличие связанной [учетной записи службы хранилища Azure][azure_storage] для хранения и извлечения файлов. 
>
>

## <a name="batch-service-resources"></a>Ресурсы пакетной службы
Для всех решений, использующих пакетную службу, требуются такие ресурсы, как учетные записи, вычислительные узлы, пулы, задания и задачи. Другие ресурсы, например расписания заданий и пакеты приложений, являются полезными дополнительными функциями.

* [Учетная запись.](#account)
* [Вычислительный узел.](#compute-node)
* [Пул.](#pool)
* [Задание.](#job)
  * [Расписания заданий](#scheduled-jobs)
* [Задача.](#task)
  * [Задача запуска](#start-task)
  * [Задача диспетчера заданий](#job-manager-task)
  * [Задачи подготовки и завершения заданий.](#job-preparation-and-release-tasks)
  * [Задачи с несколькими экземплярами](#multi-instance-tasks)
  * [Зависимости задачи](#task-dependencies)
* [Пакеты приложений](#application-packages)

## <a name="account"></a>Учетная запись.
Учетная запись Пакетной службы — это уникально идентифицируемая сущность в Пакетной службе. Вся обработка данных привязана к учетной записи пакетной службы.

Вы можете создать учетную запись пакетной службы Azure с помощью [портала](batch-account-create-portal.md) или программными средствами, например с помощью [библиотеки. NET управления пакетной службой](batch-management-dotnet.md). При создании учетной записи можно связать учетную запись хранения Azure для хранения связанных с заданием входных и выходных данных или приложений.

Можно запустить несколько рабочих нагрузок пакетной службы в одной учетной записи пакетной службы. Либо распределить рабочие нагрузки между учетными записями пакетной службы в рамках одной подписки, но в разных регионах Azure.

> [!NOTE]
> При создании учетной записи пакетной службы необходимо выбрать режим по умолчанию — **Пакетная служба**. В нем пулы автоматически выделяются в подписках, управляемых Azure. В альтернативном режиме **Пользовательская подписка**, который больше не рекомендуется использовать в большинстве сценариев, при создании пула виртуальные машины пакетной службы и другие ресурсы создаются непосредственно в подписке пользователя. Чтобы создать учетную запись пакетной службы в режиме пользовательской подписки, необходимо зарегистрировать подписку в пакетной службе Azure и связать учетную запись с Azure Key Vault.
>


## <a name="azure-storage-account"></a>Учетная запись хранения Azure

В большинстве решений пакетной службы для хранения файлов ресурсов и выходных файлов используется служба хранилища Azure. Например, в задачах пакетной службы (включая стандартные задачи, задачи запуска, задачи подготовки и прекращения заданий) обычно указываются файлы ресурсов, которые находятся в учетных записях хранения.

Пакет поддерживает следующие [параметры учетной записи хранения](../storage/common/storage-account-options.md) Azure:

* учетные записи общего назначения версии 2 (GPv2); 
* учетные записи общего назначения версии 1 (GPv1);
* Учетные записи хранения BLOB-объектов

Учетную запись хранения можно связать с вашей учетной записью пакетной службы при ее создании или позднее. При выборе учетной записи хранения учитывайте требования к расходам и производительности. Например, параметры учетной записи хранения GPv2 и учетной записи хранения больших двоичных объектов поддерживают большие [пороговые значения производительности и масштабируемости](https://azure.microsoft.com/blog/announcing-larger-higher-scale-storage-accounts/) по сравнению с GPv1. (Чтобы подать запрос на увеличение размера хранилища, обратитесь в службу поддержки Azure.) Эти параметры учетной записи могут повысить производительность решений пакетной службы, которые содержат большое число параллельных задач чтения или записи для учетной записи хранилища.

## <a name="compute-node"></a>Вычислительный узел.
Вычислительный узел — это виртуальная машина Azure или облачной службы, назначенная для обработки определенной рабочей нагрузки вашего приложения. Размер узла определяет количество ядер ЦП, объем памяти и размер локальной файловой системы, которые выделяются узлу. Вы можете создавать пулы узлов Windows или Linux с помощью облачных служб Azure, образов виртуальных машин из [Azure Marketplace][vm_marketplace] или пользовательских образов, подготовленных вами. Дополнительные сведения см. в разделе [Пул](#pool) ниже.

На узлах может выполняться любой исполняемый файл или скрипт, поддерживаемый его операционной системой: скрипты \*EXE, \*CMD, \*BAT и PowerShell для Windows и двоичные файлы, скрипты оболочки и Python для Linux.

Для всех вычислительных узлов в пакетной службе характерно следующее:

* Стандартная [структура папок](#files-and-directories) и связанные [переменные среды](#environment-settings-for-tasks), на которые могут ссылаться задачи.
* **брандмауэра**, настроенные для управления доступом.
* [Удаленный доступ](#connecting-to-compute-nodes) к узлам Windows (по протоколу RDP) и Linux (по протоколу SSH).

## <a name="pool"></a>пул
Пул — это коллекция узлов, на которых выполняется приложение. Пул может быть создан как вами (вручную), так и пакетной службой (автоматически) при указании выполняемых работ. Вы можете создавать и изменять пулы в соответствии с потребностями ресурсов своего приложения. Пул может использоваться только той учетной записью пакетной службы, в которой он был создан. Учетная запись Пакетной службы может содержать более одного пула.

Пулы пакетной службы Azure основаны на базовой вычислительной платформе Azure. Они удобны для крупномасштабных операций выделения, установки приложений, распространения данных и мониторинга работоспособности. Кроме того, пулы позволяют выполнять [масштабирование](#scaling-compute-resources) — гибкое изменение числа вычислительных узлов в пуле.

Каждому узлу, который добавляется в пул, присваивается уникальное имя и IP-адрес. При удалении узла из пула будут потеряны любые изменения, внесенные в операционную систему или файлы. Имя и IP-адрес удаленного узла освобождаются для использования в других целях. Когда узел покидает пул, он перестает существовать.

При создании пула можно указать следующие атрибуты:

- Операционная система и версия вычислительного узла
- тип вычислительного узла и целевое количество узлов;
- размер вычислительных узлов;
- политика масштабирования;
- политика планирования задач;
- состояние взаимодействия между вычислительными узлами;
- задачи запуска для вычислительных узлов;
- Пакеты приложений
- Конфигурация сети

Каждый из этих параметров описан более подробно в следующих разделах.

> [!IMPORTANT]
> Для учетных записей пакетной службы установлена квота по умолчанию, которая ограничивает количество ядер в учетной записи хранения. Число ядер соответствует количеству вычислительных узлов. Дополнительные сведения о квотах по умолчанию и инструкцию по [увеличению квоты](batch-quota-limit.md#increase-a-quota) см. в статье [Квоты и ограничения пакетной службы Azure](batch-quota-limit.md). Если пул не достигает целевого количества узлов, причиной может быть основная квота.
>


### <a name="compute-node-operating-system-and-version"></a>Операционная система и версия вычислительного узла

При создании пула пакетной службы можно указать конфигурацию виртуальной машины Azure и тип операционной системы, которую вы хотите запустить на каждом вычислительном узле в пуле. В пакетной службе доступны два типа конфигураций:

- **Конфигурация виртуальной машины**, которая указывает, что пул состоит из виртуальных машин Azure. Эти виртуальные машины могут быть созданы из образов Windows или Linux. 

    Создавая пул, основанный на конфигурации виртуальных машин, необходимо указать не только размер узлов и источник образов, которые использовались для их создания, но и **ссылку на образ виртуальной машины** и **номер SKU агента узла** пакетной службы для установки на узлах. Дополнительные сведения об указании этих свойств пула см. в статье [Подготовка вычислительных узлов Linux в пулах пакетной службы Azure](batch-linux-nodes.md). При необходимости можно подключить один или несколько пустых дисков данных к виртуальным машинам в пуле, созданных на основе образов Marketplace, или включить диски данных в пользовательские образы, используемые для создания виртуальных машин.

- **Конфигурация облачных служб**, которая указывает, что пул состоит из узлов облачных служб Azure. Облачные службы предоставляют *только* вычислительные узлы Windows.

    Доступные операционные системы пулов с конфигурацией облачных служб перечислены в статье [Таблица совместимости выпусков гостевых ОС Azure и пакетов SDK](../cloud-services/cloud-services-guestos-update-matrix.md). При создании пула, содержащего узлы облачных служб, необходимо указать размер узла и соответствующее *семейство ОС*. Облачные службы развертываются в Azure быстрее, чем виртуальные машины под управлением Windows. Если вам нужны пулы вычислительных узлов Windows, вы можете обнаружить, что облачные службы предоставляют преимущества производительности с точки зрения времени развертывания.

    * *Семейство ОС* также определяет, какие версии .NET устанавливаются вместе с операционной системой.
    * Вы можете выбрать для узлов *версию ОС*, так же как и для рабочих ролей в облачных службах (см. дополнительные сведения об [облачных службах](../cloud-services/cloud-services-choose-me.md)).
    * Как и для рабочих ролей, мы рекомендуем указывать значение `*` в качестве *версии ОС*. Тогда узлы будут обновляться автоматически, и вам не нужно будет выполнять дополнительные действия при выходе новых версий. Выбор конкретной версии ОС обычно нужен только для гарантии совместимости приложений. Это позволит протестировать обратную совместимость перед установкой обновлений. После успешной проверки вам понадобится обновить *версию ОС* для пула и установить новый образ ОС. Все выполняемые задачи будут при этом прерваны и повторно поставлены в очередь.

При создании пула вам необходимо выбрать соответствующий **nodeAgentSkuId** в зависимости от ОС базового образа вашего VHD. Вы можете получить сопоставление идентификаторов SKU доступных агентов узла с их ссылками на образы на ОС, вызвав операцию [List Supported Node Agent SKUs](https://docs.microsoft.com/rest/api/batchservice/list-supported-node-agent-skus) (Вывод списка поддерживаемых SKU агентов узла).


#### <a name="custom-images-for-virtual-machine-pools"></a>Пользовательские образы для пулов виртуальных машин

Чтобы использовать пользовательский образ, подготовьте его, сделав универсальным. Сведения о подготовке пользовательских образов под управлением Linux на основе виртуальных машин Azure см. в статье [Создание образа виртуальной машины или виртуального жесткого диска](../virtual-machines/linux/capture-image.md). Сведения о подготовке пользовательских образов под управлением Windows на основе виртуальных машин Azure см. в статье [Создание управляемого образа универсальной виртуальной машины в Azure](../virtual-machines/windows/capture-image-resource.md). 

Дополнительные сведения о требованиях и необходимых шагах см. в статье [Использование пользовательского образа для создания пула виртуальных машин](batch-custom-images.md).

#### <a name="container-support-in-virtual-machine-pools"></a>Поддержка контейнера в пулах виртуальных машин

При создании пула конфигурации виртуальной машины с помощью API-интерфейсов пакетной службы можно настроить пул для выполнения задач в контейнерах Docker. Сейчас пул нужно создавать, используя образ, который поддерживает контейнеры Docker. Используйте Windows Server 2016 Datacenter с образами контейнеров из Azure Marketplace или укажите пользовательский образ виртуальной машины, включающий Docker Community или Enterprise Edition и все необходимые драйверы. Параметры пула должны включать [конфигурацию контейнера](/rest/api/batchservice/pool/add#definitions_containerconfiguration), которая копирует образы контейнеров на виртуальные машины при создании пула. Задачи, выполняющиеся в пуле, могут ссылаться на образы контейнеров и параметры выполнения контейнера.

См. дополнительные сведения о [выполнении контейнерных приложений Docker в пакетной службе Azure](batch-docker-container-workloads.md).

## <a name="compute-node-type-and-target-number-of-nodes"></a>Тип вычислительного узла и целевое количество узлов

При создании пула можно указать нужные типы вычислительных узлов, а также целевое количество узлов. Ниже приведены два типа вычислительных узлов.

- **Выделенные вычислительные узлы.** Выделенные вычислительные узлы зарезервированы для рабочих нагрузок. Они более затратные, чем низкоприоритетные узлы, но они никогда не замещаются.

- **Низкоприоритетные вычислительные узлы.** Низкоприоритетные узлы используют избыточные ресурсы в Azure для выполнения рабочих нагрузок пакетной службы. Они экономичнее (дешевле в час) по сравнению с выделенными узлами и выполняют рабочие нагрузки, требующие большого объема вычислительной мощности. Дополнительные сведения см. в статье [Использование низкоприоритетных виртуальных машин в пакетной службе (предварительная версия)](batch-low-pri-vms.md).

    При недостаточном количестве избыточных ресурсов в Azure низкоприоритетные вычислительные узлы замещаются. Если при выполнении задач узел замещается, задачи помещаются в очередь и перезапускаются, как только он снова станет доступным. Низкоприоритетные узлы — это оптимальный вариант для рабочих нагрузок, где время завершения задания гибкое, а работа распределяется по нескольким узлам. Прежде чем использовать низкоприоритетные узлы для своего сценария, убедитесь, что любые потери работы из-за замещения будут минимальны и легко воссоздаваемы.

    
Низкоприоритетные и выделенные вычислительные узлы могут находиться в одном и том же пуле. Каждый тип узла &mdash; с низким приоритетом и выделенный &mdash; содержит свой собственный целевой объект, для которого можно указать необходимое количество узлов. 
    
Оно называется *целевым*, так как в некоторых случаях пул не может достигнуть требуемого числа узлов. Например, это может произойти из-за достижения [квоты на ядра](batch-quota-limit.md) для учетной записи пакетной службы или если примененная к пулу формула автоматического масштабирования ограничивает максимальное количество узлов.

Дополнительные сведения о ценах на низкоприоритетные и выделенные вычислительные узлы см. на странице [цен на пакетную службу](https://azure.microsoft.com/pricing/details/batch/).

### <a name="size-of-the-compute-nodes"></a>Размер вычислительных узлов

При создании пула пакетной службы Azure вы можете использовать любые семейства и размеры виртуальной машины, доступные в Azure. Azure предлагает диапазон размеров виртуальных машин для разных рабочих нагрузок, включая специализированные размеры [HPC](../virtual-machines/linux/sizes-hpc.md) или [с поддержкой GPU](../virtual-machines/linux/sizes-gpu.md). 

Дополнительные сведения см. в статье [Выбор размера виртуальной машины для вычислительных узлов в пуле пакетной службы Azure](batch-pool-vm-sizes.md).

### <a name="scaling-policy"></a>Политика масштабирования

Для динамических рабочих нагрузок можно написать и применить к пулу [формулу автоматического масштабирования](#scaling-compute-resources). По этой формуле пакетная служба периодически вычисляет и изменяет количество узлов в пуле в зависимости от выбранных вами параметров пула, заданий и задач.

### <a name="task-scheduling-policy"></a>Политика планирования задач

Параметр конфигурации [Максимальное число заданий на узел](batch-parallel-node-tasks.md) определяет максимальное число задач, которые могут параллельно выполняться на каждом вычислительном узле пула.

В конфигурации по умолчанию указывается выполнение только одной задачи на узле в любое время. Но в некоторых ситуациях выполнение нескольких задач на одном узле будет более правильным выбором. Сведения о преимуществах выполнения нескольких задач на узле см. в разделе [Пример сценария](batch-parallel-node-tasks.md#example-scenario) статьи [Повышение эффективности вычислительных ресурсов в пакетной службе Azure благодаря параллельному выполнению задач на узлах](batch-parallel-node-tasks.md).

Вы также можете выбрать *тип заполнения*. Пакетная служба может равномерно распределять задачи между всеми узлами в пуле или назначать каждому узлу максимально возможное число задач, прежде чем переходить к загрузке следующего узла пула.

### <a name="communication-status-for-compute-nodes"></a>Состояние взаимодействия между вычислительными узлами

В большинстве случаев задачи работают независимо друг от друга и взаимодействие между ними не требуется. Но в некоторых приложениях задачи должны взаимодействовать (например, при использовании [задач с несколькими экземплярами](batch-mpi.md)).

Вы можете разрешить **обмен данными между узлами**, входящими в один пул, для взаимодействия во время выполнения. При включении обмена данными между узлами узлы в пулах с конфигурацией облачных служб могут взаимодействовать друг с другом через порты с номерами выше 1100. При этом пулы с конфигурацией виртуальной машины не ограничивают трафик через какой-либо порт.

Обратите внимание, что включение обмена данными между узлами также влияет на размещение узлов в кластерах и из-за ограничений развертывания может ограничить максимальное количество узлов в пуле. Если приложению не требуется обмен данными между узлами, пакетная служба может выделить для пула большое количество узлов из разных кластеров и центров обработки данных. Это позволяет увеличить производительность параллельной обработки.

### <a name="start-tasks-for-compute-nodes"></a>Задачи запуска для вычислительных узлов

*Задача запуска* (необязательный параметр) будет выполняться на каждом узле при его присоединении к пулу, а также при каждом перезапуске или пересоздании образа узла. Она особенно полезна для подготовки вычислительных узлов к выполнению таких операций, как установка приложений, которые запускаются задачами на вычислительных узлах.

### <a name="application-packages"></a>Пакеты приложений

Вы можете указать [пакеты приложений](#application-packages) для развертывания на вычислительных узлах в пуле. Пакеты приложений обеспечивают упрощенное развертывание и управление версиями для приложений, запускаемых с помощью задач. Пакеты приложений, которые указываются для пула, устанавливаются на каждый вычислительный узел, который присоединяется к пулу, а также каждый раз, когда узел перезагружается или для него пересоздается образ.

> [!NOTE]
> Пакеты приложений поддерживаются во всех пулах пакетной службы, созданных после 5 июля 2017 г. Если пул создан с помощью конфигурации облачной службы, пакеты приложений также поддерживаются в пулах пакетной службы, созданных между 10 марта 2016 г. и 5 июля 2017 г. Пулы пакетной службы, созданные до 10 марта 2016 г., не поддерживают пакеты приложений. Дополнительные сведения о развертывании приложений на узлах пакетной службы с помощью пакетов приложений см .в [этой статье](batch-application-packages.md).
>
>

### <a name="network-configuration"></a>Конфигурация сети

Можно указать подсеть [виртуальной сети Azure](../virtual-network/virtual-networks-overview.md), в которой необходимо создать вычислительные узлы для пула. Более подробную информацию см. в разделе [Конфигурация сети пула](#pool-network-configuration).


## <a name="job"></a>Задание
Задание представляет собой набор задач. Оно управляет порядком выполнения вычислений каждой задачей на вычислительных узлах в пуле.

* Задание указывает **пул**, в котором будет выполняться работа. Вы можете создавать отдельный пул для каждого задания или использовать один пул для множества заданий. Кроме того, вы можете создавать пул для каждого задания, включенного в расписание, или единый пул для всех заданий в одном расписании.
* Вы можете указать **приоритет задания**, но это необязательный параметр. Если вы создаете задание с более высоким приоритетом, его задачи добавляются в очередь перед задачами менее приоритетных заданий. Задачи с более низким приоритетом, которые уже выполняются, прерываться не будут.
* Вы можете задать некоторые **ограничения** для заданий.

    Например, **максимальное время выполнения**. Таким образом, если задание выполняется дольше этого времени, оно будет завершено вместе со всеми задачами.

    Пакетная служба может обнаруживать и повторно выполнять незавершенные задачи. В качестве ограничения можно указать **максимальное число повторных попыток задачи**, а также следует ли пытаться повторно выполнить задачу (*всегда* или *никогда*). Повторное выполнение задачи означает, что она повторно помещается в очередь и будет снова запущена.
* Задачи к заданию может добавлять клиентское приложение. Кроме того, можно настроить [задачу диспетчера заданий](#job-manager-task). Задача диспетчера заданий содержит всю информацию для создания необходимых задач в рамках задания. Эту задачу выполняет один из вычислительных узлов пула. Задача диспетчера заданий обрабатывается пакетной службой особым образом: она помещается в очередь сразу при создании задания и перезапускается, если происходит сбой. Задача диспетчера заданий *необходима* для заданий, создаваемых согласно [расписанию заданий](#scheduled-jobs), так как это единственный способ определить задачи перед созданием экземпляра задания.
* По умолчанию задания остаются в активном состоянии после выполнения всех задач в задании. Это поведение можно изменить, чтобы задание автоматически завершалось после выполнения всех входящих в него задач. Для этого следует присвоить свойству **onAllTasksComplete** ([OnAllTasksComplete][net_onalltaskscomplete] в .NET пакетной службы) значение *terminatejob*.

    Обратите внимание, что пакетная служба считает задание *без* задач заданием, все задачи которого выполнены. Поэтому этот параметр чаще всего используется с [задачами диспетчера заданий](#job-manager-task). Если вы хотите использовать автоматическое завершение заданий без диспетчера заданий, необходимо сначала присвоить свойству **onAllTasksComplete** нового задания значение *noaction*. Значение *terminatejob* следует присвоить этому свойству только после добавления задач в задание.

### <a name="job-priority"></a>приоритет задания
При создании задания в пакетной службе ему можно назначить приоритет. Пакетная служба использует значения приоритетов заданий, чтобы определять порядок выполнения разных заданий в одной учетной записи (не путайте с [запланированным заданием](#scheduled-jobs)). Приоритет может иметь значение в диапазоне от -1000 до 1000, где -1000 означает наименьший приоритет, а 1000 — наивысший. Вы можете изменить приоритет задания с помощью вызова операции [обновления свойств задания][rest_update_job] в REST для пакетной службы или изменив свойство [CloudJob.Priority][net_cloudjob_priority] в .NET для пакетной службы.

В рамках одной учетной записи задания с высоким приоритетом имеют преимущество при планировании относительно заданий с низким приоритетом. Задания с более высоким приоритетом, относящиеся к одной учетной записи, не имеют преимущества при планировании относительно других заданий с более низким приоритетом, относящихся к другой учетной записи.

Задания распределяются по пулам независимо друг от друга. Если используется несколько пулов, задание с более высоким приоритетом не обязательно будет выполняться первым. Задание задерживается, если в связанном с ним пуле недостаточно свободных узлов. Если задания выполняются в одном пуле и имеют одинаковый приоритет, они имеют равные шансы на распределение.

### <a name="scheduled-jobs"></a>Запланированные задания
[Расписания заданий][rest_job_schedules] позволяют создавать в пакетной службе повторяющиеся задания. Расписание заданий определяет время запуска заданий и параметры для запуска этих заданий. Вы можете указать период действия задания, то есть с какого момента и в течение какого времени служба будет применять это расписание, а также частоту выполнения периодических заданий в этот период.

## <a name="task"></a>Задача
Задача представляет собой единицу вычисления, которая связана с заданием и выполняется на узле. Задачи назначаются узлу для выполнения или ставятся в очередь, пока не освободится какой-либо узел. Говоря простыми словами, задача запускает одну или несколько программ или сценариев на вычислительном узле, чтобы выполнить необходимую работу.

При создании задачи можно указать следующее:

* **Командная строка** задачи. Это командная строка, которая запускает приложение или сценарий на вычислительном узле.

    Следует отметить, что командная строка не выполняется на базе оболочки и поэтому не может автоматически использовать функции оболочки, например расширение [переменных среды](#environment-settings-for-tasks) (в том числе `PATH`). Чтобы воспользоваться этими функциями, необходимо вызвать оболочку в командной строке. Это можно сделать путем запуска `cmd.exe` на узлах Windows или `/bin/sh` на узлах Linux:

    `cmd /c MyTaskApplication.exe %MY_ENV_VAR%`

    `/bin/sh -c MyTaskApplication $MY_ENV_VAR`

    Если требуется, чтобы задачи выполняли приложение или скрипт без использования переменной `PATH` или переменных среды узла, на которые содержится ссылка, необходимо явным образом вызвать оболочку в командной строке задачи.
* **Файлы ресурсов**, которые содержат данные для обработки. Эти файлы автоматически копируются в узел из хранилища BLOB-объектов в учетной записи хранения Azure перед выполнением командной строки задачи. Дополнительные сведения см. в разделах [Задача запуска](#start-task) и [Файлы и каталоги](#files-and-directories).
* **Переменные среды**, необходимые для приложения. Дополнительные сведения см. в разделе [Параметры среды для задач](#environment-settings-for-tasks).
* **Ограничения**, в рамках которых должна выполняться задача. Например, может быть задано максимальное время на выполнение задачи, максимальное количество повторных попыток выполнить задачу, завершенную сбоем, и максимальное время хранения файлов в рабочем каталоге задачи.
* **Пакеты приложений** для развертывания на вычислительном узле, на котором запланировано выполнение задачи. [Пакеты приложений](#application-packages) обеспечивают упрощенное развертывание и управление версиями для приложений, запускаемых с помощью задач. Пакеты приложений уровня задач особенно полезны в средах с общим пулом, где различные задания выполняются в одном пуле, который не удаляется по завершении задания. Если задание содержит меньше задач, чем число узлов в пуле, пакеты приложений задач помогут минимизировать объем передаваемых данных, так как приложение развертывается только на узлах, на которых выполняются задачи.
* Ссылка на **образ контейнера** в Docker Hub или в частном реестре и дополнительные параметры для создания контейнера Docker, в котором выполняется задача на узле. Эти сведения указываются, только если пул настроен в конфигурации контейнера.

> [!NOTE]
> Максимальное время существования задачи от ее добавления к заданию до завершения составляет 7 дней. Завершенные задачи сохраняются в течение неограниченного времени; данные для задач, которые не были завершены в течение максимального времени существования, недоступны.

Помимо задач, которые можно определить для вычислений на узле, пакетная служба выполняет следующие специальные задачи.

* [Задача запуска](#start-task)
* [Задача диспетчера заданий](#job-manager-task)
* [Задачи подготовки и завершения заданий.](#job-preparation-and-release-tasks)
* [Задачи с несколькими экземплярами](#multi-instance-tasks)
* [Зависимости задачи](#task-dependencies)

### <a name="start-task"></a>Задача запуска
Связав **задачу запуска** с пулом, можно подготовить среду выполнения на его узлах. Например, эта задача может выполнять установку приложений, которые будут использоваться задачами, или запуск фоновых процессов. Задача запуска выполняется при каждом запуске узла, пока узел остается в пуле, в том числе при первом добавлении узла к пулу и при перезапуске или пересоздании образа узла.

Задача запуска особенно полезна тем, что она может содержать все сведения для настройки вычислительных узлов и установки приложений, которые нужны для выполнения задач. Таким образом, для увеличения числа узлов в пуле достаточно указать новое количество узлов. Задача запуска предоставляет пакетной службе сведения, необходимые для настройки новых узлов и подготовки их к выполнению задач.

Для этой задачи, как для любой задачи пакетной службы Azure, кроме исполняемой **командной строки**, можно указать список **файлов ресурсов**, которые хранятся в [службе хранилища Azure][azure_storage]. Пакетная служба сначала скопирует эти файлы на узел из службы хранилища Azure, а затем запустит командную строку. Список файлов для задачи запуска пула обычно содержит приложение задач или его зависимости.

В задаче запуска также могут содержаться справочные данные, которые будут использоваться всеми задачами, выполняемыми на вычислительном узле. Например, командная строка задачи запуска может выполнять операцию `robocopy`, чтобы скопировать файлы приложения (указанные в качестве файлов ресурсов и скачанные на узел) из [рабочего каталога](#files-and-directories) задачи запуска в [общую папку](#files-and-directories), а затем запустить MSI-файл или `setup.exe`.

Обычно желательно, чтобы пакетная служба дождалась завершения задачи запуска, прежде чем считать узел готовым к назначению задач, но это поведение можно изменить.

Если задача запуска на узле пула завершится сбоем, этот сбой отобразится в параметре состояния узла. При этом узлу не будут назначаться задачи. Задача запуска может завершиться сбоем, если не удастся скопировать файлы ресурсов из хранилища или если процесс, запущенный командной строкой задачи запуска, вернет ненулевой код завершения.

При добавлении или обновлении задачи запуска для существующего пула необходимо перезапустить его вычислительные узлы, чтобы применить к ним задачу запуска.

>[!NOTE]
> Общий размер задачи запуска не должен превышать 32 768 символов, включая файлы ресурсов и переменные среды. Чтобы убедиться, что ваша задача запуска соответствует этим требованиям, используйте один из двух следующих методов.
>
> 1. Можно применить пакеты для распределения приложений или данных в каждом узле пула пакетной службы. Дополнительные сведения о пакетах приложений см. в статье [Развертывание приложений на вычислительных узлах с помощью пакетов приложений пакетной службы](batch-application-packages.md).
> 2. Можно вручную создать ZIP-архив с файлами приложения. Отправьте ZIP-архив в службу хранилища Azure как большой двоичный объект. Укажите ZIP-архив в качестве файла ресурсов для задачи запуска. Перед использованием командной строки для задачи запуска распакуйте архив из командной строки. 
>
>    Для распаковки архива можно использовать средство архивации по своему усмотрению. Средство, которое использовалось для распаковки архива, необходимо указать как файл ресурсов для задачи запуска.
>
>

### <a name="job-manager-task"></a>Задача диспетчера заданий
**Задача диспетчера заданий** обычно используется для управления заданием и/или отслеживания его выполнения. Например, она создает и отправляет задачи для задания, определяет дополнительные задачи, которые нужно выполнить, и фиксирует завершение задания. Но задача диспетчера заданий не ограничивается такими действиями. Это полнофункциональная задача, которая может выполнять любые действия, требуемые в рамках задания. Например, задача диспетчера заданий может скачать файл, указанный в качестве параметра, проанализировать содержимое этого файла и в зависимости от содержимого отправить на выполнение дополнительные задачи.

Задача диспетчера заданий запускается перед выполнением всех других задач. Она предоставляет следующие возможности.

* Пакетная служба автоматически создает эту задачу при создании задания.
* Эта задача выполняется раньше любых других задач в задании.
* Узел, на котором выполняется задача, удаляется из пула последним при уменьшении размера пула.
* Такое завершение задачи может привести к завершению всех задач данного задания.
* При перезапуске задача диспетчера заданий получает наивысший приоритет. При этом, если нет свободных узлов, пакетная служба может освободить ресурсы для этой задачи, прервав выполнение одной из других задач, запущенных в пуле.
* Задача диспетчера заданий не имеет приоритета над задачами других заданий. Приоритеты между заданиями определяются только на уровне заданий.

### <a name="job-preparation-and-release-tasks"></a>Задачи подготовки и завершения заданий.
Для настройки среды выполнения задания в пакетной службе предусмотрена задача подготовки задания, а для очистки или обслуживания по окончании задания — задача завершения задания.

* **Задача подготовки задания**. Эта задача выполняется на всех вычислительных узлах, на которых запланировано выполнение задач, до выполнения какой-либо другой задачи задания. Например, вы можете применить задачу подготовки задания для копирования данных, которые используются всеми задачами, но только в рамках одного задания.
* **Задача завершения задания**. Когда задание завершается, эта задача выполняется на каждом узле в пуле, на котором была выполнена хотя бы одна задача. Задачу завершения задания можно использовать для удаления данных, скопированных задачей подготовки задания, или для сжатия и передачи диагностических данных журналов.

Задачи подготовки и завершения задания позволяют указать командную строку, которая будет выполняться при вызове задачи. Они предоставляют такие возможности, как загрузка файлов, выполнение с повышенными правами, пользовательские переменные среды, максимальная продолжительность выполнения, число повторных попыток и время хранения файла.

Дополнительные сведения о задачах подготовки и завершения заданий см. в статье [Выполнение задач подготовки и завершения заданий на вычислительных узлах пакетной службы Azure](batch-job-prep-release.md).

### <a name="multi-instance-task"></a>Задачи с несколькими экземплярами
[Задача с несколькими экземплярами](batch-mpi.md) — это задача, которая может выполняться на нескольких вычислительных узлах одновременно. С помощью задач с несколькими экземплярами можно включать высокопроизводительные вычислительные сценарии (такие как интерфейс передачи сообщений (MPI)), которым необходимо несколько совместно выделенных вычислительных узлов для обработки одной рабочей нагрузки.

Дополнительные сведения о выполнении заданий задач с несколькими экземплярами в пакетной службе с использованием библиотеки .NET для пакетной службы см. в статье [Использование задач с несколькими экземплярами для запуска приложений с интерфейсом передачи сообщений в пакетной службе Azure](batch-mpi.md).

### <a name="task-dependencies"></a>Зависимости задачи
[Зависимости задач](batch-task-dependencies.md), как можно понять из названия, позволяют настроить выполнение задачи в зависимости от предварительного завершения других задач. Эта функция обеспечивает поддержку в ситуациях, когда "подчиненная" задача использует выходные данные "вышестоящей" задачи или когда вышестоящая задача выполняет инициализацию, необходимую для подчиненных задач. Чтобы использовать эту функцию, необходимо сначала включить зависимости задач для задания пакетной службы. Затем для каждой задачи, зависящей от другой (или нескольких других), укажите задачи, от которых она зависит.

С помощью зависимостей задач можно настраивать различные сценарии, например:

* Задача *taskB* зависит от задачи *taskA* (выполнение задачи *taskB* не начнется, пока не завершится выполнение задачи *taskA*).
* Задача *taskC* зависит от задач *taskA* и *taskB*.
* Задача *taskD* зависит от ряда задач — от задачи *1* до задачи *10*.

Дополнительные сведения об этой возможности см. в статье [Зависимости задач в пакетной службе Azure](batch-task-dependencies.md) и в примере кода [TaskDependencies][github_sample_taskdeps] в репозитории [azure-batch-samples][github_samples] на сайте GitHub.

## <a name="environment-settings-for-tasks"></a>Параметры среды для задач
Каждая задача, выполняемая пакетной службой, имеет доступ к переменным среды, заданным на вычислительных узлах. Сюда входят переменные среды, определенные пакетной службой ([служебные][msdn_env_vars]), и пользовательские переменные среды, которые вы можете определить для задач. Приложения и скрипты, выполняемые с помощью задач, получают доступ к переменным среды во время выполнения.

Пользовательские переменные среды можно задать на уровне задачи или задания, задав свойство *параметров среды* для этих объектов. Для примера см. раздел об операции [добавления задачи к заданию][rest_add_task] (в REST API пакетной службы) или о свойствах [CloudTask.EnvironmentSettings][net_cloudtask_env] и [CloudJob.CommonEnvironmentSettings][net_job_env] в .NET для пакетной службы.

Чтобы получить значения служебных и пользовательских переменных среды задачи для клиентского приложения или службы, можно использовать операцию [получения сведений о задаче][rest_get_task_info] в REST для пакетной службы или свойство [CloudTask.EnvironmentSettings][net_cloudtask_env] в .NET для пакетной службы. Процессы, которые выполняются на вычислительном узле, могут обращаться к этим и другим переменным среды узла, например с помощью привычного синтаксиса `%VARIABLE_NAME%` в Windows или `$VARIABLE_NAME` в Linux.

Полный список всех служебных переменных среды см. в статье [Azure Batch compute node environment variables][msdn_env_vars] (Переменные среды вычислительного узла пакетной службы Azure).

## <a name="files-and-directories"></a>Файлы и каталоги
У каждой задачи есть *рабочий каталог*, в котором она может создавать дополнительные файлы и каталоги. Он может использоваться для хранения выполняемой программы, обрабатываемых данных и результатов обработки. Все файлы и каталоги задачи принадлежат пользователю задачи.

Пакетная служба предоставляет часть файловой системы на узле в качестве *корневого каталога*. Задачи могут обратиться к корневому каталогу с помощью ссылки на переменную среды `AZ_BATCH_NODE_ROOT_DIR`. Дополнительные сведения об использовании переменных среды см. в разделе [Параметры среды для задач](#environment-settings-for-tasks).

Корневой каталог имеет следующую структуру каталогов.

![Структура каталогов вычислительного узла][1]

* **shared**— в этом каталоге *все* задачи, выполняемые на узле, имеют права чтения и записи. Любая задача, выполняемая на узле, может создавать, читать, обновлять и удалять файлы в этом каталоге. Задачи могут получить доступ к этому каталогу с помощью ссылки на переменную среды `AZ_BATCH_NODE_SHARED_DIR` .
* **startup**— этот каталог используется задачей запуска в качестве рабочего каталога. Здесь хранятся все файлы, скачанные на узел с помощью задачи запуска. Задача запуска может создавать, читать, обновлять и удалять файлы в данном каталоге. Задачи могут получить доступ к этому каталогу с помощью ссылки на переменную среды `AZ_BATCH_NODE_STARTUP_DIR` .
* **Tasks**— такой каталог создается отдельно для каждой задачи, которая выполняется на узле. К нему можно получить доступ с помощью ссылки на переменную среды `AZ_BATCH_TASK_DIR` .

    В каждом каталоге задачи пакетная служба создает рабочий каталог (`wd`), который имеет уникальный путь, указанный в переменной среды `AZ_BATCH_TASK_WORKING_DIR`. Этот каталог предоставляет задаче доступ на чтение и запись. Задача может создавать, читать, обновлять и удалять файлы в данном каталоге. Время существования каталога определяется указанным для задачи ограничением *RetentionTime* .

    `stdout.txt` и `stderr.txt` — эти файлы сохраняются в папку задачи во время ее выполнения.

> [!IMPORTANT]
> При удалении узла из пула *все* файлы, хранящиеся на этом узле, удаляются.
>
>

## <a name="application-packages"></a>Пакеты приложений
[Пакеты приложений](batch-application-packages.md) упрощают управление приложениями и их развертывание на вычислительных узлах в пулах. Вы можете отправлять несколько версий приложений, выполняемых задачами, включая двоичные файлы и файлы поддержки (а также управлять этими версиями), а затем автоматически развертывать одно или несколько таких приложений на вычислительных узлах в пуле.

Пакеты приложений можно указывать на уровне пула и задачи. Если пакеты приложений определены на уровне пула, приложение развертывается на всех узлах в пуле. Если пакеты приложений определены на уровне задачи, приложение развертывается только на узлах, на которых запланировано выполнение хотя бы одной задачи задания, перед запуском командной строки задачи.

Пакетная служба обрабатывает сведения о работе со службой хранилища Azure, обеспечивая хранение пакетов приложений и их развертывание на вычислительных узлах. При этом упрощается код и сокращаются издержки, связанные с управлением.

Дополнительные сведения об использовании пакетов приложений см. в статье [Развертывание приложений на вычислительных узлах с помощью пакетов приложений пакетной службы](batch-application-packages.md).

> [!NOTE]
> При добавлении пакетов приложений пула в *существующий* пул необходимо перезагрузить его вычислительные узлы, чтобы обеспечить развертывание пакетов приложений на узлах.
>
>

## <a name="pool-and-compute-node-lifetime"></a>Время существования пула и вычислительного узла
При проектировании решения на базе пакетной службы Azure следует принять решение о том, когда и как будут создаваться пулы и как долго будут доступны вычислительные узлы в этих пулах.

Одной из крайностей является создание отдельного пула для каждого отправляемого задания и его удаление сразу по завершении выполнения задач. Такой вариант позволит максимально эффективно использовать ресурсы, так как узлы выделяются в необходимом количестве и завершают работу, как только переходят в состояние простоя. Но при этом задание должно ожидать выделения узлов. Важно отметить, что планирование задач для выполнения происходит по мере доступности и выделения каждого отдельного узла сразу после выполнения на нем задачи запуска. Иными словами, пакетная служба *не* дожидается, пока все узлы в пуле станут доступными, чтобы назначить задачи узлам. Это позволяет обеспечить максимально эффективное использование ресурсов.

Другим крайним вариантом является заблаговременное создание пула и подготовка его узлов до запуска заданий. Этот вариант применим для тех ситуаций, когда немедленный запуск задания имеет наивысший приоритет. В этом случае задачи будут запускаться немедленно, но при этом узлы могут некоторое время простаивать в ожидании назначения задач.

Смешанный подход обычно используется для обработки постоянной нагрузки, интенсивность которой изменяется. В этом случае создается пул для нескольких заданий, количество узлов в котором изменяется в зависимости от текущей нагрузки (см. раздел [Масштабирование вычислительных ресурсов](#scaling-compute-resources) ниже). Масштабирование можно выполнять по мере изменения интенсивности нагрузки или с упреждением, если нагрузка является прогнозируемой.

## <a name="virtual-network-vnet-and-firewall-configuration"></a>Конфигурация виртуальной сети и брандмауэра 

При подготовке пула вычислительных узлов в пакетной службе можно связать его с подсетью [виртуальной сети Azure](../virtual-network/virtual-networks-overview.md). Для использования виртуальной сети Azure API клиента пакетной службы должен использовать проверку подлинности Azure Active Directory (AD). Поддержка AAD пакетной службой Azure описана в статье [Аутентификация решений пакетной службы с помощью Active Directory](batch-aad-auth.md).  

### <a name="vnet-requirements"></a>Требования к виртуальной сети
[!INCLUDE [batch-virtual-network-ports](../../includes/batch-virtual-network-ports.md)]

Дополнительные сведения о настройке пула пакетной службы в виртуальной сети см. в статье [Create an Azure Batch pool in a virtual network](batch-virtual-network.md) (Создание пула пакетной службы Azure в виртуальной сети).

## <a name="scaling-compute-resources"></a>Масштабирование вычислительных ресурсов
[Автоматическое масштабирование](batch-automatic-scaling.md)позволяет использовать пакетную службу для динамической настройки количества вычислительных узлов в пуле в соответствии с текущей рабочей нагрузкой и использованием ресурсов в рамках вашего сценария вычислений. Это позволит снизить общую стоимость работы приложения за счет использования только необходимых ресурсов и освобождения остальных.

Чтобы включить автоматическое масштабирование, необходимо написать [соответствующую формулу](batch-automatic-scaling.md#automatic-scaling-formulas) и связать ее с пулом. Пакетная служба использует эту формулу для определения целевого количества узлов в пуле для следующего интервала масштабирования (интервал, который можно настроить). Вы можете указать параметры автоматического масштабирования для пула при его создании или включить масштабирование позже. Вы также можете обновить параметры масштабирования в пуле с включенным масштабированием.

Рассмотрим для примера задание, которое требует отправки большого количества задач для выполнения. Вы можете назначить для пула формулу масштабирования, которая изменяет количество узлов пула в зависимости от текущего числа задач в очереди и скорости выполнения этих задач, входящих в задание. Пакетная служба периодически вычисляет формулу и изменяет размер пула в зависимости от рабочей нагрузки и других параметров формулы. По мере необходимости служба добавляет узлы, если в очереди стоит большое количество задач, и удаляет узлы при отсутствии задач в очереди или выполняемых задач.

Формула масштабирования может использовать следующие метрики.

* **Метрики времени** — основываются на статистических данных, которые собираются каждые 5 минут за указанное число часов.
* **Метрики ресурсов** — зависят от показателей загрузки ЦП, использования пропускной способности и памяти, а также количества узлов.
* **Метрики задач** зависят от состояния задачи: *Активная* (в очереди), *Выполняется* или *Завершена*.

Если при автоматическом масштабировании уменьшается количество вычислительных узлов в пуле, необходимо учитывать способ обработки текущих выполняемых задач. Чтобы решить эту проблему, пакетная служба предоставляет *параметр отмены выделения узла*, который можно добавить в формулу. Например, можно указать, чтобы выполняемые задачи сразу останавливались, а затем помещались в очередь на выполнение на другом узле или завершались до удаления узла из пула.

Подробные сведения об автоматическом масштабировании приложения см. в статье [Автоматическое масштабирование вычислительных узлов в пуле пакетной службы Azure](batch-automatic-scaling.md).

> [!TIP]
> Для максимально эффективного использования ресурсов укажите значение "ноль" для целевого количества узлов на момент завершения задания, но позвольте текущим задачам завершиться нормально.
>
>

## <a name="security-with-certificates"></a>Безопасность с использованием сертификатов
Обычно сертификаты нужны для шифрования и расшифровки конфиденциальных сведений, используемых задачами, например ключей [учетной записи службы хранилища Azure][azure_storage]. Такие сертификаты можно установить на узлах. Зашифрованные данные передаются задачам через параметры командной строки или через ресурсы задачи, а установленные сертификаты позволяют расшифровать их.

Для добавления сертификата к учетной записи пакетной службы используйте операцию [добавления сертификата][rest_add_cert] в REST API пакетной службы или метод [CertificateOperations.CreateCertificate][net_create_cert] в .NET для пакетной службы. Затем можно будет связать сертификат с новым или существующим пулом. Если к пулу привязан сертификат, пакетная служба устанавливает этот сертификат на каждом узле пула. Пакетная служба устанавливает нужные сертификаты при запуске узла до начала выполнения каких-либо задач (в том числе задач запуска и задач диспетчера заданий).

При добавлении сертификатов в *существующий* пул необходимо перезагрузить его вычислительные узлы, чтобы применить к ним сертификаты.

## <a name="error-handling"></a>Обработка ошибок
Возможно, вы захотите обрабатывать ошибки задач и приложений в своем решении пакетной службы.

### <a name="task-failure-handling"></a>Обработка сбоев задач
Сбои задач делятся на следующие категории.

* **Ошибки предварительной обработки**

    Если не удается запустить задачу, для нее устанавливается ошибка предварительной обработки.  

    Ошибки предварительной обработки могут возникать, если файлы ресурсов задачи перемещены, учетная запись хранения недоступна или не удалось выполнить копирование файлов на узел из-за другой проблемы.

* **Ошибки передачи файлов**

    Если по какой-либо причине происходит сбой передачи файлов, указанных для задачи, для нее устанавливается ошибка передачи файлов.

    Ошибки передачи файлов могут возникать, если подписанный URL-адрес, указанный для доступа к службе хранилища Azure, недействителен или не предоставляет разрешения на запись, учетная запись хранения недоступна либо произошла другая ошибка, которая не позволяет скопировать файлы с узла.    

* **Ошибки приложений**

    Процесс, указанный в командной строке задачи, также может завершиться ошибкой. Если процесс, который выполняет задача, возвращает ненулевой код завершения, считается, что такой процесс завершился ошибкой (см. подраздел *Код завершения задач* в следующем разделе).

    Вы можете настроить пакетную службу так, чтобы в случае ошибки приложения она автоматически повторяла задачу, а также указать максимальное количество таких попыток.

* **Ошибки ограничения**

    Вы можете установить ограничение на максимальное время выполнения задания или задачи с помощью параметра *maxWallClockTime*. Это полезно для завершения задач, переставших отвечать на запросы.

    Если превышено максимальное время выполнения, задача отмечается как *завершенная*, но с кодом выхода `0xC000013A`. При этом поле *schedulingError* будет иметь значение `{ category:"ServerError", code="TaskEnded"}`.

### <a name="debugging-application-failures"></a>Отладка ошибок приложений
* `stderr` и `stdout`

    Во время выполнения приложение может создавать диагностические данные, которые помогут устранить неполадки. Как упоминалось выше в разделе [Файлы и каталоги](#files-and-directories), пакетная служба записывает стандартные потоки вывода и ошибок в файлы `stdout.txt` и `stderr.txt`, расположенные в каталоге задач на вычислительном узле. Чтобы получить эти файлы, можно использовать портал Azure или один из пакетов SDK пакетной службы. Например, вы можете получить эти и другие файлы для устранения неполадок, используя методы [ComputeNode.GetNodeFile][net_getfile_node] и [CloudTask.GetNodeFile][net_getfile_task] библиотеки .NET для пакетной службы.

* **Код завершения задач**

    Как упоминалось выше, пакетная служба помечает задачу как завершившуюся сбоем, если процесс, выполняемый задачей, возвращает ненулевой код завершения. Когда задача выполняет процесс, пакетная служба заполняет свойство кода завершения задачи *кодом возврата процесса*. Следует отметить, что код завершения задачи определяется **не** пакетной службой. Код завершения задачи определяется самим процессом или операционной системой, в которой он выполняется.

### <a name="accounting-for-task-failures-or-interruptions"></a>Работа со сбоями и прерываниями задач
Задачи могут иногда завершаться ошибками или прерываться. Например, может завершиться ошибкой приложение задачи или узел, на котором выполняется задача, может быть перезапущен. Кроме того, узел может быть удален из пула при изменении размера, если установленная политика отмены выделения предусматривает немедленное удаление узла без ожидания завершения задачи. Во всех случаях пакетная служба может автоматически поставить задачу в очередь на повторное выполнение на другом узле.

Задача может также зависнуть или выполняться слишком долго из-за кратковременного сбоя. Для задачи можно установить максимальный интервал выполнения. В случае его превышения пакетная служба прерывает выполнение приложения задачи.

### <a name="connecting-to-compute-nodes"></a>Подключение к вычислительным узлам
Дополнительные возможности для отладки и устранения неполадок можно получить, выполнив вход на вычислительный узел удаленно. Вы можете использовать портал Azure, чтобы скачать RDP-файл для узлов Windows и получить сведения о подключении SSH для узлов Linux. Это также можно сделать с помощью API пакетной службы (например, в экземплярах [Batch .NET][net_rdpfile] или [Batch Python](batch-linux-nodes.md#connect-to-linux-nodes-using-ssh)).

> [!IMPORTANT]
> Чтобы подключиться к узлу по протоколу RDP или SSH, на узле нужно создать пользователя. Для этого можно использовать портал Azure, [добавить учетную запись пользователя на узел][rest_create_user] с помощью REST API пакетной службы, вызвать метод [ComputeNode.CreateComputeNodeUser][net_create_user] в .NET API пакетной службы или метод [add_user][py_add_user] в модуле Python пакетной службы.
>
>

Если необходимо ограничить или отключить доступ к вычислительным узлам по RDP или SSH, см. руководство по [настройке или отключению удаленного доступа к вычислительным узлам в пуле пакетной службы Azure](pool-endpoint-configuration.md).

### <a name="troubleshooting-problematic-compute-nodes"></a>Устранение неполадок проблемных вычислительных узлов
В ситуациях, когда при выполнении некоторых задач происходит сбой, пакетное клиентское приложение или служба может проверить метаданные неудачных задач для определения узла, который плохо работает. Каждому узлу в пуле присваивается уникальный идентификатор, а сведения об узле, на котором выполняется задача, включены в метаданные задачи. Определив проблемный узел, вы можете предпринять некоторые действия:

* **Перезапустить узел** ([REST][rest_reboot] | [.NET][net_reboot])

    В некоторых случаях перезапуск узла может устранить некоторые скрытые проблемы, например задержки и сбои при выполнении процессов. Обратите внимание, что если пул использует начальную задачу или задание использует задачу подготовки задания, они будут выполнены при перезапуске узла.
* **Пересоздать образ узла** ([REST][rest_reimage] | [.NET][net_reimage])

    Это обеспечит переустановку операционной системы на узле. Как и в случае перезагрузки узла, задачи запуска и задачи подготовки заданий будут повторно выполнены после повторного создания образа узла.
* **Удалить узел из пула** ([REST][rest_remove] | [.NET][net_remove])

    Иногда бывает необходимо полностью удалить узел из пула.
* **Отключить планирование задач на узле** ([REST][rest_offline] | [.NET][net_offline])

    Это эффективно переключит узел в "автономный режим", чтобы ему не назначались дальнейшие задачи, но сохранялась возможность продолжать выполнять текущие задачи, оставаясь в пуле. Благодаря этому вы сможете продолжить поиск причины сбоев без потери данных невыполненной задачи и без сбоев при выполнении дополнительных задач на узле. Например, можно отключить планирование задач на узле, а затем выполнить [удаленный вход](#connecting-to-compute-nodes) на узел для анализа журналов событий или устранения других неполадок. Проанализировав проблемы, вы сможете снова подключить узел к сети, включив планирование задач ([REST][rest_online] | [.NET][net_online]) или выполнив одно из перечисленных выше действий.

> [!IMPORTANT]
> С помощью каждого действия, перечисленного в этом разделе, (перезагрузки, пересоздания образа, удаления, отключения планирования задач) вы можете указать вариант обработки текущих задач на узле при выполнении действия. Например, при отключении планирования задач на узле с помощью клиентской библиотеки .NET для пакетной службы вы можете указать значение перечисления [DisableComputeNodeSchedulingOption][net_offline_option], чтобы определить, что нужно сделать до выполнения действия (**TaskCompletion**): **прекратить** выполнение текущих задач, **повторно поставить их в очередь** для планирования выполнения на других узлах или разрешить завершение текущих задач.
>
>

## <a name="next-steps"></a>Дополнительная информация
* См. дополнительные сведения об [API-интерфейсах и средствах пакетной службы](batch-apis-tools.md) для сборки решений пакетной службы.
* Ознакомьтесь с пошаговой инструкцией по созданию примера приложения пакетной службы в статье [Начало работы с библиотекой пакетной службы Azure для .NET](batch-dotnet-get-started.md). Существует также [версия Python](batch-python-tutorial.md) этого руководства. В ней рассматривается выполнение рабочих нагрузок на вычислительных узлах Linux.
* Скачайте и установите [BatchLabs][batch_labs] для использования во время разработки решений пакетной службы. Используйте BatchLabs для создания, отладки и мониторинга приложений пакетной службы Azure. 
* Узнайте, как [создавать пулы вычислительных узлов Linux](batch-linux-nodes.md).
* Посетите [форум по пакетной службе Azure][batch_forum] на сайте MSDN. Здесь могут задавать вопросы как начинающие, так и опытные пользователи пакетной службы.

[1]: ./media/batch-api-basics/node-folder-structure.png

[azure_storage]: https://azure.microsoft.com/services/storage/
[batch_forum]: https://social.msdn.microsoft.com/Forums/en-US/home?forum=azurebatch
[cloud_service_sizes]: ../cloud-services/cloud-services-sizes-specs.md
[msmpi]: https://msdn.microsoft.com/library/bb524831.aspx
[github_samples]: https://github.com/Azure/azure-batch-samples
[github_sample_taskdeps]:  https://github.com/Azure/azure-batch-samples/tree/master/CSharp/ArticleProjects/TaskDependencies
[batch_labs]: https://azure.github.io/BatchLabs/
[batch_net_api]: https://msdn.microsoft.com/library/azure/mt348682.aspx
[msdn_env_vars]: https://msdn.microsoft.com/library/azure/mt743623.aspx
[net_cloudjob_jobmanagertask]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudjob.jobmanagertask.aspx
[net_cloudjob_priority]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudjob.priority.aspx
[net_cloudpool_starttask]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudpool.starttask.aspx
[net_cloudtask_env]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudtask.environmentsettings.aspx
[net_create_cert]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.certificateoperations.createcertificate.aspx
[net_create_user]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.computenode.createcomputenodeuser.aspx
[net_getfile_node]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.computenode.getnodefile.aspx
[net_getfile_task]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudtask.getnodefile.aspx
[net_job_env]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudjob.commonenvironmentsettings.aspx
[net_multiinstancesettings]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.multiinstancesettings.aspx
[net_onalltaskscomplete]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.cloudjob.onalltaskscomplete.aspx
[net_rdp]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.computenode.getrdpfile.aspx
[net_reboot]: https://msdn.microsoft.com/library/azure/mt631495.aspx
[net_reimage]: https://msdn.microsoft.com/library/azure/mt631496.aspx
[net_remove]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.pooloperations.removefrompoolasync.aspx
[net_offline]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.computenode.disableschedulingasync.aspx
[net_online]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.computenode.enableschedulingasync.aspx
[net_offline_option]: https://msdn.microsoft.com/library/azure/microsoft.azure.batch.common.disablecomputenodeschedulingoption.aspx
[net_rdpfile]: https://msdn.microsoft.com/library/azure/Mt272127.aspx
[vnet]: https://msdn.microsoft.com/library/azure/dn820174.aspx#bk_netconf

[py_add_user]: http://azure-sdk-for-python.readthedocs.io/en/latest/ref/azure.batch.operations.html#azure.batch.operations.ComputeNodeOperations.add_user

[batch_rest_api]: https://msdn.microsoft.com/library/azure/Dn820158.aspx
[rest_add_job]: https://msdn.microsoft.com/library/azure/mt282178.aspx
[rest_add_pool]: https://msdn.microsoft.com/library/azure/dn820174.aspx
[rest_add_cert]: https://msdn.microsoft.com/library/azure/dn820169.aspx
[rest_add_task]: https://msdn.microsoft.com/library/azure/dn820105.aspx
[rest_create_user]: https://msdn.microsoft.com/library/azure/dn820137.aspx
[rest_get_task_info]: https://msdn.microsoft.com/library/azure/dn820133.aspx
[rest_job_schedules]: https://msdn.microsoft.com/library/azure/mt282179.aspx
[rest_multiinstance]: https://msdn.microsoft.com/library/azure/mt637905.aspx
[rest_multiinstancesettings]: https://msdn.microsoft.com/library/azure/dn820105.aspx#multiInstanceSettings
[rest_update_job]: https://msdn.microsoft.com/library/azure/dn820162.aspx
[rest_rdp]: https://msdn.microsoft.com/library/azure/dn820120.aspx
[rest_reboot]: https://msdn.microsoft.com/library/azure/dn820171.aspx
[rest_reimage]: https://msdn.microsoft.com/library/azure/dn820157.aspx
[rest_remove]: https://msdn.microsoft.com/library/azure/dn820194.aspx
[rest_offline]: https://msdn.microsoft.com/library/azure/mt637904.aspx
[rest_online]: https://msdn.microsoft.com/library/azure/mt637907.aspx

[vm_marketplace]: https://azure.microsoft.com/marketplace/virtual-machines/
