---
title: Проектирование признаков при обработке и анализе данных | Документация Майкрософт
description: Описывает цели реконструирования характеристик и приводит примеры, поясняющие его роль в совершенствовании данных в процессе машинного обучения.
services: machine-learning
documentationcenter: ''
author: deguhath
manager: cgronlun
editor: cgronlun
ms.assetid: 3fde69e8-5e7b-49ad-b3fb-ab8ef6503a4d
ms.service: machine-learning
ms.component: team-data-science-process
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 11/21/2017
ms.author: deguhath
ms.openlocfilehash: b4194ef5ab1c2c09206ea0acf78cb539bc2fc0b7
ms.sourcegitcommit: 944d16bc74de29fb2643b0576a20cbd7e437cef2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/07/2018
ms.locfileid: "34836523"
---
# <a name="feature-engineering-in-data-science"></a>Проектирование признаков при обработке и анализе данных
В этой статье описано, зачем проектировать признаки, а также на примерах показана их роль в процессе оптимизации данных в ходе машинного обучения. Примеры, представленные для иллюстрирования этого процесса, взяты из студии машинного обучения Azure. 

[!INCLUDE [cap-create-features-data-selector](../../../includes/cap-create-features-selector.md)]

Это **меню** содержит ссылки на статьи, в которых объясняется, как создавать признаки для данных в разных средах. Эта задача является одним из этапов [процесса обработки и анализа данных группы (TDSP)](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/).

Реконструирование характеристик пытается повысить эффективность прогнозирования алгоритмов обучения путем создания характеристик из необработанных данных, позволяющих упростить процесс обучения. Проектирование и выбор признаков являются частью процесса TDSP, описанного в статье [Что такое процесс обработки и анализа данных группы (TDSP)?](overview.md) Проектирование и выбор характеристик входят в этап **разработки характеристик** процесса TDSP. 

* **Проектирование признаков.** Этот процесс направлен на создание дополнительных характерных признаков на основе существующих необработанных признаков и повышение эффективности прогнозирования алгоритма обучения.
* **Выбор признаков**: в этом процессе выбирается ключевое подмножество исходных признаков с целью сокращения размерности задачи обучения.

Как правило, **проектирование признаков** сначала применяется для создания дополнительных признаков, а затем выполняется на этапе **выбора признаков**, чтобы исключить несоответствующие, избыточные или сильно коррелирующие признаки.

Обучающие данные, используемые в машинном обучении, можно улучшить путем извлечения характеристик из собранных необработанных данных. Пример реконструирования характеристики в контексте обучения для классификации изображений рукописных символов представляет собой битовую карту распределения плотности, построенную на основе необработанных данных распределения битов. Эта карта помогает более эффективно находить края символов, чем в случае необработанных данных о распределении.

[!INCLUDE [machine-learning-free-trial](../../../includes/machine-learning-free-trial.md)]

## <a name="create-features-from-your-data---feature-engineering"></a>Создание признаков на основе данных. Проектирование признаков
Обучающие данные образуют матрицу из примеров (записей или наблюдений, хранимых в строках), каждый из которых имеет набор признаков (переменных или полей, хранящихся в столбцах). Признаки, указанные в схеме эксперимента должны характеризовать закономерности в данных. Несмотря на то, что многие поля необработанных данных можно напрямую включить в набор выбранных признаков, используемых для обучения модели, часто бывает так, что для формирования набора усовершенствованных обучающих данных дополнительные (реконструированные) признаки требуется создавать из признаков в необработанных данных.

Какие признаки нужно создавать для расширения набора данных при обучении модели? Реконструированные признаки, совершенствующие обучение, содержат сведения, которые лучше выделяют закономерности в данных. Новые признаки должны предоставлять дополнительные сведения, нечетко зарегистрированные или неочевидные в исходном или существующем наборе. Это довольно творческий процесс. Обоснованные и эффективные решения часто требуют определенного знания предметной области.

При запуске машинного обучения Azure проще всего понять этот процесс с помощью примеров, которые поставляются в комплекте со Студией. Здесь представлены два примера.

* Пример регрессии [Прогнозирование количества прокатов велосипедов](http://gallery.cortanaintelligence.com/Experiment/Regression-Demand-estimation-4) в контролируемом эксперименте с известными целевыми значениями
* Пример классификации интеллектуального анализа текста с использованием [хэширования признаков](https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/)

## <a name="example-1-add-temporal-features-for-a-regression-model"></a>Пример 1. Добавление временных признаков для регрессионной модели
Воспользуемся экспериментом «Прогнозирование спроса на велосипеды» в студии машинного обучения Azure, чтобы продемонстрировать реконструкцию признаков для задачи регрессии. Цель этого эксперимента — прогноз спроса на велосипеды, то есть количество сдаваемых напрокат велосипедов в конкретный день/месяц/час. «Набор данных по прокату велосипедов UCI» используется в качестве необработанных входных данных. Этот набор данных основывается на реальных данных компании Capital Bikeshare, которая содержит сеть проката велосипедов в Вашингтоне (ОК), США. Набор данных представляет количество сдаваемых напрокат велосипедов в определенный час дня в 2011–2012 гг. и содержит 17379 строки и 17 столбцов. Набор необработанных признаков содержит погодные условия (температура, влажность и скорость ветра) и тип дня (праздник/будний день). Поле cnt для прогнозирования определяет количество велосипедов, сдаваемых напрокат в течение указанного часа, в диапазоне от 1 до 977.

Для создания эффективных признаков в обучающих данных строятся четыре регрессионные модели с использованием одного и того же алгоритма, но с четырьмя разными обучающими наборами данных. Четыре набора данных представляют те же необработанные входные данные, но с увеличиваемым номером набора признаков. Эти признаки сгруппированы в четыре категории:

1. А = «погода» + «праздник» + «рабочий день» + «выходной день» для прогнозируемого дня
2. Б = количество велосипедов, которые сданы напрокат в каждый из предыдущих 12 часов
3. В = количество велосипедов, которые были сданы напрокат в каждый из предыдущих 12 дней в течение одного и того же часа
4. Г = количество велосипедов, которые были сданы напрокат в каждую из предыдущих 12 недель в течение одного и того же часа и дня

Помимо набора признаков А, который уже существует в исходных необработанных данных, другие три набора признаков создаются в процессе реконструирования признаков. Набор признаков Б охватывает новейший спрос на велосипеды. Набор признак В спрос на велосипеды в конкретный час. Набор признаков Г охватывает спрос на велосипеды в определенный час и определенный день недели. Четыре набора обучающих данных содержат наборы признаков А, А + Б, А + Б + В и A + Б + В + Г, соответственно.

В эксперименте машинного обучения Azure эти четыре наборы обучающих данных формируются через четыре ветви предварительно обработанного входного набора данных. За исключением крайней левой ветви, каждая из этих ветвей содержит модуль [Выполнить сценарий R](https://msdn.microsoft.com/library/azure/30806023-392b-42e0-94d6-6b775a6e0fd5/), в котором производные признаки (набор признаков Б, В и Г) соответственно реконструируются и добавляются в импортируемый набор данных. На следующем рисунке показан сценарий R, используемый для создания набора признаков Б во второй слева ветви.

![создание признаков](./media/create-features/addFeature-Rscripts.png)

Сравнение результатов производительности четырех моделей приведено в таблице ниже. 

![сравнение результатов](./media/create-features/result1.png)

Наилучшие результаты даются набором признаков А + Б + В. Обратите внимание, что частота ошибок уменьшается, когда в обучающие данные включается дополнительный набор признаков. Он подтверждает предположение, что набор признаков Б + В предоставляет дополнительные данные для задачи регрессии. Однако добавление набора признаков Г не дает дополнительного сокращения частоты ошибок.

## <a name="example2"></a> Пример 2. Создание признаков в интеллектуальном анализе текста
Реконструирование признаков широко применяется в задачах, связанных с интеллектуальным анализом текста, например классификации документов и анализе тональностей. Например, если нужно классифицировать документы по нескольким категориям, типичными предположениями являются слова или фразы, которые вероятнее всего есть в одной категории документов и которые с меньшей вероятностью есть в другой категории. Другими словами, частота распределения слов или фраз может характеризовать разные категории документов. В приложениях интеллектуального анализа текста отдельные части текстового содержимого обычно служат в качестве входных данных, поэтому для создания признаков, связанных с частотой вхождения слова или фразы, необходим процесс реконструирования признаков.

Для выполнения этой задачи вызывается метод **хэширования признаков** , чтобы эффективно превратить произвольные признаки текста в индексы. Вместо того, чтобы сопоставлять каждый признак текста (слова или фразы) для определенного индекса, этот метод работает путем применения хэш-функции к признакам и непосредственного использования их хэш-значений как индексов.

В машинном обучении Azure есть модуль [хэширования признаков](https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/) , с помощью которого удобнее создавать признаки этих слов и фраз. На рисунке ниже показан пример использования данного модуля. Входной набор данных содержит два столбца: рейтинг книги от 1 до 5 и содержимое фактической рецензии. Задача этого модуля [хэширования признаков](https://msdn.microsoft.com/library/azure/c9a82660-2d9c-411d-8122-4d9e0b3ce92a/) состоит в извлечении множества новых признаков, чтобы показать частоту вхождения соответствующих слов в рецензии на определенную книгу. Чтобы использовать этот модуль, сделайте следующее:

* Сначала выберите столбец, содержащий входной текст («Col2» в этом примере).
* Затем для Hashing bitsize установите значение 8, означающее, что будет создано 2^8 = 256 признаков. Слова и фразы всего текста будут хэшированы на 256 индексов. Параметр Hashing bitsize меняется в диапазоне от 1 до 31. Слова и фразы с меньшей вероятностью хэшируются с тем же индексом при росте значения параметра.
* После этого задайте для параметра N-grams значение 2. Этот значение возвращает частоту вхождения униграмм (признаков для каждого отдельного слова) и биграмм (признаков для каждой пары смежных слов) во входном тексте. Параметр N-grams меняется от 0 до 10, определяя максимальное количество последовательно идущих слов, которые включены в признак.  

![Модуль «Хэширование признаков»](./media/create-features/feature-Hashing1.png)

На следующем рисунке показано, на что похожи эти новые признаки.

![Пример «Хэширование признаков»](./media/create-features/feature-Hashing2.png)

## <a name="conclusion"></a>Заключение
Реконструированные и выбранные признаки повышают эффективность процесса обучения, который пытается извлечь ключевые сведения, содержащиеся в данных. Они также дают возможность повысить возможности этих моделей, чтобы точнее классифицировать входные данные и более надежно предсказывать нужные результаты. Реконструирование и выбор признаков можно также объединять, чтобы сделать процесс обучения более алгоритмизируемым. Этого можно достичь путем расширения и сокращения числа признаков, необходимых для калибровки или обучения модели. С точки зрения математики выбранные для обучения модели признаки являются минимальным набором независимых переменных, которые определяют структуры в данных и затем успешно прогнозируют результаты.

Не всегда обязательно выполнять реконструирование или выбор признаков. Необходимость в этом зависит от передаваемых или собранных данных, выбранного алгоритма и цели эксперимента.

