---
title: "Создание модели для службы \"Машинное обучение Azure\" (предварительная версия) | Документация Майкрософт"
description: "Из этого полного руководства вы узнаете, как использовать службу \"Машинное обучение Azure\" (предварительная версия). Это вторая часть серии руководств. В ней рассматривается экспериментирование."
services: machine-learning
author: hning86
ms.author: haining
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.workload: data-services
ms.custom: mvc, tutorial
ms.topic: hero-article
ms.date: 11/06/2017
ms.openlocfilehash: 79374f18d46e8e7d84772423c2cd40d9acb4d7dd
ms.sourcegitcommit: a48e503fce6d51c7915dd23b4de14a91dd0337d8
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 12/05/2017
---
# <a name="classify-iris-part-2-build-a-model"></a>Часть 2. Классификация цветков ириса: создание модели
Служба "Машинное обучение Azure" (предварительная версия) — это полнофункциональное интегрированное аналитическое решение для специалистов по обработке и анализу данных. Оно помогает подготавливать данные, разрабатывать эксперименты и развертывать модели в масштабе облака.

Это руководство представляет собой вторую часть серии, состоящей из трех частей. В этой части вы будете использовать службу "Машинное обучение Azure" (предварительная версия), чтобы научиться выполнять следующие задачи:

> [!div class="checklist"]
> * использование Azure Machine Learning Workbench;
> * открытие скриптов и проверка кода;
> * выполнение скриптов в локальной среде;
> * просмотр журнала выполнения;
> * выполнение скриптов в локальной среде Docker;
> * выполнение скриптов в локальном окне Azure CLI;
> * выполнение скриптов в удаленной среде Docker;
> * выполнение скриптов в облачной среде Azure HDInsight.

В этом руководстве используется классический [набор данных "Ирисы Фишера"](https://en.wikipedia.org/wiki/Iris_flower_data_set). Снимки экрана представляют среду Windows, но для Mac OS все процедуры практически идентичны.

## <a name="prerequisites"></a>Предварительные требования
Выполните инструкции из первой части этой серии руководств. Прежде чем начинать работу с этим руководством, выполните инструкции из руководства по [подготовке данных](tutorial-classifying-iris-part-1.md), чтобы создать ресурсы службы "Машинное обучение Azure" и установить приложение Azure Machine Learning Workbench.

Кроме того, можно попробовать выполнить скрипты с использованием локального контейнера Docker. Для этого установите и запустите подсистему Docker (достаточно выпуска Community Edition) локально на компьютере с Windows или Mac OS. Дополнительные сведения см. в [инструкциях по установке Docker](https://docs.docker.com/engine/installation/).

Чтобы запустить выполнение скриптов в контейнере Docker на удаленной виртуальной машине Azure или в кластере HDInsight Spark, следуйте [инструкциям по созданию виртуальной машины Azure для обработки и анализа данных на базе Ubuntu или кластера HDInsight](how-to-create-dsvm-hdi.md).

## <a name="review-irissklearnpy-and-the-configuration-files"></a>Просмотр файлов конфигурации и файла iris_sklearn.py
1. Откройте приложение Azure Machine Learning Workbench, а затем откройте проект **myIris**, созданный в предыдущей части этой серии руководств.

2. Открыв проект, нажмите кнопку **Файлы** (значок папки) на крайней левой панели, чтобы открыть список файлов в папке проекта.

3. Выберите файл **iris_sklearn.py**. На новой вкладке текстового редактора в Workbench откроется код Python.

   ![Открытие файла](media/tutorial-classifying-iris/open_iris_sklearn.png)

   >[!NOTE]
   >Код, который вы увидите, может не совпадать с кодом на снимке экрана выше, так как пример проекта постоянно обновляется.

4. Просмотрите код скрипта Python, чтобы ознакомиться со стилем программирования. Скрипт выполняет следующие задачи:

   - Загружает пакет подготовки данных **iris.dprep** для создания [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). 

        >[!NOTE]
        >Используйте пакет подготовки данных `iris.dprep` из примера проекта. Он должен соответствовать файлу `iris-1.dprep`, созданному в первой части этой серии руководств.

   - Добавляет случайные компоненты, чтобы усложнить задачу. Случайность необходима, так как "Ирисы Фишера" — это небольшой набор данных, который можно легко классифицировать почти со 100 %-й точностью.

   - Использует библиотеку машинного обучения [scikit-learn](http://scikit-learn.org/stable/index.html), чтобы создать модель логистической регрессии. 

   - Сериализует модель путем вставки библиотеки [pickle](https://docs.python.org/2/library/pickle.html) в файл в папке `outputs`. Затем скрипт загружает модель и десериализует ее обратно в память.

   - Использует десериализованную модель для прогнозирования на основе новой записи. 

   - Отображает два графика, матрицу неточностей и многоклассовую кривую рабочих характеристик приемника (ROC) с помощью библиотеки [matplotlib](https://matplotlib.org/), а затем сохраняет их в папку `outputs`.

   - Объект `run_logger` используется во всех операциях для записи частоты регуляризации и точности модели в журналы. Журналы автоматически отображаются в журнале выполнения.


## <a name="execute-irissklearnpy-script-in-a-local-environment"></a>Выполнение скрипта iris_sklearn.py в локальной среде

Давайте подготовим скрипт **iris_sklearn.py** к первому выполнению. Для работы этого скрипта требуются пакеты **scikit-learn** и **matplotlib**. Пакет **scikit-learn** устанавливается вместе с Azure Machine Learning Workbench. Но вам нужно установить пакет **matplotlib**. 

1. В Azure Machine Learning Workbench в меню **Файл** выберите **Открыть командную строку**. Это окно интерфейса командной строки называется *окно Azure Machine Learning Workbench CLI* или просто *окно CLI* для краткости.

2. В окне CLI введите следующую команду, чтобы установить пакет Python **matplotlib**. Операция займет не больше минуты.

   ```azurecli
   pip install matplotlib
   ```

   >[!NOTE]
   >Если пропустить предыдущую команду `pip install`, код в файле `iris_sklearn.py` будет успешно запущен. Но если запустить только `iris_sklearn.py`, код не создаст выходные данные матрицы неточностей и графики многоклассовой кривой ROC, как показано в визуализациях журнала.

3. Вернитесь в окно приложения Workbench. 

4. На панели инструментов в верхней части вкладки **iris_sklearn.py** выберите раскрывающееся меню рядом со значком **Сохранить**, а затем выберите **Конфигурация запуска**. Выберите **локальную** среду выполнения и введите `iris_sklearn.py` в качестве скрипта для запуска.

5. Затем перейдите к правой части панели инструментов и введите `0.01` в поле **Аргументы**. 

   ![Элемент управления "Запустить"](media/tutorial-classifying-iris/run_control.png)

6. Нажмите кнопку **Запустить**. Будет запланировано выполнение задания. Задания перечислены на панели **Задания** с правой стороны окна Workbench. 

7. Через несколько секунд состояние задания изменится с **Отправка** на **Выполнение**, а затем — на **Завершено**.

   ![Запуск sklearn](media/tutorial-classifying-iris/run_sklearn.png)

8. Выберите **Завершено** в тексте состояния задания на панели **Задания**. Откроется всплывающее окно, отображающее текст стандартного потока вывода (stdout) выполняемого скрипта. Чтобы закрыть текст stdout, нажмите кнопку **Закрыть** (**x**) в правом верхнем углу всплывающего окна.

9. В том же состоянии задания на панели **Задания** выберите синий текст **iris_sklearn.py [n]** (_n_ — это номер запуска) над состоянием **Завершено** и временем начала. Откроется окно **свойств запуска**, в котором отобразятся следующие сведения об этом запуске:
   - сведения о **свойствах запуска**;
   - файлы **выходных данных**;
   - **визуализации** (если есть);
   - **Журналы** 

   По завершении запуска во всплывающем окне отобразятся следующие результаты:

   >[!NOTE]
   >Так как выше мы включили случайный выбор компонентов в набор для обучения, ваши результаты могут отличаться от приведенных здесь.

   ```text
   Python version: 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]
   
   Iris dataset shape: (150, 5)
   Regularization rate is 0.01
   LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
   Accuracy is 0.6792452830188679
   
   ==========================================
   Serialize and deserialize using the outputs folder.
   
   Export the model to model.pkl
   Import the model from model.pkl
   New sample: [[3.0, 3.6, 1.3, 0.25]]
   Predicted class is ['Iris-setosa']
   Plotting confusion matrix...
   Confusion matrix in text:
   [[50  0  0]
    [ 1 37 12]
    [ 0  4 46]]
   Confusion matrix plotted.
   Plotting ROC curve....
   ROC curve plotted.
   Confusion matrix and ROC curve plotted. See them in Run History details pane.
   ```

10. Закройте вкладку **свойств запуска** и вернитесь на вкладку **iris_sklearn.py**. 

11. Повторите дополнительные процедуры выполнения. 

    Введите ряд числовых значений в поле **Аргументы** в диапазоне от `0.001` до `10`. Нажмите кнопку **Запустить**, чтобы запустить код еще несколько раз. Значение аргумента, которое вы каждый раз меняете, передается в алгоритм логистической регрессии в коде, поэтому каждый раз вы получаете разные результаты.

## <a name="review-the-run-history-in-detail"></a>Подробный просмотр журнала выполнения
В Azure Machine Learning Workbench каждое выполнение скрипта записывается в журнале выполнения. Откройте представление **Запуски**, чтобы просмотреть журнал выполнения определенного скрипта.

1. Нажмите кнопку **Запуски** (значок часов) на панели инструментов слева, чтобы открыть список **Запуски**. Затем выберите **iris_sklearn.py**, чтобы отобразить **панель мониторинга запусков** для `iris_sklearn.py`.

   ![Представление "Запуски"](media/tutorial-classifying-iris/run_view.png)

2. Откроется вкладка **Панель мониторинга запусков**. Просмотрите статистику, записанную для нескольких запусков. Графики отображаются в верхней части вкладки. Каждому запуску присвоен порядковый номер, а сведения о запуске отображаются в таблице в нижней части экрана.

   ![Панель мониторинга запуска](media/tutorial-classifying-iris/run_dashboard.png)

3. Отфильтруйте таблицу. Затем выберите любой из графиков, чтобы просмотреть состояние, длительность, точность и частоту регуляризации для каждого запуска. 

4. Выберите два или три запуска в таблице **Запуски** и нажмите кнопку **Сравнить**, чтобы открыть страницу с подробными сведениями. Сравните результаты. Нажмите кнопку **Список запусков** со стрелкой назад в верхней левой части панели **Сравнение**, чтобы вернуться на **панель мониторинга запусков**.

5. Выберите отдельный запуск, чтобы просмотреть подробные сведения о запуске. Обратите внимание: статистика для выбранного запуска доступна в разделе **Свойства запуска**. Файлы, записанные в выходную папку, перечислены в разделе **Выходные данные**, где их можно скачать.

   ![Сведения о запуске](media/tutorial-classifying-iris/run_details.png)

   Два графика, матрица неточностей и многоклассовая кривая ROC отображаются в разделе **Визуализации**. Все файлы журнала также доступны в разделе **Журналы**.

## <a name="execute-scripts-in-the-local-docker-environment"></a>Выполнение скриптов в локальной среде Docker

Машинное обучение позволяет легко настраивать дополнительные среды выполнения (например, Docker) и запускать в них скрипты. 

>[!IMPORTANT]
>Для этого требуется локально установленная и запущенная подсистема Docker. Дополнительную информацию см. в инструкциях по установке Docker.

1. На панели инструментов слева выберите значок **папки**, чтобы открыть список **файлов** проекта. Разверните папку `aml_config`. 

2. Вы увидите несколько предварительно настроенных сред: **docker-python**, **docker-spark** и **local**. 

   В каждой среде есть два файла: `docker-python.compute` и `docker-python.runconfig`. Откройте каждый файл. Вы увидите, что некоторые параметры можно изменить в текстовом редакторе.  

   Чтобы выполнить очистку, выберите значок **Закрыть** (**x**) на вкладках в открытых текстовых редакторах.

3. Запустите скрипт **iris_sklearn.py** с помощью среды **docker-python**. 

   - На панели инструментов слева щелкните значок **часов**, чтобы открыть панель **Запуски**. Выберите **Все запуски**. 
   - В верхней части представления **Все запуски** выберите **docker-python** как целевую среду вместо стандартного значения **local**. 
   - Затем справа выберите **iris_sklearn.py** в качестве скрипта для запуска. 
   - Оставьте поле **Аргументы** пустым, так как скрипт определит значение по умолчанию. 
   - Нажмите кнопку **Запустить**.

4. Понаблюдайте за запуском нового задания. Оно отобразится на панели **Задания** в правой части окна Workbench.

   Первый запуск в Docker выполняется на несколько минут дольше. 

   Azure Machine Learning Workbench в фоновом режиме создает новый файл Docker. 
   Новый файл ссылается на базовый образ Docker, указанный в файле `docker.compute`, и пакеты зависимостей Python, указанные в файле `conda_dependencies.yml`. 
   
   Подсистема Docker выполняет следующие задачи:

    - скачивает базовый образ из Azure;
    - устанавливает пакеты Python, указанные в файле `conda_dependencies.yml`;
    - запускает контейнер Docker;
    - копирует локальную копию папки проекта (или создает ссылку на нее в зависимости от конфигурации запуска);      
    - выполняет скрипт `iris_sklearn.py`.

   В итоге вы увидите результат, аналогичный результату при выборе среды **local**.

5. Теперь поработаем со Spark. Базовый образ Docker содержит предварительно установленный и настроенный экземпляр Spark. Поэтому вы можете запускать в нем скрипт PySpark. Это простой способ разработки и тестирования программы Spark. Вам не нужно тратить время на самостоятельные установку и настройку Spark. 

   Откройте файл `iris_spark.py` . Этот скрипт загружает файл данных `iris.csv` и использует алгоритм логистической регрессии из библиотеки службы машинного обучения Spark для классификации набора данных "Ирисы Фишера". Теперь измените среду выполнения на **docker-spark**, а скрипт — на **iris_spark.py** и повторите запуск. Этот процесс займет немного больше времени, так как сеанс Spark должен быть создан и запущен в контейнере Docker. Как видите, stdout отличается от stdout из `iris_spark.py`.

6. Выполните еще несколько запусков, используя разные аргументы. 

7. Откройте файл `iris_spark.py`, чтобы просмотреть модель логистической регрессии, созданную с использованием библиотеки службы машинного обучения Spark. 

8. Поработайте с панелью **Задания**, откройте представление списка журналов выполнения и представление сведений о запусках в разных средах выполнения.

## <a name="execute-scripts-in-the-azure-machine-learning-cli-window"></a>Выполнение скриптов в локальном окне Azure Machine Learning Workbench CLI

1. В Azure Machine Learning Workbench откройте окно командной строки. Для этого в меню **Файл** выберите **Открыть командную строку**. Командная строка откроется в папке проекта со строкой `C:\Temp\myIris\>`.

   >[!IMPORTANT]
   >Для выполнения следующих действий необходимо использовать окно командной строки, открыв его из Workbench.

2. Войдите в Azure с помощью командной строки. 

   Приложение Workbench и CLI используют независимые кэши учетных данных для аутентификации пользователя ресурсов Azure. Это необходимо сделать только один раз до истечения срока действия кэшированного маркера. Команда **az account list** возвращает список доступных подписок для вашего имени входа. Если у вас несколько подписок, используйте значение идентификатора из нужной подписки. Назначьте эту подписку учетной записью по умолчанию для использования с командой **az account set -s**, а затем укажите значение идентификатора подписки. Подтвердите настройки с помощью команды **show** для учетной записи.

   ```azurecli
   REM login by using the aka.ms/devicelogin site
   az login
   
   REM lists all Azure subscriptions you have access to 
   az account list -o table
   
   REM sets the current Azure subscription to the one you want to use
   az account set -s <subscriptionId>
   
   REM verifies that your current subscription is set correctly
   az account show
   ```

3. Выполнив аутентификацию и настроив контекст текущей подписки Azure, введите следующие команды в окне CLI. Так вы установите библиотеку **matplotlib** и отправите скрипт Python в качестве эксперимента для запуска.

   ```azurecli
   REM you don't need to run this command if you have installed matplotlib locally from the previous steps
   pip install matplotlib
   
   REM kicks off an execution of the iris_sklearn.py file against the local compute context
   az ml experiment submit -c local .\iris_sklearn.py
   ```

4. Просмотрите выходные данные. Вы получите те же результаты, что и при использовании приложения Workbench для запуска скрипта. 

5. Если на вашем компьютере установлена подсистема Docker, запустите этот же скрипт еще раз, используя среду выполнения Docker.

   ```azurecli
   REM executes iris_sklearn.py in the local Docker container Python environment
   az ml experiment submit -c docker-python .\iris_sklearn.py 0.01
   
   REM executes iris_spark.py in the local Docker container Spark environment
   az ml experiment submit -c docker-spark .\iris_spark.py 0.1
   ```
6. В Workbench щелкните значок **папки** на панели инструментов слева, чтобы открыть список файлов проекта. Затем откройте скрипт Python с именем **run.py**. 

   Этот скрипт можно использовать для повторного запуска с разной частотой регуляризации. Запустите эксперимент несколько раз с разной частотой. Этот скрипт начинается с задания `iris_sklearn.py` с частотой регуляризации `10.0` (очень большое число). Затем скрипт сокращает частоту наполовину в следующем запуске и продолжает сокращать ее в последующих запусках, пока ее значение не дойдет до `0.005`. 

   ```python
   # run.py
   import os
   
   reg = 10
   while reg > 0.005:
       os.system('az ml experiment submit -c local ./iris_sklearn.py {}'.format(reg))
       reg = reg / 2
   ```

   Чтобы открыть скрипт **run.py** из командной строки, выполните следующие команды:

   ```cmd
   REM submits iris_sklearn.py multiple times with different regularization rates
   python run.py
   ```

   По выполнении `run.py` вы увидите график в представлении списка журналов выполнения в Workbench.

## <a name="execute-in-a-docker-container-on-a-remote-machine"></a>Выполнение в контейнере Docker на удаленном компьютере
Чтобы выполнить скрипт в контейнере Docker на удаленном компьютере Linux, необходимо иметь доступ SSH (имя пользователя и пароль) к этому компьютеру. Кроме того, на удаленном компьютере должна быть установлена и запущена подсистема Docker. Самый простой способ получить доступ к такому компьютеру Linux — создать виртуальную машину для обработки и анализа данных на базе Ubuntu в Azure. См. дополнительные сведения о [создании виртуальной машины для обработки и анализа данных Ubuntu для использования в Azure ML Workbench](how-to-create-dsvm-hdi.md#create-an-ubuntu-dsvm-in-azure-portal).

>[!NOTE] 
>Виртуальная машина для обработки и анализа данных на базе CentOS *не* поддерживается.

1. Созданную виртуальную машину можно присоединить в качестве среды выполнения, создав пару файлов `.runconfig` и `.compute`. Для создания этих файлов выполните следующую команду. Назовем новую среду `myvm`.
 
   ```azurecli
   REM creates an myvm compute target
   az ml computetarget attach remotedocker --name myvm --address <IP address> --username <username> --password <password>
   ```
   
   >[!NOTE]
   >IP-адрес также может быть общедоступным полным доменным именем (FQDN), например `vm-name.southcentralus.cloudapp.azure.com`. Рекомендуем добавить полное доменное имя виртуальной машины для обработки и анализа данных и использовать его вместо IP-адреса. Такой подход очень удобен, так как вы можете в любой момент отключить виртуальную машину, чтобы сэкономить на оплате. Кроме того, при очередном запуске виртуальной машины, IP-адрес может быть изменен.

   Затем выполните следующую команду, чтобы создать образ Docker на виртуальной машине и подготовить ее для выполнения скриптов:
   
   ```azurecli
   REM prepares the myvm compute target
   az ml experiment prepare -c myvm
   ```
   >[!NOTE]
   >Можно также изменить значение `PrepareEnvironment` в `myvm.runconfig` со значения по умолчанию `false` на `true`. После этого изменения вы автоматически подготовите контейнер Docker при первом запуске.

2. Измените созданный файл `myvm.runconfig` в разделе `aml_config` и измените значение параметра Framework с `PySpark` (по умолчанию) на `Python`:

   ```yaml
   "Framework": "Python"
   ```
   >[!NOTE]
   >Можно также оставить для параметра Framework значение PySpark. Но это будет менее эффективно, если вам не нужен сеанс Spark для запуска скрипта Python.

3. Выполните ту же команду, что и в окне CLI, только на этот раз используйте _myvm_:
   ```azurecli
   REM executes iris_sklearn.py in a remote Docker container
   az ml experiment submit -c myvm .\iris_sklearn.py
   ```
   Команда выполняется, как и при использовании среды `docker-python`, но сейчас это происходит на удаленной виртуальной машине Linux. Окно CLI отображает те же выходные данные.

4. Попробуем использовать Spark в контейнере. Откройте проводник. Это также можно сделать в окне CLI, если вы привыкли использовать базовые команды для работы с файлами. Создайте копию файла `myvm.runconfig` и назовите ее `myvm-spark.runconfig`. Отредактируйте новый файл, чтобы изменить значение параметра `Framework` с `Python` на `PySpark`:
   ```yaml
   "Framework": "PySpark"
   ```
   Не вносите изменения в файл `myvm.compute`. Для выполнения Spark используется тот же образ Docker на той же виртуальной машине. В новом файле `myvm-spark.runconfig` поле `target` указывает на тот же файл `myvm.compute`, ссылаясь на его имя `myvm`.

5. Введите следующую команду, чтобы выполнить запуск в экземпляре Spark в удаленном контейнере Docker:
   ```azureli
   REM executes iris_spark.py in a Spark instance on a remote Docker container
   az ml experiment submit -c myvm-spark .\iris_spark.py
   ```

## <a name="execute-script-in-an-hdinsight-cluster"></a>Выполнение скрипта в кластере HDInsight
Этот скрипт также можно выполнить в кластере HDInsight. См. дополнительные сведения о [создании кластера HDInsight Spark в Azure ML Workbench](how-to-create-dsvm-hdi.md#create-an-apache-spark-for-azure-hdinsight-cluster-in-azure-portal).

>![ПРИМЕЧАНИЕ] Кластер HDInsight должен использовать большие двоичные объекты Azure в качестве основного хранилища. Использование хранилища Azure Data Lake еще не поддерживается.

1. Если у вас есть доступ к Spark для кластера Azure HDInsight, создайте команду конфигурации запуска HDInsight, как показано ниже. Укажите в качестве параметров имя кластера HDInsight, имя пользователя HDInsight и пароль. Используйте следующую команду:

   ```azurecli
   REM creates a compute target that points to a HDInsight cluster
   az ml computetarget attach cluster --name myhdi --address <cluster head node FQDN> --username <username> --password <password>

   REM prepares the HDInsight cluster
   az ml experiment prepare -c myhdi
   ```

   Полное доменное имя головного узла кластера обычно выглядит так: `<cluster_name>-ssh.azurehdinsight.net`.

   >[!NOTE]
   >`username` — это имя пользователя SSH кластера. Значение по умолчанию — `sshuser`, если вы не меняли его при настройке HDInsight. Это не пользователь `admin`, который был создан при настройке для включения доступа к веб-сайту администрирования кластера. 

2. Выполните следующую команду, чтобы запустить скрипт в кластере HDInsight:

   ```azurecli
   REM executes iris_spark on the HDInsight cluster
   az ml experiment submit -c myhdi .\iris_spark.py
   ```

   >[!NOTE]
   >Выполняя скрипт в удаленном кластере HDI, вы можете просмотреть подробные сведения о выполнении задания Yet Another Resource Negotiator (YARN) в `https://<cluster_name>.azurehdinsight.net/yarnui` с помощью учетной записи `admin`.


## <a name="next-steps"></a>Дальнейшие действия
Из второй части серии руководств, состоящей из трех частей, вы узнали, как с помощью службы "Машинное обучение Azure" выполнять следующие задачи:
> [!div class="checklist"]
> * использование Azure Machine Learning Workbench;
> * открытие скриптов и проверка кода;
> * выполнение скриптов в локальной среде;
> * просмотр журнала выполнения;
> * выполнение скриптов в локальной среде Docker;
> * выполнение скриптов в локальном окне Azure CLI;
> * выполнение скриптов в удаленной среде Docker;
> * выполнение скриптов в облачной среде HDInsight.

Вы готовы перейти к третьей части этой серии руководств. Теперь, когда вы создали модель логистической регрессии, вы можете развернуть ее как веб-службу, работающую в реальном времени.

> [!div class="nextstepaction"]
> [Развертывание модели](tutorial-classifying-iris-part-3.md)
