---
title: Выбор алгоритмов машинного обучения | Документация Майкрософт
description: Как выбрать алгоритмы машинного обучения Azure для контролируемого и неконтролируемого обучения в экспериментах кластеризации, классификации или регрессии.
services: machine-learning
documentationcenter: ''
author: pakalra
ms.author: pakalra
manager: cgronlun
editor: cgronlun
tags: ''
ms.assetid: a3b23d7f-f083-49c4-b6b1-3911cd69f1b4
ms.service: machine-learning
ms.component: studio
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 12/18/2017
ms.openlocfilehash: 79b2cc3951fa8a48282f42f7180ec831050508f8
ms.sourcegitcommit: 944d16bc74de29fb2643b0576a20cbd7e437cef2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/07/2018
ms.locfileid: "34834388"
---
# <a name="how-to-choose-algorithms-for-microsoft-azure-machine-learning"></a>Выбор алгоритмов машинного обучения Microsoft Azure
Ответ на вопрос "Какие алгоритмы машинного обучения использовать?" всегда звучит так: "Это зависит от ряда обстоятельств". Это зависит от размера, качества и природы данных. Это зависит от того, что нужно сделать с ответом. Это зависит от того, как математический алгоритм был преобразован в инструкции для вашего компьютера. И это зависит от того, сколько времени у вас есть. Даже самые опытные специалисты по данным не смогут определить наилучший алгоритм, не попробовав его.

## <a name="the-machine-learning-algorithm-cheat-sheet"></a>Памятка по алгоритмам машинного обучения
**Памятка по алгоритмам машинного обучения для Студии машинного обучения Microsoft Azure** поможет выбрать правильный алгоритм из библиотеки алгоритмов машинного обучения Microsoft Azure для решений прогнозной аналитики.
В этой статье описано, как пользоваться памяткой.

> [!NOTE]
> Чтобы загрузить памятку и последовать указаниям в этой статье, перейдите к разделу [Памятка по алгоритмам машинного обучения для Студии машинного обучения Microsoft Azure](algorithm-cheat-sheet.md).
> 
> 

Это памятка рассчитана на очень узкую аудиторию: начинающих специалистов по данным, которые пытаются выбрать алгоритм для начала работы со Студией машинного обучения Microsoft Azure. Это означает, что в памятке используются некоторые обобщения и упрощения, но она направит вас в верном направлении. Это также означает, что существует множество алгоритмов, которые не описаны в памятке. По мере развития машинного обучения Azure и пополнения списка доступных методов мы будем добавлять их в памятку.

Эти рекомендации представляют собой объединенные отзывы и советы от большого количества специалистов по обработке и анализу данных, а также экспертов по машинному обучению. Мы достигли соглашения не во всем, но попытались прийти к единому мнению по сложным вопросам. Большинство инструкций, в которых возникли разногласия, начинаются со слов "Это зависит от..."

### <a name="how-to-use-the-cheat-sheet"></a>Как пользоваться памяткой
Обозначения пути и алгоритма на схеме следует читать как "для *&lt;обозначения пути&gt;* используйте *&lt;алгоритм&gt;*". Например, "для *скорости* используйте *двухклассную логистическую регрессию*". Иногда может использоваться более одной ветви алгоритма.
Иногда ни одна из ветвей алгоритма не подходит идеально. Эти рекомендации приближенные, поэтому не нужно беспокоиться о том, что они не являются точными.
Некоторые специалисты по данным, с которыми я общался, говорили, что единственный надежный способ определить наилучший алгоритм — попробовать их все.

Ниже приведен пример эксперимента из [коллекции решений ИИ Azure](http://gallery.cortanaintelligence.com/), в котором используется несколько алгоритмов для одних и тех же данных, а затем сравниваются результаты: [Сравнение многоклассовых классификаторов: распознавание букв](http://gallery.cortanaintelligence.com/Details/a635502fc98b402a890efe21cec65b92).

> [!TIP]
> Чтобы скачать и распечатать схему, на которой представлены общие возможности Студии машинного обучения, см. [обзорную схему возможностей Студии машинного обучения Azure](studio-overview-diagram.md).
> 
> 

## <a name="flavors-of-machine-learning"></a>Разновидности машинного обучения
### <a name="supervised"></a>Контролируемое
Контролируемые алгоритмы обучения выполняют прогнозирование на основе набора примеров. Например, стоимость акций в прошлом позволяет предположить стоимость акций в будущем. Каждый пример, используемый для обучения, помечается интересующим нас значением — в данном случае это стоимость акций. Контролируемый алгоритм обучения выполняет поиск шаблонов в этих значениях. Он может использовать любые соответствующие сведения — день недели, время года, финансовые данные компании, тип отрасли, наличие важных геополитических событий — и каждый алгоритм ищет шаблоны различных типов. После того как алгоритм обнаружил наилучший шаблон, он может на основе этого шаблона предсказать неразмеченные проверочные данные — завтрашние цены.

Контролируемое обучение — это популярный и полезный тип машинного обучения. За одним исключением все модули машинного обучения Azure являются контролируемыми алгоритмами обучения. В машинном обучении Azure существует несколько типов контролируемых алгоритмов обучения: классификация, регрессия и обнаружение аномалий.

* **Классификация**. Если данные используются для прогнозирования категории, контролируемое обучение также называется классификацией. Это происходит, когда рисунок определяется как изображение "кошки" или "собаки". При наличии только двух вариантов такая классификация называется **двухклассной** или **биномиальной**. При наличии нескольких категорий, как при прогнозировании победителя турнира NCAA March Madness, классификация называется **многоклассовой**.
* **Регрессия**. При прогнозировании значения, например стоимости акций, контролируемое обучение называется регрессией.
* **Обнаружение аномалий**. Иногда задача состоит в идентификации точек данных, которые просто являются необычными. Например, при выявлении мошенничества с кредитной картой подозрительными являются любые необычные операции оплаты. Количество возможных вариантов так велико, а количество известных примеров так мало, что научиться определять мошеннические действия очень трудно. Подход, который используется при обнаружении аномалий, состоит в том, чтобы просто изучить, как выглядят нормальные действия (с помощью журнала нормальных транзакций), и определять все действия, которые существенно отличаются от нормальных.

### <a name="unsupervised"></a>Неконтролируемое
При неконтролируемом обучении точкам данных не присваиваются метки. Вместо этого цель алгоритма неконтролируемого обучения — определенное упорядочивание данных или описание их структуры. Это может означать группировку данных в кластеры или поиск различных способов анализа сложных данных для их упрощения или улучшения их организации.

### <a name="reinforcement-learning"></a>Обучение с подкреплением
В обучении с подкреплением алгоритм выбирает действие в ответ на каждую точку данных. Алгоритм обучения также вскоре получает сигнал, оповещающий об успехе, который дает понять, насколько удачно было принято решение.
На основе этого алгоритм изменяет свою стратегию для достижения лучшего результата. На данный момент в машинном обучении Azure модули алгоритмов обучения с подкреплением отсутствуют. Обучение с подкреплением широко распространено в робототехнике, где набор показаний датчиков в один момент времени представляет собой точку данных и алгоритму необходимо выбрать следующее действие робота. Кроме того, оно естественным образом подходит для приложений из Интернета вещей.

## <a name="considerations-when-choosing-an-algorithm"></a>Рекомендации по выбору алгоритма
### <a name="accuracy"></a>Точность
Получение наиболее точного ответа необходимо не всегда.
Иногда достаточно приближенного ответа в зависимости от того, для чего он используется. В этом случае можно значительно сократить время обработки, придерживаясь более приближенных методов. Еще одним преимуществом более приближенных методов является то, что они естественным образом стремятся избежать [чрезмерно высокой точности](https://youtu.be/DQWI1kvmwRg).

### <a name="training-time"></a>Время обучения
Количество минут или часов, необходимых для обучения модели, сильно отличается для различных алгоритмов. Время обучения часто тесно связано с точностью — одно обычно сопутствует другому. Кроме того, некоторые алгоритмы более чувствительны к количеству точек данных, чем другие.
Когда время ограничено, это может повлиять на выбор алгоритма, особенно с большим набором данных.

### <a name="linearity"></a>Линейность
Линейность используется во многих алгоритмах машинного обучения. Алгоритмы линейной классификации предполагают, что классы могут быть разделены прямой линией (или ее аналогом для большего числа измерений). К ним относятся логистическая регрессия и метод опорных векторов (в том виде, в котором это реализовано в машинном обучении Azure).
Алгоритмы линейной регрессии предполагают, что тренды данных следуют прямой линии. Эти предположения допустимы для ряда задач, но для других задач они приводят к снижению точности.

![Граница нелинейного класса][1]

***Граница нелинейного класса*** *— использование алгоритма линейной классификации приведет к низкой точности*

![Данные с нелинейным трендом][2]

***Данные с нелинейным трендом*** *— использование алгоритма линейной классификации приведет к появлению гораздо большего количества ошибок, чем необходимо*

Несмотря на их опасность, линейные алгоритмы очень популярны на первой линии атаки. Обычно они алгоритмически просты и быстро осваиваются.

### <a name="number-of-parameters"></a>Количество параметров
Параметры являются теми регуляторами, которые специалист по данным поворачивает при настройке алгоритма. Это числа, которые влияют на поведение алгоритма, например чувствительность к ошибкам или количество итераций, или на варианты поведения алгоритма. Время обучения и точность алгоритма иногда могут быть очень чувствительными к точности задания параметров. Как правило, алгоритмы с большим числом параметров требуют большого количества проб и ошибок, чтобы определить удачное сочетание параметров.

Кроме того, в машинном обучении Azure есть блок модулей [корректировки параметров](algorithm-parameters-optimize.md) , который автоматически пробует все сочетания параметров с любой выбранной детализацией. Хотя это отличный способ убедиться в том, что вы заполнили пространство параметров, с увеличением количества параметров экспоненциально возрастает время, необходимое для обучения модели.

Плюсом является то, что наличие большого количества параметров обычно означает, что алгоритм имеет большую гибкость. Это часто позволяет добиваться очень хорошей точности. При условии, что вы можете найти правильную комбинацию параметров.

### <a name="number-of-features"></a>Количество функций
Для некоторых типов данных количество функций может быть очень большим по сравнению с количеством точек данных. Это часто происходит с генетическими или текстовыми данными. Большое количество функций для некоторых алгоритмов обучения может привести к тому, что они увязнут и время обучения станет недопустимо большим. Для этого варианта особенно хорошо подходит метод опорных векторов (см. ниже).

### <a name="special-cases"></a>Особые случаи
Некоторые алгоритмы обучения делают определенные предположения о структуре данных или желаемых результатов. Если вы сможете найти тот алгоритм, который соответствует вашим потребностям, с ним вы сможете получить более точные результаты, более точные прогнозы и сократить время обучения.

| **Алгоритм** | **Точность** | **Время обучения** | **Линейность** | **Параметры** | **Примечания** |
| --- |:---:|:---:|:---:|:---:| --- |
| **Двуклассовая классификация** | | | | | |
| [логистическая регрессия](https://msdn.microsoft.com/library/azure/dn905994.aspx) | |● |● |5 | |
| [лес решений](https://msdn.microsoft.com/library/azure/dn906008.aspx) |● |○ | |6 | |
| [джунгли решений](https://msdn.microsoft.com/library/azure/dn905976.aspx) |● |○ | |6 |Низкий объем памяти |
| [увеличивающееся дерево решений](https://msdn.microsoft.com/library/azure/dn906025.aspx) |● |○ | |6 |Большой объем памяти |
| [нейронная сеть](https://msdn.microsoft.com/library/azure/dn905947.aspx) |● | | |9 |[Возможна дополнительная настройка](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [усредненное восприятие](https://msdn.microsoft.com/library/azure/dn906036.aspx) |○ |○ |● |4. | |
| [метод опорных векторов](https://msdn.microsoft.com/library/azure/dn905835.aspx) | |○ |● |5 |Подходит для больших наборов функций |
| [локально глубокий метод опорных векторов](https://msdn.microsoft.com/library/azure/dn913070.aspx) |○ | | |8 |Подходит для больших наборов функций |
| [точечная машина Байеса](https://msdn.microsoft.com/library/azure/dn905930.aspx) | |○ |● |3 | |
| **Многоклассовая классификация** | | | | | |
| [логистическая регрессия](https://msdn.microsoft.com/library/azure/dn905853.aspx) | |● |● |5 | |
| [лес решений](https://msdn.microsoft.com/library/azure/dn906015.aspx) |● |○ | |6 | |
| [джунгли решений ](https://msdn.microsoft.com/library/azure/dn905963.aspx) |● |○ | |6 |Низкий объем памяти |
| [нейронная сеть](https://msdn.microsoft.com/library/azure/dn906030.aspx) |● | | |9 |[Возможна дополнительная настройка](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [one-v-all](https://msdn.microsoft.com/library/azure/dn905887.aspx) |- |- |- |- |Просмотрите свойства выбранного двухклассового метода |
| **Регрессия** | | | | | |
| [линейная](https://msdn.microsoft.com/library/azure/dn905978.aspx) | |● |● |4. | |
| [Байесовская линейная](https://msdn.microsoft.com/library/azure/dn906022.aspx) | |○ |● |2 | |
| [лес решений](https://msdn.microsoft.com/library/azure/dn905862.aspx) |● |○ | |6 | |
| [увеличивающееся дерево решений](https://msdn.microsoft.com/library/azure/dn905801.aspx) |● |○ | |5 |Большой объем памяти |
| [квантильная регрессия быстрого леса](https://msdn.microsoft.com/library/azure/dn913093.aspx) |● |○ | |9 |Распределения, а не точечные прогнозы |
| [нейронная сеть](https://msdn.microsoft.com/library/azure/dn905924.aspx) |● | | |9 |[Возможна дополнительная настройка](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [регрессия Пуассона](https://msdn.microsoft.com/library/azure/dn905988.aspx) | | |● |5 |С технической точки зрения логлинейная. Для прогнозирования количества |
| [порядковая](https://msdn.microsoft.com/library/azure/dn906029.aspx) | | | |0 |Для прогнозирования упорядочения за рангом |
| **Обнаружение аномалий** | | | | | |
| [метод опорных векторов](https://msdn.microsoft.com/library/azure/dn913103.aspx) |○ |○ | |2 |Особенно полезна для больших наборов функций |
| [Обнаружение аномалий на основе анализа первичных компонентов](https://msdn.microsoft.com/library/azure/dn913102.aspx) | |○ |● |3 | |
| [K-средних](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/) | |○ |● |4. |Алгоритм кластеризации |

**Свойства алгоритма:**

**●** — показывает высокую точность, быстрое время обучения и использует линейность

**○** — показывает хорошую точность и умеренное время обучения

## <a name="algorithm-notes"></a>Примечания к алгоритму
### <a name="linear-regression"></a>Linear regression
Как упоминалось ранее, [линейная регрессия](https://msdn.microsoft.com/library/azure/dn905978.aspx) связывает с набором данных линию (либо плоскость или гиперплоскость). Это быстрая и простая "рабочая лошадка", но она может быть излишне простой для некоторых задач.
Руководство по линейной регрессии можно найти [здесь](linear-regression-in-azure.md).

![Данные с линейным трендом][3]

***Данные с линейным трендом***

### <a name="logistic-regression"></a>Логистическая регрессия
Несмотря на вводящее в заблуждение слово "регрессия" в названии, логистическая регрессия на самом деле является мощным инструментом [двухклассовой](https://msdn.microsoft.com/library/azure/dn905994.aspx) и [многоклассовой](https://msdn.microsoft.com/library/azure/dn905853.aspx) классификации. Это быстрый и простой метод. Тот факт, что в нем вместо прямой линии используется S-образная кривая, позволяет естественным образом использовать его для разделения данных на группы. Логистическая регрессия приводит к появлению линейных границ классов, поэтому при ее использовании убедитесь, что вам комфортно с линейной аппроксимацией.

![Логистическая регрессия для двухклассовых данных со всего одной функцией][4]

***Логистическая регрессия для двухклассовых данных со всего одной функцией*** *— граница класса является точкой, в которой логистическая кривая равноудалена от обоих классов*

### <a name="trees-forests-and-jungles"></a>Деревья, леса и джунгли
Леса решений ([регрессионные](https://msdn.microsoft.com/library/azure/dn905862.aspx), [двухклассовые](https://msdn.microsoft.com/library/azure/dn906008.aspx) и [многоклассовые](https://msdn.microsoft.com/library/azure/dn906015.aspx)), джунгли решений ([двухклассовые](https://msdn.microsoft.com/library/azure/dn905976.aspx) и [многоклассовые](https://msdn.microsoft.com/library/azure/dn905963.aspx)) и увеличивающиеся деревья решений ([регрессионные](https://msdn.microsoft.com/library/azure/dn905801.aspx) и [двухклассовые](https://msdn.microsoft.com/library/azure/dn906025.aspx)) основаны на деревьях решений, базовой концепции машинного обучения. Существует множество вариантов деревьев решений, но все они делают одно и то же: подразделяют пространство функций на области с преимущественно одинаковыми метками. Это могут быть области с одинаковой категорией или одинаковым значением в зависимости от того, проводится ли классификация или регрессия.

![Дерево решений подразделяет пространство функций][5]

***Дерево решений подразделяет пространство функций на области примерно c одинаковыми значениями.***

Так как пространство функций можно подразделить на регионы произвольного размера, легко представить такое разделение, при котором в одном регионе будет только одна точка данных. Это крайний пример чрезмерно высокой точности. Чтобы этого избежать, большие наборы деревьев создаются с особой математической осторожностью, чтобы деревья не коррелировали друг с другом. Средним для этого "леса решений" является дерево, что позволяет избежать чрезмерно высокой точности. Леса решений могут использовать большой объем памяти. Джунгли решений — это вариант, который используют меньший объем памяти за счет небольшого увеличения времени обучения.

В увеличивающихся деревьях решений во избежание чрезмерно высокой точности ограничиваются количество повторных делений и минимальное количество точек данных в каждом регионе. Алгоритм создает последовательность деревьев, каждое из которых учится компенсировать ошибки, оставленные предыдущим деревом. В результате мы получаем очень точный механизм обучения, который, как правило, использует большой объем памяти. Полное техническое описание см. в [исходном документе Фридмана](http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf).

[Квантильная регрессия быстрого леса](https://msdn.microsoft.com/library/azure/dn913093.aspx) является разновидностью дерева решений для особого случая, в котором вы хотите знать не только типичное (среднее) значение данных в пределах региона, но его распределение в виде квантилей.

### <a name="neural-networks-and-perceptrons"></a>Нейронные сети и восприятия
Нейронные сети — это алгоритмы обучения, вдохновленные устройством человеческого мозга, которые охватывают [многоклассовые](https://msdn.microsoft.com/library/azure/dn906030.aspx), [двухклассовые](https://msdn.microsoft.com/library/azure/dn905947.aspx) и [регрессионные](https://msdn.microsoft.com/library/azure/dn905924.aspx) задачи. Разнообразие нейронных сетей очень велико, но в машинном обучении Azure все они имеют форму направленного ациклического графа. Это означает, что входные функции передаются вперед (и только вперед) по последовательности слоев, после чего превращаются в выходные данные. В каждом слое входные функции взвешиваются в различных сочетаниях, суммируются и передаются на следующий уровень. Такое сочетание простых вычислений дает возможность как по волшебству изучать границы сложных классов и тренды данных. Многослойные сети такого типа выполняют "глубокое обучение", которое так широко представлено в технических отчетах и научно-фантастической литературе.

Но такая высокая производительность имеет и обратную сторону. На обучение нейронных сетей может уходить длительное время, особенно для больших наборов данных с большим количеством функций. Они также имеют больше параметров, чем большинство алгоритмов, что означает, что корректировка параметров значительно удлиняет время обучения.
А для тех, кто хочет превысить собственные достижения и [определить собственную структуру сети](http://go.microsoft.com/fwlink/?LinkId=402867), возможности нейронных сетей неисчерпаемы.

![Границы, изучаемые нейронными сетями][6]
***Границы, изучаемые нейронными сетями, могут быть сложными и нестандартными***

[Двухклассное усредненное восприятие](https://msdn.microsoft.com/library/azure/dn906036.aspx) — ответ нейронных сетей на огромное увеличение времени обучения. В нем используется структура сети, предоставляющая линейные границы класса. Она почти примитивна по сегодняшним стандартам, но имеет долгую историю надежной работы и достаточно мала для быстрого изучения.

### <a name="svms"></a>Методы опорных векторов
Методы опорных векторов находят границу, которая разделяет классы с как можно большей шириной. Если два класса нельзя четко разделить, алгоритмы найдут наилучшую границу, которую смогут. Как записано в Машинном обучении Azure, [двухклассовые методы опорных векторов](https://msdn.microsoft.com/library/azure/dn905835.aspx) делают это только для прямой линии. (В терминах методов опорных векторов, они используют линейное ядро.) Так как это выполняется с помощью линейной аппроксимации, время выполнения достаточно мало. Эти методы действительно проявляют себя с данными с большим количеством функций, такими как текст или генетические данные. В этих случаях методы опорных векторов позволяют разделить классы быстрее и с меньшей избыточной точностью, чем большинство других алгоритмов; кроме того, они используют небольшой объем памяти.

![Граница класса метода опорных векторов][7]

***Типичная граница класса для метода опорных векторов увеличивает ширину границы, разделяющей два класса.***

Другой продукт Microsoft Research, [двухклассовый локально глубокий метод опорных векторов](https://msdn.microsoft.com/library/azure/dn913070.aspx) , представляет собой нелинейный вариант метода опорных векторов, который сохраняет большую часть скорости и эффективного использования памяти линейной версии метода. Он идеально подходит для случаев, в которых линейный подход не дает достаточно точных результатов. Разработчики сохранили скорость метода путем разбиения задачи на несколько малых задач метода опорных векторов. Подробнее узнать о том, как они это сделали, можно в [полном описании](http://proceedings.mlr.press/v28/jose13.html) .

С помощью эффективного расширения нелинейных методов опорных векторов [одноклассовый метод опорных векторов](https://msdn.microsoft.com/library/azure/dn913103.aspx) проводит границу, которая плотно отделяет весь набор данных. Это удобно для обнаружения аномалий. Все новые точки данных, которые выходят далеко за эту границу, достаточно необычны, чтобы обратить на них внимание.

### <a name="bayesian-methods"></a>Методы Байеса
Методы Байеса имеют одно очень ценное качество: они не приводят к чрезмерному увеличению точности. Для этого они предварительно делают некоторые предположения о вероятном распределении ответа. Другим побочным эффектом этого подхода является то, что у этих методов очень мало параметров. В Машинном обучении Azure есть оба алгоритма Байеса для классификации ([двухклассная точечная машина Байеса](https://msdn.microsoft.com/library/azure/dn905930.aspx)) и регрессии ([линейная регрессия Байеса](https://msdn.microsoft.com/library/azure/dn906022.aspx)).
Обратите внимание, что в них предполагается, что данные можно разбить прямой линией или сопоставить ей.

С исторической точки зрения точечные машины Байеса были разработаны в Microsoft Research. За ними стоит исключительная теоретическая работа. Заинтересовавшиеся могут ознакомиться с [исходной статьей в JMLR](http://jmlr.org/papers/volume1/herbrich01a/herbrich01a.pdf) и [исчерпывающим блогом Криса Бишопа (Chris Bishop)](http://blogs.technet.com/b/machinelearning/archive/2014/10/30/embracing-uncertainty-probabilistic-inference.aspx).

### <a name="specialized-algorithms"></a>Специализированные алгоритмы
При наличии очень конкретной цели вам может повезти со специализированным алгоритмом. В коллекции машинного обучения Azure есть алгоритмы, которые специализируются на:

- прогнозировании ранжирования ([порядковая регрессия](https://msdn.microsoft.com/library/azure/dn906029.aspx));
- количественных прогнозах ([регрессия Пуассона](https://msdn.microsoft.com/library/azure/dn905988.aspx));
- обнаружении аномалий (на основе [анализа основных компонентов](https://msdn.microsoft.com/library/azure/dn913102.aspx) и на основе [метода опорных векторов](https://msdn.microsoft.com/library/azure/dn913103.aspx));
- кластеризации ([K-средних](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/)).

![Обнаружение аномалий на основе анализа первичных компонентов][8]

***Обнаружение аномалий на основе анализа первичных компонентов*** *— большинство данных попадает в стереотипное распределение; подозрительными считаются точки, которые значительно отклоняются от этого распределения*

![Набор данных, сгруппированный с использованием K-средних][9]

***Набор данных группируется в пять кластеров с использованием K-средних***

Также существует [многоклассовая классификация "один-все"](https://msdn.microsoft.com/library/azure/dn905887.aspx), которая разбивает проблему классификации класса N на проблемы двухклассовой классификации класса N-1. Точность, время обучения и свойства линейности определяются используемыми двухклассовыми классификаторами.

![Двухклассные классификаторы объединяются для получения трехклассного классификатора][10]

***Два двухклассовых классификатора объединяются вместе для получения трехклассового классификатора.***

Машинное обучение Azure также включает доступ к мощной платформе машинного обучения под названием [Vowpal Wabbit](https://msdn.microsoft.com/library/azure/8383eb49-c0a3-45db-95c8-eb56a1fef5bf).
Эта платформа пренебрегает приведенной здесь классификацией, так как может решать как классификационные, так и регрессионные задачи и даже обучаться на основе частично неразмеченных данных. Ее можно настроить для использования любого алгоритма обучения, любой функции потери и любого алгоритма оптимизации. Эта система изначально разрабатывалась как эффективная, параллельная и очень быстрая. Она обрабатывает огромные наборы функций с минимальными усилиями.
Запущенная и управляемая Джоном Лэнгфордом из Microsoft Research, Vowpal Wabbit — это "формула один" среди других алгоритмов. С помощью Vowpal Wabbit можно решить не все задачи, но если система подходит для вашей задачи, возможно, стоит потратить время на изучение интерфейса системы. Система также доступна в виде [автономного открытого исходного кода](https://github.com/JohnLangford/vowpal_wabbit) на нескольких языках.

## <a name="more-help-with-algorithms"></a>Дополнительная помощь с алгоритмами
* Сведения о скачиваемой инфографике с описанием алгоритмов и примерами см. в статье [Загружаемая инфографика по основам машинного обучения с примерами алгоритмов](basics-infographic-with-algorithm-examples.md).
* Список всех категорий алгоритмов, доступных в Студии машинного обучения Azure, см. в справке по алгоритмам и модулям Студии машинного обучения [Initialize Model][initialize-model] (Инициализация модели).
* Полный список всех алгоритмов и модулей машинного обучения, доступных в Студии машинного обучения, расположенных в алфавитном порядке, см. в справке по алгоритмам и модулям Студии машинного обучения [A-Z List of Machine Learning Studio Modules][a-z-list] (Полный список модулей Студии машинного обучения).
* Чтобы скачать и распечатать схему, на которой представлены общие возможности Студии машинного обучения Azure, см. [обзорную схему возможностей Студии машинного обучения Azure](studio-overview-diagram.md).


<!-- Reference links -->
[initialize-model]: https://msdn.microsoft.com/library/azure/dn905812.aspx
[a-z-list]: https://msdn.microsoft.com/library/azure/dn906033.aspx

<!-- Media -->

[1]: ./media/algorithm-choice/image1.png
[2]: ./media/algorithm-choice/image2.png
[3]: ./media/algorithm-choice/image3.png
[4]: ./media/algorithm-choice/image4.png
[5]: ./media/algorithm-choice/image5.png
[6]: ./media/algorithm-choice/image6.png
[7]: ./media/algorithm-choice/image7.png
[8]: ./media/algorithm-choice/image8.png
[9]: ./media/algorithm-choice/image9.png
[10]: ./media/algorithm-choice/image10.png
