---
title: Подготовка виртуальной машины Linux (Ubuntu) для обработки и анализа данных в Azure | Документация Майкрософт
description: Создание и настройка виртуальной машины Linux (Ubuntu) в Azure для обработки и анализа данных и машинного обучения.
services: machine-learning
documentationcenter: ''
author: bradsev
manager: cgronlun
ms.assetid: 3bab0ab9-3ea5-41a6-a62a-8c44fdbae43b
ms.service: machine-learning
ms.component: data-science-vm
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: conceptual
ms.date: 03/16/2018
ms.author: bradsev
ms.openlocfilehash: 18465463e924c10ddc35d619992655773e12cc82
ms.sourcegitcommit: e2adef58c03b0a780173df2d988907b5cb809c82
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2018
ms.locfileid: "32179713"
---
# <a name="provision-the-data-science-virtual-machine-for-linux-ubuntu"></a>Подготовка виртуальной машины Linux (Ubuntu) для обработки и анализа данных

Виртуальная машина для обработки и анализа данных для Linux — это образ виртуальной машины Azure на основе Ubuntu, который позволяет легко начать работу с машинным обучением, включая глубокое обучение. Доступны следующие инструменты глубокого обучения:

  * [Caffe](http://caffe.berkeleyvision.org/): платформа глубокого обучения, предназначенная для обеспечения скорости, выразительности и модульности.
  * [Caffe2](https://github.com/caffe2/caffe2): кроссплатформенная версия Caffe.
  * [Microsoft Cognitive Toolkit](https://github.com/Microsoft/CNTK): набор программных средств для глубокого обучения от Microsoft Research.
  * [H2O](https://www.h2o.ai/): платформа для больших данных с открытым исходным кодом и графический пользовательский интерфейс.
  * [Keras](https://keras.io/): API нейронной сети высокого уровня на языке Python для Theano и TensorFlow.
  * [MXNet](http://mxnet.io/): гибкая и эффективная библиотека глубокого обучения с множеством языковых привязок.
  * [NVIDIA DIGITS](https://developer.nvidia.com/digits): графическая система, которая упрощает выполнение распространенных задач глубокого обучения.
  * [PyTorch](http://pytorch.org/): высокоуровневая библиотека Python с поддержкой динамических сетей.
  * [TensorFlow](https://www.tensorflow.org/): библиотека с открытым исходным кодом для использования искусственного интеллекта от Google.
  * [Theano](http://deeplearning.net/software/theano/): библиотека Python для определения, оптимизации и эффективной оценки математических выражений с применением многомерных массивов.
  * [Torch](http://torch.ch/): платформа для научных расчетов с поддержкой разнообразных алгоритмов машинного обучения.
  * CUDA, cuDNN и драйвер NVIDIA.
  * Множество примеров объектов Jupyter Notebook.

Все библиотеки являются версиями для графического процессора, хотя они также работают при использовании центрального процессора.

Виртуальная машина Linux для обработки и анализа данных также содержит популярные инструменты для обработки и анализа данных, включая следующие:

* Microsoft R Server Developer Edition с Microsoft R Open
* Дистрибутив Anaconda Python (версий 2.7 и 3.5), включая популярные библиотеки для анализа данных.
* JuliaPro — проверенный дистрибутив на языке Julia с популярными библиотеками для обработки и анализа данных.
* Изолированный экземпляр Spark и кластер Hadoop (HDFS, Yarn) с одним узлом.
* JupyterHub — многопользовательский сервер Jupyter Notebook, поддерживающий ядра R, Python, PySpark и Julia.
* обозреватель хранилищ Azure
* Интерфейс командной строки Azure (Azure CLI) для управления ресурсами Azure.
* Инструменты машинного обучения
  * [Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit): система быстрого машинного обучения, поддерживающая такие методы, как онлайн-обучение, хэширование, общее сокращение, сокращение, обучение поиску, активное и интерактивное обучение.
  * [XGBoost](https://xgboost.readthedocs.org/en/latest/): инструмент, предоставляющий быструю и точную реализацию повышенного дерева.
  * [Rattle](http://rattle.togaware.com/): графический инструмент, который облегчает начало работы с анализом данных и машинным обучением в R.
  * [LightGBM](https://github.com/Microsoft/LightGBM): быстрая, распределенная и высокопроизводительная платформа для градиентного бустинга.
* Пакет SDK для Azure в Java, Python, node.js, Ruby и PHP
* Библиотеки R и Python для машинного обучения Azure и других служб Azure
* Средства разработки и редакторы (RStudio, PyCharm, IntelliJ, Emacs и vim).


Анализ данных включает выполнение следующих задач:

1. поиск, загрузка и предварительная обработка данных;
2. построение и тестирование моделей;
3. развертывание моделей для использования в приложениях для анализа.

Для выполнения этих задач специалисты по обработке и анализу данных используют широкий набор инструментов. Поиск подходящей версии программного обеспечения и его последующее скачивание, компиляция и установка могут занимать довольно много времени.

Виртуальная машина Linux для обработки и анализа данных может существенно упростить выполнение этих задач. Используйте ее, чтобы быстро начать работу со своим аналитическим проектом. Она позволяет работать над задачами, используя различные языки, включая R, Python, SQL, Java и C++. Пакет SDK для Azure в виртуальной машине позволяет создавать приложения с помощью различных служб в Linux для облачной платформы Майкрософт. Кроме того, доступны другие языки, такие как Ruby, Perl, PHP и node.js, которые также предварительно установлены.

Плата за программное обеспечение для этого образа виртуальной машины не взимается. Вы платите только за оборудование Azure в зависимости от размера виртуальной машины, которая подготавливается. Дополнительные сведения о плате за вычисления можно найти в [списке виртуальных машин на сайте Azure Marketplace](https://azure.microsoft.com/marketplace/partners/microsoft-ads/linux-data-science-vm/).

## <a name="other-versions-of-the-data-science-virtual-machine"></a>Другие версии виртуальных машин для обработки и анализа данных
Также доступен образ [CentOS](linux-dsvm-intro.md), который содержит большинство инструментов, входящих в образ Ubuntu. Также доступен образ [Windows](provision-vm.md).

## <a name="prerequisites"></a>предварительным требованиям
Перед созданием виртуальной машины Linux для обработки и анализа данных необходимо убедиться в наличии подписки Azure. Сведения о ее получении см. на странице [создания бесплатной учетной записи Azure](https://azure.microsoft.com/free/).

## <a name="create-your-data-science-virtual-machine-for-linux"></a>Создание виртуальной машины Linux для обработки и анализа данных
Ниже приведены шаги по созданию экземпляра виртуальной машины Linux для обработки и анализа данных.

1. Перейдите к списку виртуальных машин на [портале Azure](https://portal.azure.com/#create/microsoft-ads.linux-data-science-vm-ubuntulinuxdsvmubuntu).
2. В нижней части страницы нажмите кнопку **Создать**. Откроется мастер.![configure-data-science-vm](./media/dsvm-ubuntu-intro/configure-data-science-virtual-machine.png)
3. В следующих разделах приведены входные данные для всех шагов мастера (номера см. справа на предыдущем рисунке) по созданию виртуальной машины Майкрософт для обработки и анализа данных. Ниже приведено описание входных данных, необходимых для настройки на каждом из шагов.
   
   a. **Основные сведения**:
   
   * **Имя**— имя создаваемого сервера для обработки и анализа данных.
   * **Имя пользователя**— идентификатор для входа первой учетной записи.
   * **Пароль**— пароль первой учетной записи (вместо пароля можно использовать открытый ключ SSH).
   * **Подписка**— при наличии нескольких подписок выберите ту, в которой будет создана виртуальная машина и для которой будет взиматься плата. Вам необходимо иметь права на создание ресурсов для этой подписки.
   * **Группа ресурсов**— вы можете создать новую группу или использовать существующую.
   * **Расположение**— выберите наиболее подходящий центр обработки данных. Обычно это центр обработки данных, в котором размещена большая часть ваших данных, или ближайший к вашему физическому расположению центр для наиболее быстрого доступа к сети.
   
   Б. **Размер**:
   
   * Выберите один из типов серверов, который соответствует вашим функциональным требованиям и финансовым ограничениям. Выберите **Просмотреть все** , чтобы отобразить дополнительные варианты размеров виртуальных машин. Для обучения работе с GPU выберите виртуальную машину класса NC или ND. На странице [Доступность продуктов по регионам](https://azure.microsoft.com/global-infrastructure/services/) перечислены регионы, для которых поддерживается использование GPU.
   
   c. **Параметры**:
   
   * **Тип диска** — выберите **Премиум**, если требуется твердотельный накопитель (SSD). В противном случае выберите тип **Стандартный**. Для виртуальных машин, работающих с графическим процессором, требуется диск уровня "Стандартный".
   * **Учетная запись хранения** — вы можете создать учетную запись хранения Azure в подписке или использовать существующую учетную запись в расположении, которое было выбрано на этапе работы мастера **Основные сведения**.
   * **Другие параметры**— в большинстве случаев используются значения по умолчанию. Чтобы использовать значения, отличные от значений по умолчанию, наведите указатель мыши на информационную ссылку, чтобы получить справку по конкретному полю.
   
   d. **Сводка**:
   
   * Проверьте, все ли сведения введены правильно.
   
   д. **Купить**:
   
   * Чтобы начать подготовку, щелкните **Купить**. Отобразится ссылка на условия транзакции. За использование виртуальной машины не взимается дополнительная плата, кроме платы за размер сервера, выбранный на шаге **Размер** .

Подготовка занимает примерно 5–10 минут. Состояние подготовки отображается на портале Azure.

## <a name="how-to-access-the-data-science-virtual-machine-for-linux"></a>Как осуществить доступ к виртуальной машине Linux для обработки и анализа данных

Получить доступ к DSVM Ubuntu можно тремя методами.
1. SSH для сеансов терминала
2. X2Go для графических сеансов
3. JupyterHub и JupyterLab для записных книжек Jupyter

### <a name="ssh"></a>SSH

После создания виртуальной машины вы можете войти в нее с помощью протокола SSH. Для входа с помощью интерфейса текстовой оболочки используйте учетную запись, созданную в разделе **Основные сведения** на шаге 3. В Windows можно скачать клиент SSH, например [Putty](http://www.putty.org). Если вы предпочитаете графический рабочий стол (система X Windows), можете использовать перенаправление X11 в Putty или установить клиент X2Go.

> [!NOTE]
> При тестировании клиент X2Go работал лучше по сравнению с перенаправлением X11. Мы рекомендуем клиент X2Go для графического интерфейса рабочего стола.
> 
> 

### <a name="x2go"></a>X2Go
Виртуальная машина Linux уже подготовлена на сервере X2Go и готова к приему подключений клиента. Для подключения к графическому рабочему столу виртуальной машины Linux выполните следующую процедуру на клиенте.

1. Скачайте клиент X2Go для своей клиентской платформы [отсюда](http://wiki.x2go.org/doku.php/doc:installation:x2goclient)и установите его.    
2. Запустите клиент X2Go и выберите **Новая сессия**. Откроется окно конфигурации с несколькими вкладками. Введите следующие параметры конфигурации:
   * **Вкладка "Сеанс"**:
     * **Хост**— имя узла или IP-адрес виртуальной машины Linux для обработки и анализа данных.
     * **Пользователь**— имя пользователя на виртуальной машине Linux.
     * **Порт SSH**: оставьте 22 (значение по умолчанию).
     * **Тип сеанса**: измените значение на XFCE. В настоящее время виртуальная машина Linux поддерживает только рабочий стол XFCE.
   * **Вкладка "Мультимедиа"**: здесь можно отключить поддержку звука и печати на клиенте, если они не нужны.
   * **Общие папки**: если вы хотите смонтировать каталоги клиентских компьютеров на виртуальной машине Linux, добавьте необходимые каталоги на этой вкладке.

После входа в виртуальную машину с помощью клиента SSH или подключения к рабочему столу XFCE посредством клиента X2Go можно начать использовать инструменты, которые установлены и настроены на виртуальной машине. На рабочем столе XFCE вы видите ярлыки из меню и значки рабочего стола для многих инструментов.

### <a name="jupyterhub-and-jupyterlab"></a>JupyterHub и JupyterLab

Ubuntu DSVM работает на базе [JupyterHub](https://github.com/jupyterhub/jupyterhub), многопользовательского сервера Jupyter. Чтобы подключиться, перейдите к https://your-vm-ip:8000 на своем ноутбуке или настольном компьютере, введите имя пользователя и пароль, использованные для создания виртуальной машины, и войдите в систему. Для просмотра и испытания доступно много примеров записных книжек.

Кроме того, доступен JupyterLab, следующее поколение записных книжек Jupyter, и JupyterHub. Чтобы получить к нему доступ, войдите в JupyterHub, затем перейдите по URL-адресу https://your-vm-ip:8000/lab. JupyterLab можно установить в качестве сервера записных книжек по умолчанию, добавив эту строку в каталог /etc/jupyterhub/jupyterhub_config.py:

    c.Spawner.default_url = '/lab'

## <a name="tools-installed-on-the-data-science-virtual-machine-for-linux"></a>Инструменты, установленные на виртуальной машине Linux для обработки и анализа данных
### <a name="deep-learning-libraries"></a>Библиотеки глубокого обучения

#### <a name="cntk"></a>CNTK
Набор средств Microsoft Cognitive Toolkit имеет открытый исходный код и предназначен для глубокого обучения. Привязки Python доступны в корневой среде и в средах Conda для Python 3.5 (py35). В набор также входит программа командной строки (cntk), которая уже добавлена в переменную PATH.

Примеры объектов Python Notebook доступны в JupyterHub. Чтобы запустить в командной строке простой пример, выполните следующие команды в оболочке:

    cd /home/[USERNAME]/notebooks/CNTK/HelloWorld-LogisticRegression
    cntk configFile=lr_bs.cntk makeMode=false command=Train

Дополнительные сведения см. в разделе CNTK на сайте [GitHub](https://github.com/Microsoft/CNTK) и на [вики-сайте CNTK](https://github.com/Microsoft/CNTK/wiki).

#### <a name="caffe"></a>Caffe
Caffe — это платформа глубокого обучения из Berkeley Vision и центра обучения. Она доступна в папке /opt/caffe. Примеры находятся в папке /opt/caffe/examples.

#### <a name="caffe2"></a>Caffe2
Caffe2 — это платформа глубокого обучения от Facebook на основе Caffe. Она доступна на Python 2.7 корневой среде Conda. Для активации выполните следующую команду из оболочки:

    source /anaconda/bin/activate root

Некоторые примеры объектов Notebook доступны в JupyterHub.

#### <a name="h2o"></a>H2O
H2O — это быстрая распределенная платформа, работающая в памяти, для машинного обучения и прогнозной аналитики. Пакет Python установлен в корневой среде и в средах Anaconda для Python 3.5 (py35). Также установлен пакет R. Для запуска H2O из командной строки запустите `java -jar /dsvm/tools/h2o/current/h2o.jar`. Имеется множество [параметров командой строки](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/starting-h2o.html#from-the-command-line), которые можно настроить. Чтобы получить доступ к веб-интерфейсу Flow, перейдите по адресу http://localhost:54321 для начала работы. Примеры объектов Notebook доступны в JupyterHub.

#### <a name="keras"></a>Keras
Keras — это интерфейс API нейронной сети высокого уровня на языке Python, который может выполняться на платформе TensorFlow или Theano. Она доступна в корневой среде и в средах Python 3.5 (py35). 

#### <a name="mxnet"></a>MXNet
MXNet — это платформа глубокого обучения, предназначенная для обеспечения эффективности и гибкости. Она имеет привязки R и Python, входящие в состав DSVM. Примеры объектов Notebook доступны в JupyterHub, а пример кода доступен в папке /dsvm/samples/mxnet.

#### <a name="nvidia-digits"></a>NVIDIA DIGITS
Система обучения работе с графическим процессором на базе глубокого обучения NVIDIA, также известная как DIGITS, — это система, которая упрощает выполнение распространенных задач глубокого обучения, таких как управление данными, разработка и обучение нейронных сетей в системах с графическими процессорами, а также мониторинг производительности в режиме реального времени с помощью расширенного представления. 

Система DIGITS доступна в виде службы, которая также называется Digits. Чтобы начать, запустите службу и перейдите к http://localhost:5000.

Служба DIGITS также установлена как модуль Python в корневой среде Conda.

#### <a name="tensorflow"></a>TensorFlow
TensorFlow — это библиотека глубокого обучения от Google. Она является библиотекой программного обеспечения с открытым исходным кодом для числовых вычислений с применением графиков потоков данных. TensorFlow доступен в среде Python 3.5 (py35), а несколько примеров объектов Notebook доступно в JupyterHub.

#### <a name="theano"></a>Theano
Theano — это библиотека Python для эффективных численных вычислений. Она доступна в корневой среде и в средах Python 3.5 (py35). 

#### <a name="torch"></a>Torch
Torch — это платформа для научных расчетов с поддержкой разнообразных алгоритмов машинного обучения. Она доступна в папке /dsvm/tools/torch, а интерактивный сеанс и диспетчер пакетов LuaRocks доступны из командной строки. Примеры доступны в папке /dsvm/samples/torch.

Платформа PyTorch также доступна в корневой среде Anaconda. Примеры доступны в папке /dsvm/samples/pytorch.

### <a name="microsoft-r-server"></a>Microsoft R Server
R — один из самых популярных языков для анализа данных и машинного обучения. Если вы хотите использовать R для анализа, то воспользуйтесь установленной на виртуальной машине платформой Microsoft R Server (MRS) с компонентом Microsoft R Open (MRO) и библиотекой Math Kernel Library (MKL). Библиотека MKL оптимизирует математические операции, которые широко применяются в аналитических алгоритмах. MRO полностью совместим с CRAN-R, и любые библиотеки R, опубликованные в CRAN, можно установить в MRO. MRS обеспечивает масштабирование и ввод в эксплуатацию моделей R, преобразованных в веб-службы. Для редактирования программ R можно воспользоваться одним из редакторов по умолчанию, например RStudio, vi или Emacs. Если вы предпочитаете использовать редактор Emacs, то он предварительно установлен. Пакет ESS (Emacs Speaks Statistics) упрощает работу с файлами R в редакторе Emacs.

Чтобы запустить консоль R, просто введите **R** в оболочке. Откроется интерактивная среда. Для разработки программы R обычно используется редактор, такой как Emacs или vi, а затем сценарии запускаются в R. RStudio предоставляет полноценную графическую интегрированную среду разработки для программ R.

При желании для установки [20 самых популярных пакетов R](http://www.kdnuggets.com/2015/06/top-20-r-packages.html) можно воспользоваться R-скриптом. Этот сценарий можно запустить в интерактивном интерфейсе R, для подключения к которому, как уже упоминалось, необходимо ввести **R** в оболочке.  

### <a name="python"></a>Python
Anaconda Python устанавливается вместе со средой Python 2.7 и 3.5. Среда версии 2.7 называется _root_, а среда версии 3.5 — _py35_. Этот дистрибутив содержит базовую версию Python, а также примерно 300 наиболее популярных математических и инженерных пакетов и пакетов аналитики данных. 

Среда py35 устанавливается по умолчанию. Чтобы активировать среду root (2.7):

    source activate root

Чтобы снова активировать среду py35:

    source activate py35

Чтобы вызвать интерактивный сеанс python, просто введите **python** в оболочке. 

Установите дополнительные библиотеки Python с помощью ```conda``` или ````pip````. Сначала активируйте правильную среду для pip, если не хотите использовать среду по умолчанию:

    source activate root
    pip install <package>

Или укажите полный путь к pip:

    /anaconda/bin/pip install <package>
    
Для conda всегда следует указывать имя среды (_py35_ или _root_):

    conda install <package> -n py35

Если вы используете графический интерфейс или перенаправление X11, то можете ввести команду **pycharm** для запуска интегрированной среды разработки PyCharm Python. Можно использовать текстовые редакторы по умолчанию. Кроме того, можно использовать Spyder, интегрированную среду разработки Python, которая входит в состав дистрибутива Anaconda Python. Для Spyder необходим графический рабочий стол или перенаправление X11. Ярлык для Spyder предусмотрен в графических рабочих столах.

### <a name="jupyter-notebook"></a>Записная книжка Jupyter
Дистрибутив Anaconda также содержит записную книжку Jupyter, среду для совместного использования кода и анализа. Доступ к записной книжке Jupyter можно получить через JupyterHub. Для входа используйте учетные данные локального пользователя Linux.

На сервере записной книжки Jupyter предварительно настроена поддержка ядер Python 2, Python 3 и R. На рабочем столе есть значок "Записная книжка Jupyter", с помощью которого можно запустить браузер для доступа к серверу записной книжки. Если вы подключаетесь к виртуальной машине с помощью клиента SSH или X2Go, то к серверу Jupyter Notebook можно обратиться по адресу [https://localhost:8000/](https://localhost:8000/).

> [!NOTE]
> При появлении любых предупреждений о сертификатах нажмите кнопку "Продолжить".
> 
> 

Сервер записной книжки Jupyter доступен с любого узла. Просто введите адрес *https://\<DNS-имя_или_IP-адрес_виртуальной_машины\>:8000/*

> [!NOTE]
> Когда виртуальная машина подготавливается, на брандмауэре по умолчанию открывается порт 8000.
> 
> 

Мы добавили по одному примеру записной книжки для Python и R. Ссылки на примеры можно найти на домашней странице записной книжки, войдя в записную книжку Jupyter с помощью учетных данных локального пользователя Linux. Для создания новой записной книжки нажмите кнопку **Создать**, а затем укажите соответствующий язык ядра. Если вы не видите кнопки **Создать**, щелкните значок **Jupyter** в верхнем левом углу, чтобы перейти на домашнюю страницу сервера записной книжки.

### <a name="apache-spark-standalone"></a>Изолированный экземпляр Apache Spark 
Изолированный экземпляр Apache Spark предустановлен на виртуальной машине Linux для обработки и анализа данных, что поможет вам разрабатывать приложения Spark локально перед тестированием и развертыванием в крупных кластерах. Программы PySpark можно выполнять через ядро Jupyter. При открытии Jupyter и нажатии кнопки **Создать** отображается список доступных ядер. Spark-Python — это ядро PySpark, которое позволяет создавать приложения Spark с использованием языка Python. Также можно использовать интегрированную среду разработки Python, такую как PyCharm или Spyder, для создания своей программы Spark. Так как это изолированный экземпляр, то стек Spark работает в вызывающей клиентской программе. Это позволяет быстрее и проще устранять неполадки, если сравнивать с разработкой в кластере Spark. 

Пример объекта Notebook PySpark, предоставляемый на Jupyter, можно найти в каталоге SparkML корневого каталога Jupyter ($HOME/notebooks/SparkML/pySpark). 

Если вы программируете на R для Spark, то можете использовать Microsoft R Server, SparkR или sparklyr. 

Перед запуском в контексте Spark на Microsoft R Server необходимо выполнить одноразовую настройку для включения локального кластера Hadoop HDFS с одним узлом и экземпляра Yarn. По умолчанию на виртуальной машине для обработки и анализа данных службы Hadoop установлены, но отключены. Чтобы их включить, при первом использовании необходимо выполнить следующие команды в качестве корня:

    echo -e 'y\n' | ssh-keygen -t rsa -P '' -f ~hadoop/.ssh/id_rsa
    cat ~hadoop/.ssh/id_rsa.pub >> ~hadoop/.ssh/authorized_keys
    chmod 0600 ~hadoop/.ssh/authorized_keys
    chown hadoop:hadoop ~hadoop/.ssh/id_rsa
    chown hadoop:hadoop ~hadoop/.ssh/id_rsa.pub
    chown hadoop:hadoop ~hadoop/.ssh/authorized_keys
    systemctl start hadoop-namenode hadoop-datanode hadoop-yarn

Вы можете остановить работу связанных служб Hadoop, когда они не нужны, выполнив следующую команду: ````systemctl stop hadoop-namenode hadoop-datanode hadoop-yarn```` Пример, демонстрирующий, как разрабатывать и тестировать с использованием MRS в удаленном контексте Spark (являющимся изолированным экземпляром Spark на виртуальной машине для обработки и анализа данных), доступен в каталоге `/dsvm/samples/MRS`. 

### <a name="ides-and-editors"></a>Интегрированные среды разработки и редакторы
Для выбора доступны несколько редакторов кода. В частности, vi/VIM, Emacs, PyCharm, RStudio и IntelliJ. IntelliJ, RStudio и PyCharm — графические редакторы, и для их использования необходимо войти в графический рабочий стол. На рабочем столе есть меню и значки для запуска этих редакторов.

**VIM** и **Emacs** — текстовые редакторы. В Emacs мы установили пакет надстройки ESS, который упрощает работу с R в редакторе Emacs. Дополнительные сведения см. в описании пакета [ESS](http://ess.r-project.org/).

**LaTex** устанавливается с помощью пакета texlive вместе с пакетом надстройки Emacs [auctex](https://www.gnu.org/software/auctex/manual/auctex/auctex.html) , который упрощает создание документов LaTex в Emacs.  

### <a name="databases"></a>Базы данных

#### <a name="graphical-sql-client"></a>Графический клиент SQL
Для подключения к различным базам данных (Microsoft SQL Server и MySQL) и для выполнения SQL-запросов предоставлен графический клиент SQL — **SQuirrel SQL**. Его можно запустить в графическом рабочем столе (например, с помощью клиента X2Go). Для запуска SQuirrel SQL можно воспользоваться значком на рабочем столе или выполнить следующую команду в оболочке.

    /usr/local/squirrel-sql-3.7/squirrel-sql.sh

Перед первым применением настройте драйверы и псевдонимы базы данных. Драйверы JDBC расположены в каталоге:

*/usr/share/java/jdbcdrivers*

Дополнительные сведения см. в разделе [SQuirrel SQL](http://squirrel-sql.sourceforge.net/index.php?page=screenshots).

#### <a name="command-line-tools-for-accessing-microsoft-sql-server"></a>Программы командной строки для доступа к Microsoft SQL Server
В пакете драйвера ODBC для SQL Server также содержатся две программы командной строки.

**bcp**— это служебная программа для массового копирования данных между экземпляром Microsoft SQL Server и файлом данных в любом пользовательском формате. С помощью служебной программы bcp можно выполнять импорт большого количества новых строк в таблицы SQL Server или экспорт данных из таблиц в файлы данных. Чтобы импортировать данные в таблицу, необходимо использовать файл форматирования, созданный для этой таблицы, или изучить структуру таблицы и типы данных для ее столбцов.

Дополнительную информацию см. в статье [Соединение с помощью bcp](https://msdn.microsoft.com/library/hh568446.aspx).

Служебная программа **sqlcmd** позволяет выполнять из командной строки инструкции Transact-SQL, системные процедуры и файлы сценариев. Эта программа использует ODBC для выполнения пакетов Transact-SQL.

Дополнительную информацию см. в статье [Соединение с помощью sqlcmd](https://msdn.microsoft.com/library/hh568447.aspx).

> [!NOTE]
> Версии этой служебной программы для платформ Windows и Linux немного отличаются. Дополнительные сведения см. в документации по .
> 
> 

#### <a name="database-access-libraries"></a>Библиотеки для доступа к базам данных
В Python и R доступны библиотеки для доступа к базам данных.

* Для языка R: пакеты **RODBC** и **dplyr** позволяют выполнять на сервере базы данных запросы и инструкции SQL.
* Для Python: библиотека **pyodbc** предоставляет доступ к базе данных с использованием ODBC в качестве базового уровня.  

### <a name="azure-tools"></a>Инструменты Azure
На виртуальной машине установлены следующие инструменты Azure:

* **Интерфейс командной строки Azure** позволяет создавать ресурсы Azure и управлять ими с помощью команд оболочки. Для вызова инструментов Azure просто введите **azure help**. Дополнительные сведения см. на [странице документации по Azure CLI](https://docs.microsoft.com/cli/azure/get-started-with-az-cli2).
* **Microsoft Azure Storage Explorer**— это графический инструмент, который позволяет просматривать объекты, сохраненные в учетной записи хранения Azure, а также передавать и скачивать данные больших двоичных объектов Azure. Для доступа к обозревателю хранилищ воспользуйтесь значком рабочего стола. Его можно открыть из командной строки, введя **StorageExplorer**. Для этого необходимо выполнить вход в клиенте X2Go или настроить перенаправление X11.
* **Библиотеки Azure**. Ниже приведены некоторые предварительно установленные библиотеки.
  
  * **Python**. Среди установленных библиотек Python к Azure имеют отношение **azure**, **azureml**, **pydocumentdb** и **pyodbc**. Первые три библиотеки позволяют обращаться к службам хранилища Azure, Машинному обучению Azure и Azure Cosmos DB (база данных NoSQL в Azure). Четвертая библиотека, pyodbc, (вместе с драйвером Microsoft ODBC для SQL Server) обеспечивает доступ к SQL Server, Базе данных SQL Azure и хранилищу данных SQL Azure из Python с помощью интерфейса ODBC. Для просмотра всех перечисленных библиотек введите команду **pip list**. Выполните эту команду как в среде Python версии 2.7, так и в среде Python версии 3.5.
  * **R**. Среди установленных библиотек R к Azure имеют отношение **AzureML** и **RODBC**.
  * **Java**. Список библиотек Java для Azure можно найти в каталоге **/dsvm/sdk/AzureSDKJava** на виртуальной машине. Основные библиотеки — это API-интерфейсы для службы хранилища Azure и API-интерфейсы для управления Azure, драйверы Azure Cosmos DB и драйверы JDBC для SQL Server.  

[Портал Azure](https://portal.azure.com) можно открыть в предустановленном браузере Firefox. На портале Azure можно создавать ресурсы Azure, а также управлять ими и отслеживать их.

### <a name="azure-machine-learning"></a>Машинное обучение Azure
Машинное обучение Azure — полностью управляемая облачная служба, которая позволяет легко создавать, развертывать решения прогнозной аналитики и предоставлять к ним общий доступ. В Студии машинного обучения Azure можно создавать свои эксперименты и модели. Ее можно открыть из браузера на виртуальной машине для обработки и анализа данных, перейдя в раздел [Машинное обучение Microsoft Azure](https://studio.azureml.net).

После входа в Студию машинного обучения Azure откроется холст для экспериментов, на котором вы можете создать логическую блок-схему алгоритмов машинного обучения. Вам также доступна записная книжка Jupyter, размещенная в Машинном обучении Azure, и вы можете легко работать с экспериментами в Студии машинного обучения. Вы можете ввести в эксплуатацию созданные модели машинного обучения, упаковав их в интерфейс веб-службы. Это позволяет клиентам, написанным на любом языке, получать прогнозы из моделей машинного обучения. Дополнительные сведения см. в [документации по машинному обучению](https://azure.microsoft.com/documentation/services/machine-learning/).

Можно также создавать модели в R или Python на виртуальной машине, а затем развертывать их в рабочей среде в Машинном обучении Azure. Мы установили библиотеки в R (**AzureML**) и Python (**azureml**), которые позволят выполнить эти действия.

Сведения о развертывании моделей R и Python в Машинном обучении Azure см. в разделе "Создание моделей с помощью R или Python и их ввод в эксплуатацию с помощью машинного обучения Azure" статьи [10 задач, которые можно выполнить в виртуальной машине для обработки и анализа данных](vm-do-ten-things.md).

> [!NOTE]
> Эти инструкции были написаны для Windows-версии виртуальной машины для обработки и анализа данных. Но приведенная информация о развертывании моделей в Машинном обучении Azure также применима к виртуальной машине Linux.
> 
> 

### <a name="machine-learning-tools"></a>Инструменты машинного обучения
В состав виртуальной машины входят некоторые инструменты и алгоритмы машинного обучения, которые были предварительно скомпилированы и установлены локально. в частности такие:

* **Vowpal Wabbit**— алгоритм быстрого онлайн-обучения.
* **xgboost**— инструмент, предоставляющий оптимизированные алгоритмы повышенного дерева.
* **Rattle**: графический инструмент на основе R, который облегчает просмотр данных и моделирование.
* **Python**— в Anaconda Python алгоритмы машинного обучения содержатся в разных библиотеках, например Scikit-learn. С помощью команды `pip install` можно установить другие библиотеки.
* **LightGBM**: быстрая, распределенная и высокопроизводительная платформа для градиентного бустинга, основанная на алгоритмах дерева решений.
* **R** — для R существует обширный набор функций машинного обучения. В число предустановленных входят библиотеки lm, glm, randomForest и rpart. Другие библиотеки можно установить, выполнив приведенную ниже команду.
  
        install.packages(<lib name>)

Вот некоторые дополнительные сведения о первых трех инструментах машинного обучения в списке.

#### <a name="vowpal-wabbit"></a>Vowpal Wabbit
Vowpal Wabbit — это система машинного обучения, поддерживающая такие методы, как онлайн-обучение, хэширование, общее сокращение, сокращение, обучение поиску, активное и интерактивное обучение.

Для запуска инструмента с простым примером сделайте следующее:

    cp -r /dsvm/tools/VowpalWabbit/demo vwdemo
    cd vwdemo
    vw house_dataset

В этом каталоге есть и другие примеры, большего размера. Дополнительные сведения о VW см. в [этом разделе GitHub](https://github.com/JohnLangford/vowpal_wabbit) и на [вики-сайте Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit/wiki).

#### <a name="xgboost"></a>XGBoost
Это библиотека, разработанная и оптимизированная для алгоритмов увеличивающегося дерева. Цель этой библиотеки — сдвинуть вычислительные ограничения виртуальных машин до пределов, необходимых для получения повышенного дерева большого размера, которое является масштабируемым, переносимым и точным.

Эта библиотека, так же как и библиотека R, предоставляется в виде оболочки командной строки.

Чтобы использовать эту библиотеку в R, запустите интерактивный сеанс R (просто введя **R** в оболочке) и загрузите библиотеку.

Ниже приведен простой пример, который можно запустить в командной строке R:

    library(xgboost)

    data(agaricus.train, package='xgboost')
    data(agaricus.test, package='xgboost')
    train <- agaricus.train
    test <- agaricus.test
    bst <- xgboost(data = train$data, label = train$label, max.depth = 2,
                    eta = 1, nthread = 2, nround = 2, objective = "binary:logistic")
    pred <- predict(bst, test$data)

Для запуска командной строки xgboost выполните следующие команды в оболочке.

    cp -r /dsvm/tools/xgboost/demo/binary_classification/ xgboostdemo
    cd xgboostdemo
    xgboost mushroom.conf


Файл .model записывается в указанный каталог. Дополнительную информацию об этом примере см. [на сайте GitHub](https://github.com/dmlc/xgboost/tree/master/demo/binary_classification).

Дополнительные сведения об xgboost см. на [странице документации по xgboost](https://xgboost.readthedocs.org/en/latest/) и в соответствующем [репозитории GitHub](https://github.com/dmlc/xgboost).

#### <a name="rattle"></a>Rattle;
Rattle (**R** **A**nalytical **T**ool **T**o **L**earn **E**asily, аналитический инструмент R для легкого обучения) использует изучение и моделирование данных на основе графического пользовательского интерфейса. Он предоставляет статистические и визуальные сводные данные, преобразует данные для удобного моделирования, создает контролируемые и неконтролируемые модели на основе данных, показывает производительность моделей в графическом виде и оценивает новые наборы данных. Он также формирует код R, соответствующий операциям в пользовательском интерфейсе. Этот код можно запустить непосредственно в R или использовать в качестве отправной точки для дальнейшего анализа.

Для запуска Rattle необходимо войти в сеанс графического рабочего стола. В терминале введите ```R``` для запуска среды R. В командной строке R введите следующие команды.

    library(rattle)
    rattle()

Откроется графический интерфейс с набором вкладок. Вот список действий в Rattle, которые позволят быстро построить модель на основе примера погодных данных. В некоторых действиях будет предложено автоматически скачать и установить необходимые пакеты R, которые еще не установлены в системе.

> [!NOTE]
> Если у вас нет разрешений на установку пакета в системном каталоге (по умолчанию), то в окне консоли R может появиться запрос на установку пакетов в вашей персональной библиотеке. Ответьте *y* (да) на все эти запросы.
> 
> 

1. Нажмите **Execute (Выполнить)**.
2. Откроется диалоговое окно с вопросом, хотите ли вы использовать пример погодных данных. Нажмите кнопку **Yes** (Да), чтобы загрузить пример.
3. Перейдите на вкладку **Model** (Модель).
4. Нажмите кнопку **Execute** (Выполнить) для построения дерева принятия решений.
5. Нажмите кнопку **Draw** (Нарисовать) для отображения дерева принятия решений.
6. Щелкните переключатель **Forest** (Лес) и нажмите кнопку **Execute** (Выполнить) для создания случайного леса.
7. Перейдите на вкладку **Evaluate** (Оценка).
8. Щелкните переключатель **Risk** (Риск) и нажмите кнопку **Execute** (Выполнить) для отображения двух диаграмм производительности "Risk (Cumulative)" (Риск (накопительный)).
9. Щелкните вкладку **Log** (Журнал), чтобы показать код R, созданный для предыдущих операций.
   (Из-за ошибки в текущем выпуске Rattle необходимо вставить знак *#* перед строкой *Export this log…* (Экспортировать этот файл журнала…) в тексте журнала).
10. Нажмите кнопку **Export** (Экспортировать), чтобы сохранить файл R-скрипт под именем *weather_script.R* в домашней папке.

Закройте Rattle и R. Теперь можно изменить созданный R-скрипт или запустить его в любое удобное время для повторения всех действий, которые были выполнены в пользовательском интерфейсе Rattle. Это простой способ (особенно для новичков в R) быстро выполнить анализ и машинное обучение в простом графическом интерфейсе с автоматическим созданием кода на R для изменения и (или) изучения.

## <a name="next-steps"></a>Дополнительная информация
Вот как можно продолжить обучение и изучение.

* В пошаговом руководстве [Обработка и анализ данных с использованием специально подготовленной виртуальной машины Linux](linux-dsvm-walkthrough.md) описаны способы выполнения распространенных задач обработки и анализа данных с помощью подготовленной виртуальной машины Linux. 
* Изучите различные средства обработки и анализа данных на виртуальной машине, используя средства, описанные в этой статье. Кроме того, можно выполнить команду *dsvm-more-info* в оболочке на виртуальной машине, чтобы получить базовые сведения и ссылки на дополнительные сведения об инструментах, которые установлены на виртуальной машине.  
* Изучите систематический подход к созданию комплексных аналитических решений с помощью [группового процесса обработки и анализа данных](https://azure.microsoft.com/documentation/learning-paths/cortana-analytics-process/).
* Перейдите в [коллекцию Cortana Analytics](http://gallery.cortanaanalytics.com) , чтобы найти примеры машинного обучения и анализа данных с использованием Cortana Analytics Suite.

