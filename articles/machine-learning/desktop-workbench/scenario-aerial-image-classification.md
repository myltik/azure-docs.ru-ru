---
title: Классификация изображений аэрофотосъемки | Документация Майкрософт
description: Содержит инструкции для реального сценария классификации изображений аэрофотосъемки.
author: mawah
ms.author: mawah
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.topic: article
ms.service: machine-learning
ms.component: desktop-workbench
services: machine-learning
ms.workload: data-services
ms.date: 12/13/2017
ms.openlocfilehash: d34f25fd75816f0ae840b3cbb2e0e88cbc2bfd91
ms.sourcegitcommit: 944d16bc74de29fb2643b0576a20cbd7e437cef2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/07/2018
ms.locfileid: "34832413"
---
# <a name="aerial-image-classification"></a>Классификация изображений аэрофотосъемки

В этом примере показано использование Azure Machine Learning Workbench для координации распределенного обучения и ввода в эксплуатацию модели классификации изображений. Для обучения используется два подхода: (i) уточнение глубокой нейронной сети с помощью кластера GPU [искусственного интеллекта пакетной службы Azure](https://docs.microsoft.com/azure/batch-ai/) и (ii) использование пакета [службы "Машинное обучение Microsoft Azure" для Apache Spark (MMLSpark)](https://github.com/Azure/mmlspark) для создания признаков изображений с помощью предварительно обученных моделей CNTK и обучения классификаторов с помощью производных признаков. Затем мы параллельно применяем обученные модели к крупным наборам изображений в облаке с помощью кластера [Azure HDInsight Spark](https://azure.microsoft.com/services/hdinsight/apache-spark/), позволяющего масштабировать скорость обучения и ввода в эксплуатацию путем добавления или удаления узлов рабочих ролей.

В этом примере представлено два подхода для передачи обучения, которые используют предварительно обученные модели для сокращения затрат на обучение глубоких нейронных сетей с нуля. Переподготовка глубокой виртуальной сети обычно требует вычислительных ресурсов GPU, но может повысить точность при использовании большого набора для обучения. Обучение простого классификатора на основе изображения с признаками не требует вычислительных ресурсов GPU, быстро выполняется, произвольно масштабируется и требует меньше параметров. Это лучший метод при отсутствии большого количества примеров, как это часто бывает в пользовательских вариантах использования. 

Кластер Spark, используемый в этом примере, имеет 40 рабочих узлов и затраты на его работу составляют 40 долларов США/час. Ресурсы кластера искусственного интеллекта пакетной службы включают восемь GPU, затраты на работу которых составляют 10 долларов США/час. Завершение этого пошагового руководства займет примерно три часа. После завершения выполните инструкции по очистке, чтобы удалить созданные ресурсы и не нести расходов.

## <a name="link-to-the-gallery-github-repository"></a>Ссылка на репозиторий коллекции на GitHub

Общедоступный репозиторий GitHub содержит все материалы для этого реального сценария, в том числе примеры кода, которые нам потребуются.

[https://github.com/Azure/MachineLearningSamples-AerialImageClassification](https://github.com/Azure/MachineLearningSamples-AerialImageClassification)

## <a name="use-case-description"></a>Описание варианта использования

В этом сценарии мы обучаем модель машинного обучения для классификации типа земли, показанного на изображениях аэрофотосъемки размером 224 x 224 м. Модели классификации землепользования позволяют отслеживать урбанизацию, исчезновение лесов, исчезновение болот и другие значительные тенденции в области окружающей среды с помощью периодически собираемых аэрофотоснимков. Мы подготовили наборы изображений для обучения и проверки, снятые в рамках программы изображений национального сельского хозяйства США, и метки землепользования, опубликованные в базе данных национального растительного покрова США. Примеры изображений каждого класса землепользования показаны здесь:

![Примеры регионов для каждой метки землепользования](media/scenario-aerial-image-classification/example-labels.PNG)

После обучения и проверки модели классификации она будет применена для изображений аэрофотосъемки, охватывающих округ Мидлсекс в штате Массачусетс, где находится центр исследований и разработок Новой Англии (NERD) корпорации Майкрософт, чтобы показать, как эти модели можно использовать для изучения тенденций городского развития.

Для создания классификатора изображений с переносом обучения специалисты по обработке и анализу данных часто создают несколько моделей, использующих различные методы, и выбирают наиболее эффективную. Azure Machine Learning Workbench может помочь специалистам по обработке и анализу данных координировать обучение в различных вычислительных средах, отслеживать и сравнивать эффективность нескольких моделей, а также применять выбранную модель к большим наборам данных в облаке.

## <a name="scenario-structure"></a>Структура сценария

В этом примере данные изображений и предварительно обученные модели включены в учетную запись хранения Azure. Кластер Azure HDInsight Spark считывает эти файлы и создает модель классификации изображений с помощью MMLSpark. Обученная модель и ее прогнозы затем записываются в учетной записи хранения, где их можно проанализировать и визуализировать, используя записную книжку Jupyter, выполняемую локально. Приложение Azure Machine Learning Workbench координирует удаленное выполнение скриптов в кластере Spark. Оно также отслеживает метрики точности для нескольких моделей, обученных с помощью разных методов, позволяя выбрать наиболее эффективную модель.

![Схема для реального сценария классификации изображений аэрофотосъемки](media/scenario-aerial-image-classification/scenario-schematic.PNG)

Пошаговые инструкции начинаются с руководства по созданию и подготовке учетной записи хранения Azure и кластера Spark, включая передачу данных и установку зависимостей. Затем описывается запуск заданий обучения и сравнение эффективности итоговых моделей. Наконец, рассматривается, как применить выбранную модель к крупному набору изображений в кластере Spark и анализировать результаты прогноза локально.


## <a name="set-up-the-execution-environment"></a>Настройка среды выполнения

Следующие инструкции описывают процесс настройки среды выполнения для этого примера.

### <a name="prerequisites"></a>предварительным требованиям
- [Учетная запись Azure](https://azure.microsoft.com/free/) (доступны бесплатные пробные версии).
    - Создается кластер HDInsight Spark с 40 рабочими узлами (всего 168 ядер). Убедитесь, что ваша учетная запись имеет достаточно доступных ядер, проверив вкладку "Использование и квоты" вашей подписки на портале Azure.
       - При отсутствии достаточного количества ядер можно изменить шаблон кластера HDInsight и уменьшить количество подготовленных рабочих узлов. Инструкции см. в разделе "Создание кластера HDInsight Spark".
    - В этом примере создается кластер обучения искусственного интеллекта по пакетной службе с двумя виртуальными машинами NC6 (1 GPU, 6 виртуальных процессоров). Убедитесь, что ваша учетная запись имеет достаточно доступных ядер в регионе "Восточная часть США", проверив вкладку "Использование и квоты" вашей подписки на портале Azure.
- [Azure Machine Learning Workbench](../service/overview-what-is-azure-ml.md).
    - Чтобы установить эту программу и создать учетные записи Экспериментирования и Управления моделями, выполните инструкции из [краткого руководства по установке и созданию](../service/quickstart-installation.md).
- Пакет SDK Python и Azure CLI 2.0 для [искусственного интеллекта пакетной службы](https://github.com/Azure/BatchAI)
    - Необходимо выполнить действия, описанные в следующих разделах [файла сведений с инструкциями по работе с Batch AI](https://github.com/Azure/BatchAI/tree/master/recipes):
        - Необходимые компоненты
        - Создание и получение приложения Azure Active Directory (AAD)
        - Регистрация поставщиков ресурсов Batch AI (раздел, посвященный выполнению инструкций с помощью Azure CLI 2.0)
        - Установка клиента управления Batch AI Azure
        - Установка пакета Azure SDK для Python
    - Запишите идентификатор клиента, секрет и идентификатор арендатора создаваемого приложения Azure Active Directory. Вы будете использовать эти учетные данные далее в этом руководстве.
    - На момент написания этой статьи для Azure Machine Learning Workbench и Azure Batch AI используются отдельные вилки Azure CLI 2.0. Для ясности мы называем версию интерфейса командной строки для Workbench как "интерфейс командной строки, запускаемый из Azure Machine Learning Workbench", а общедоступную версию (которая включает искусственный интеллект пакетной службы) — Azure CLI 2.0.
- [AzCopy](https://docs.microsoft.com/azure/storage/common/storage-use-azcopy) — это бесплатная служебная программа, координирующая передачу файлов между учетными записями хранения Azure.
    - Убедитесь, что папка, содержащая исполняемый файл AzCopy, находится в переменной среды PATH системы. (Инструкции по изменению переменных среды доступны [здесь](https://support.microsoft.com/help/310519/how-to-manage-environment-variables-in-windows-xp))
- Мы рекомендуем такой клиент SSH — [PuTTY](http://www.putty.org/).

Этот пример был протестирован на 10 компьютерах под управлением Windows. Его можно запустить с любого компьютера под управлением Windows, включая виртуальные машины обработки и анализа данных Azure. Azure CLI 2.0 был установлен из файла MSI, согласно [этим инструкциям](https://github.com/Azure/azure-sdk-for-python/wiki/Contributing-to-the-tests#getting-azure-credentials). Могут потребоваться небольшие изменения (например, изменения в путях к файлам) при выполнении этого примера на macOS.

### <a name="set-up-azure-resources"></a>Настройка ресурсов Azure

Для этого примера требуется кластер HDInsight Spark и учетная запись хранения Azure для размещения соответствующих файлов. Выполните приведенные ниже действия для создания этих ресурсов в новой группе ресурсов Azure.

#### <a name="create-a-new-workbench-project"></a>Создание проекта в Workbench

Создайте проект, используя в качестве шаблона следующий пример:
1.  Откройте Azure Machine Learning Workbench.
2.  На странице **Projects** (Проекты) щелкните знак **+** и выберите **New Project** (Создать проект).
3.  В области **Create New Project** (Создание проекта) введите информацию о новом проекте.
4.  В поле поиска **Search Project Templates** (Поиск шаблонов проектов) введите Aerial Image Classification (Классификация изображений аэрофотосъемки) и выберите шаблон.
5.  Нажмите кнопку **Создать**.
 
#### <a name="create-the-resource-group"></a>Создание группы ресурсов

1. После загрузки проекта в Azure Machine Learning Workbench откройте интерфейс командной строки (CLI), щелкнув "Файл-> Open Command Prompt" (Открыть командную строку).
    Используйте эту версию интерфейса командной строки при работе с большей частью руководства. (Там, где указано, будет предложено открыть другую версию CLI для подготовки ресурсов искусственного интеллекта пакетной службы)

1. Из интерфейса командной строки войдите в свою учетную запись Azure с помощью следующей команды:

    ```
    az login
    ```

    Вам будет предложено перейти по URL-адресу и ввести предоставленный временный код. Веб-сайт запросит учетные данные учетной записи Azure.
    
1. Выполнив вход, вернитесь к интерфейсу командной строки и используйте указанную ниже команду, чтобы определить, какие подписки Azure доступны вашей учетной записи Azure.

    ```
    az account list
    ```

    Эта команда выводит список всех подписок, связанных с учетной записью Azure. Найдите идентификатор подписки, которую вы хотите использовать. Укажите идентификатор подписки, как указано в следующей команде, а затем задайте подписку, выполнив эту же команду:

    ```
    az account set --subscription [subscription ID]
    ```

1. Ресурсы Azure, созданные в этом примере, хранятся вместе в группе ресурсов Azure. Выберите уникальное имя группы ресурсов и укажите его в указанном месте, а затем выполните обе команды, чтобы создать группу ресурсов Azure.

    ```
    set AZURE_RESOURCE_GROUP=[resource group name]
    az group create --location eastus --name %AZURE_RESOURCE_GROUP%
    ```

#### <a name="create-the-storage-account"></a>Создание учетной записи хранения

Сейчас мы создадим учетную запись хранения, содержащую файлы проекта, к которым должен обращаться HDInsight Spark.

1. Выберите уникальное имя учетной записи хранения и укажите его, как показано в следующей команде `set`, а затем создайте учетную запись хранения Azure, выполнив обе команды.

    ```
    set STORAGE_ACCOUNT_NAME=[storage account name]
    az storage account create --name %STORAGE_ACCOUNT_NAME% --resource-group %AZURE_RESOURCE_GROUP% --sku Standard_LRS
    ```

1. Выполните следующую команду, чтобы вывести список ключей учетной записи хранения:

    ```
    az storage account keys list --resource-group %AZURE_RESOURCE_GROUP% --account-name %STORAGE_ACCOUNT_NAME%
    ```

    Укажите значение `key1` в качестве ключа к хранилищу данных в следующей команде, а затем выполните ее, чтобы сохранить значение.
    ```
    set STORAGE_ACCOUNT_KEY=[storage account key]
    ```
1. Создайте файловый ресурс с именем `baitshare` в учетной записи хранения с помощью следующей команды:

    ```
    az storage share create --account-name %STORAGE_ACCOUNT_NAME% --account-key %STORAGE_ACCOUNT_KEY% --name baitshare
    ```
1. В предпочитаемом текстовом редакторе загрузите файл `settings.cfg` из подкаталога Code проекта Azure Machine Learning Workbench и вставьте имя и ключ учетной записи хранения в соответствии с полученными рекомендациями. Сохраните и закройте файл `settings.cfg`.
1. Если вы еще этого не сделали, скачайте и установите служебную программу [AzCopy](http://aka.ms/downloadazcopy). Убедитесь, что исполняемый файл AzCopy расположен в вашем системном пути. Для этого введите AzCopy и нажмите клавишу ВВОД, чтобы отобразить документацию о нем.
1. Выполните следующие команды, чтобы скопировать все примеры данных, предварительно обученные модели и скрипты для обучения моделей в соответствующие расположения в учетной записи хранения.

    ```
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/test /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/test /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/train /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/train /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/middlesexma2016 /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/middlesexma2016 /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/pretrainedmodels /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.blob.core.windows.net/pretrainedmodels /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/pretrainedmodels /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.file.core.windows.net/baitshare/pretrainedmodels /DestKey:%STORAGE_ACCOUNT_KEY% /S
    AzCopy /Source:https://mawahsparktutorial.blob.core.windows.net/scripts /SourceSAS:"?sv=2017-04-17&ss=bf&srt=sco&sp=rwl&se=2037-08-25T22:02:55Z&st=2017-08-25T14:02:55Z&spr=https,http&sig=yyO6fyanu9ilAeW7TpkgbAqeTnrPR%2BpP1eh9TcpIXWw%3D" /Dest:https://%STORAGE_ACCOUNT_NAME%.file.core.windows.net/baitshare/scripts /DestKey:%STORAGE_ACCOUNT_KEY% /S
    ```

    Передача файлов займет до часа. За это время можно перейти к следующему разделу. Вам может понадобиться открыть другой интерфейс командной строки в Workbench и переопределить в нем временные переменные.

#### <a name="create-the-hdinsight-spark-cluster"></a>Создание кластера HDInsight Spark

Для создания кластера HDInsigh мы рекомендуем использовать шаблон Resource Manager кластера HDInsight Spark, который расположен во вложенной папке Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning этого проекта.

1. Шаблон кластера HDInsight Spark — это файл template.json, расположенный во вложенной папке Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning этого проекта. По умолчанию шаблон создает кластер Spark с 40 рабочими узлами. Если требуется изменить это число, откройте шаблон в предпочитаемом текстовом редакторе и замените все экземпляры числа 40 необходимым количеством рабочих узлов.
    - Позднее вы можете столкнуться с ошибками нехватки памяти, если выбрано небольшое количество рабочих узлов. Для решения этой проблемы можно запустить скрипты обучения и ввода в эксплуатацию с использованием подмножества доступных данных, как описано далее в этом документе.
2. Выберите уникальное имя и пароль для кластера HDInsight и запишите их, как показано в следующей команде. Затем создайте кластер, выполнив следующие команды:

    ```
    set HDINSIGHT_CLUSTER_NAME=[HDInsight cluster name]
    set HDINSIGHT_CLUSTER_PASSWORD=[HDInsight cluster password]
    az group deployment create --resource-group %AZURE_RESOURCE_GROUP% --name hdispark --template-file "Code\01_Data_Acquisition_and_Understanding\01_HDInsight_Spark_Provisioning\template.json" --parameters storageAccountName=%STORAGE_ACCOUNT_NAME%.blob.core.windows.net storageAccountKey=%STORAGE_ACCOUNT_KEY% clusterName=%HDINSIGHT_CLUSTER_NAME% clusterLoginPassword=%HDINSIGHT_CLUSTER_PASSWORD%
    ```

Развертывание кластера может занять до 30 минут (включая подготовку и выполнение действия скрипта).

### <a name="set-up-batch-ai-resources"></a>Настройка ресурсов искусственного интеллекта пакетной службы

Ожидая передачи файла учетной записи хранения и развертывания кластера Spark, можно подготовить сетевой файловый сервер искусственного интеллекта пакетной службы и кластер GPU. Откройте Azure CLI 2.0 с повышенными привилегиями и выполните следующую команду:

```
az --version 
```

Убедитесь, что `batchai` находится в списке установленных модулей. Если нет, возможно, используется другой интерфейс командной строки (например, одно окно открыто из рабочей среды).

Затем убедитесь, что регистрация поставщика успешно выполнена. (Регистрация поставщика занимает до пятнадцати минут и по-прежнему может выполняться, если вы недавно завершили [инструкции по установке искусственного интеллекта пакетной службы](https://github.com/Azure/BatchAI/tree/master/recipes).) Убедитесь, что Microsoft.Batch и Microsoft.BatchAI отображаются с состоянием "Зарегистрировано" в выходных данных следующей команды:

```
az provider list --query "[].{Provider:namespace, Status:registrationState}" --out table
```

Если нет, выполните следующие команды регистрации поставщика и подождите 15 минут до их завершения.
```
az provider register --namespace Microsoft.Batch
az provider register --namespace Microsoft.BatchAI
```

Изменить следующие команды, чтобы заменить выражения в квадратных скобках значениями, использовавшимися ранее при создании группы ресурсов и учетной записи хранения. Затем сохраните значения как переменные, выполнив такие команды:
```
az account set --subscription [subscription ID]
set AZURE_RESOURCE_GROUP=[resource group name]
set STORAGE_ACCOUNT_NAME=[storage account name]
set STORAGE_ACCOUNT_KEY=[storage account key]
az configure --defaults location=eastus
az configure --defaults group=%AZURE_RESOURCE_GROUP%
```

Определите папку, содержащую проект службы "Машинное обучение Azure" (например, `C:\Users\<your username>\AzureML\aerialimageclassification`). Замените значения в квадратных скобках путем к папке (без обратной косой черты) и выполните следующую команду:
```
set PATH_TO_PROJECT=[The filepath of your project's root directory]
```
Теперь все готово для создания ресурсов искусственного интеллекта пакетной службы, необходимых для этого руководства.

#### <a name="prepare-the-batch-ai-network-file-server"></a>Подготовка сетевого файлового сервера искусственного интеллекта пакетной службы

Кластер искусственного интеллекта пакетной службы может предоставить доступ к данным обучения на сетевом файловом сервере. Вы можете получить доступ к данным в несколько раз быстрее, обращаясь к файлам из NFS, а не из файлового ресурса Azure или хранилища BLOB-объектов Azure.

1. Выполните следующую команду для создания сетевого файлового сервера:

    ```
    az batchai file-server create -n landuseclassifier -u demoUser -p "Dem0Pa$$w0rd" --vm-size Standard_DS2_V2 --disk-count 1 --disk-size 1000 --storage-sku Premium_LRS
    ```

1. Проверьте состояние подготовки сетевого файлового сервера с помощью следующей команды:

    ```
    az batchai file-server list
    ```

    Когда provisioningState сетевого файлового сервера landuseclassifier будет иметь значение "Успешно", сервер будет готов к использованию. Подготовка может занять около пяти минут.
1. Найдите общедоступный IP-адрес NFS в выходных данных предыдущей команды (свойство fileServerPublicIp в разделе mountSettings). Запишите IP-адрес, показанный в следующей команде, а затем сохраните значение, выполнив команду:

    ```
    set AZURE_BATCH_AI_TRAINING_NFS_IP=[your NFS IP address]
    ```

1. С помощью предпочитаемого инструмента SSH (в следующем примере команды используется [PuTTY](http://www.putty.org/)) выполните сценарий `prep_nfs.sh` проекта в NFS для передачи наборов изображений для обучения и проверки.

    ```
    putty -ssh demoUser@%AZURE_BATCH_AI_TRAINING_NFS_IP% -pw Dem0Pa$$w0rd -m %PATH_TO_PROJECT%\Code\01_Data_Acquisition_and_Understanding\02_Batch_AI_Training_Provisioning\prep_nfs.sh
    ```

    Не волнуйтесь, если процесс скачивания и извлечения данных обновит прокрутку по окну оболочки так быстро, что данные в нем будут неразборчивы.

При необходимости можно подтвердить, что передача данных была выполнена согласно плану, войдя на файловый сервер с помощью предпочитаемого инструмента SSH и проверив содержимое каталога `/mnt/data`. Вы должны найти две папки: training_images и validation_images, каждая из которых содержит вложенные папки с именем, соответствующим категориям землепользования.  Наборы для обучения и проверки должны содержать около 44 тысяч и 11 тысяч изображений соответственно.

#### <a name="create-a-batch-ai-cluster"></a>Создание кластера искусственного интеллекта пакетной службы

1. Создайте кластер, выполнив следующие команды:

    ```
    az batchai cluster create -n landuseclassifier2 -u demoUser -p "Dem0Pa$$w0rd" --afs-name baitshare --nfs landuseclassifier --image UbuntuDSVM --vm-size STANDARD_NC6 --max 2 --min 2 --storage-account-name %STORAGE_ACCOUNT_NAME% 
    ```

1. Чтобы проверить состояние подготовки кластера, используйте следующую команду:

    ```
    az batchai cluster list
    ```

    Когда состояние распределения кластера landuseclassifier изменяется с "Изменения размера" на "Устойчивое", можно отправить задания. Однако задания не начнут выполняться, пока во всех виртуальных машинах в кластере состояние "Подготовка" не изменится на другое. Если свойство errors кластера не имеет значение null, во время создания кластера произошла ошибка и его не следует использовать.

#### <a name="record-batch-ai-training-credentials"></a>Запись учетных данных обучения искусственного интеллекта по пакетной службе

Ожидая выделения кластера, откройте файл `settings.cfg` из подкаталога Code этого проекта в предпочитаемом текстовом редакторе. Обновите следующие переменные с помощью собственных учетных данных:
- `bait_subscription_id` (36-символьный идентификатор подписки Azure);
- `bait_aad_client_id` (идентификатор клиента или приложения Azure Active Directory, описанный в разделе "Предварительные требования");
- `bait_aad_secret` (секрет приложения Azure Active Directory, описанный в разделе "Предварительные требования");
- `bait_aad_tenant` (идентификатор клиента Azure Active Directory, описанный в разделе "Предварительные требования");
- `bait_region` (на момент написания этой статьи единственный параметр: eastus);
- `bait_resource_group_name` (выбранная ранее группа ресурсов).

После присвоения этих значений измененные строки файла settings.cfg должны выглядеть следующим образом:

```
[Settings]
    # Credentials for the Azure Storage account
    storage_account_name = yoursaname
    storage_account_key = kpIXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXQ==
    
    # Batch AI training credentials
    bait_subscription_id = 0caXXXXX-XXXX-XXXX-XXXX-XXXXXXXXX9c3
    bait_aad_client_id = d0aXXXXX-XXXX-XXXX-XXXX-XXXXXXXXX7f8
    bait_aad_secret = ygSXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX6I=
    bait_aad_tenant = 72fXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXb47
    bait_region = eastus
    bait_resource_group_name = yourrgname
```

Сохраните и закройте `settings.cfg`.

Теперь можно закрыть окно интерфейса командной строки, где выполнялись команды создания ресурса искусственного интеллекта пакетной службы. Во всех дальнейших шагах этого руководства используется интерфейс командной строки, запущенный из Azure Machine Learning Workbench.

### <a name="prepare-the-azure-machine-learning-workbench-execution-environment"></a>Подготовка среды выполнения Azure Machine Learning Workbench

#### <a name="register-the-hdinsight-cluster-as-an-azure-machine-learning-workbench-compute-target"></a>Регистрация кластера HDInsight в качестве целевого объекта вычисления Azure Machine Learning Workbench

Создав кластер HDInsight, зарегистрируйте его в качестве целевого объекта вычисления для вашего проекта следующим образом:

1.  Выполните следующую команду в интерфейсе командной строки Машинного обучения Azure:

    ```
    az ml computetarget attach cluster --name myhdi --address %HDINSIGHT_CLUSTER_NAME%-ssh.azurehdinsight.net --username sshuser --password %HDINSIGHT_CLUSTER_PASSWORD%
    ```

    Эта команда добавляет два файла, `myhdi.runconfig` и `myhdi.compute`, в папку `aml_config` проекта.

1. Откройте файл `myhdi.compute` в предпочитаемом текстовом редакторе. Измените строку `yarnDeployMode: cluster` на `yarnDeployMode: client`, а затем сохраните и закройте файл.
1. Выполните следующую команду, чтобы подготовить среду HDInsight для использования:
   ```
   az ml experiment prepare -c myhdi
   ```

#### <a name="install-local-dependencies"></a>Установка локальных зависимостей

Откройте интерфейс командной строки из Azure Machine Learning Workbench и установите необходимые для локального выполнения зависимости, выполнив следующую команду:

```
pip install matplotlib azure-storage==0.36.0 pillow scikit-learn azure-mgmt-batchai
```

## <a name="data-acquisition-and-understanding"></a>Получение и изучение данных

В этом сценарии используются общедоступные данные аэрофотоснимков из [программы изображений национального сельского хозяйства](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) с разрешением 1 метр. Мы создали наборы PNG-файлов размером 224 x 224 пикселей, обрезанные копии исходных данных программы, которые отсортированы в соответствии с метками землепользования, опубликованными в [базе данных национального растительного покрова США](https://www.mrlc.gov/nlcd2011.php). Пример изображения с меткой Developed показан в полном размере:

![Пример района застройки](media/scenario-aerial-image-classification/sample-tile-developed.png)

Для обучения и проверки модели использовались наборы (с балансировкой классов) изображений в количестве примерно 44 000 и 11 000 соответственно. Мы демонстрируем развертывание модели для набора изображений в количестве примерно 67 000, который охватывает округ Мидлсекс в штате Массачусетс, где находится центр исследований и разработок Новой Англии (NERD) корпорации Майкрософт. Дополнительные сведения о том, как были созданы эти наборы изображений, см. в [репозитории Git, посвященном классификации изображений с усложненным параллелизмом](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification).

![Расположение округа Мидлсекс в штате Массачусетс](media/scenario-aerial-image-classification/middlesex-ma.png)

Во время установки используемые в этом примере наборы изображений аэрофотосъемки были перенесены в созданную вами учетную запись хранения. Все изображения для обучения, проверки и практического применения — это PNG-файлы размером 224 x 224 пикселей с разрешением один пиксель на квадратный метр. Изображения для обучения и проверки упорядочены по вложенным папкам на основе их меток землепользования. (Метки землепользования изображений для практического применения неизвестны и во многих случаях неоднозначны. Некоторые из этих изображений содержат несколько типов земельных покровов.) Дополнительные сведения о том, как были созданы эти наборы изображений, см. в [репозитории Git, посвященном классификации изображений с усложненным параллелизмом](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification).

Чтобы просмотреть примеры изображений в учетной записи хранения Azure (необязательно), сделайте следующее:
1. Войдите на [портал Azure](https://portal.azure.com).
1. Найдите имя вашей учетной записи хранения в строке поиска в верхней части экрана. Щелкните вашу учетную запись хранения в результатах поиска.
2. Щелкните ссылку больших двоичных объектов в главной области учетной записи хранения.
3. Щелкните контейнер с именем train. Должен отобразиться список каталогов, названных в соответствии с типом землепользования.
4. Щелкните любой из этих каталогов, чтобы загрузить список изображений, которые он содержит.
5. Щелкните любое изображение и загрузите его для просмотра.
6. Если нужно, щелкните контейнеры с именами test и middlesexma2016, чтобы также просмотреть их содержимое.

## <a name="modeling"></a>Моделирование

### <a name="training-models-with-azure-batch-ai"></a>Обучение моделей с помощью искусственного интеллекта пакетной службы Azure

Сценарий `run_batch_ai.py` во вложенной папке Code\02_Modeling проекта Workbench используется для вызова задания обучения искусственного интеллекта по пакетной службе. Это задание повторно обучает классификатор изображений DNN, выбранный пользователем (AlexNet или ResNet 18, предварительно обученными на ImageNet). Кроме того, можно задать глубину повторного обучения: повторное обучение только последнего слоя сети может уменьшить чрезмерно высокую точность при нескольких доступных примерах обучения, в то время как точная настройка всей сети (или, в случае с AlexNet, полностью соединенных слоев) может повысить производительность модели при использовании достаточно большого обучающего набора.

После завершения задания обучения этот сценарий сохраняет модель (вместе с файлом, описывающим сопоставление между целочисленными выходными данными модели и строковыми метками) и прогнозы в хранилище BLOB-объектов. Файл журнала задания BAIT анализируется для извлечения временной шкалы сокращения частоты ошибок в течение эпох обучения. Временная шкала сокращения частоты ошибок записывается в журнал выполнения AML Workbench для дальнейшего просмотра.

Выберите имя для обученной модели, тип предварительно обученной модели и глубину повторного обучения. Запишите необходимые значения, как показано в указанной ниже команде, а затем начните переобучение, выполнив команду в интерфейсе командной строки Машинного обучения Azure:

```
az ml experiment submit -c local Code\02_Modeling\run_batch_ai.py --config_filename Code/settings.cfg --output_model_name [unique model name, alphanumeric characters only] --pretrained_model_type {alexnet,resnet18} --retraining_type {last_only,fully_connected,all} --num_epochs 10
```

Запуск Azure Machine Learning может занять около получаса. Рекомендуется запускать несколько аналогичных команд (различные имена модели выходных данных, тип предварительной обученной модели и глубина повторного обучения), чтобы можно было сравнить производительность моделей, обученных с помощью различных методов.

### <a name="training-models-with-mmlspark"></a>Обучение моделей с помощью MMLSpark

Скрипт `run_mmlspark.py` во вложенной папке Code\02_Modeling проекта Workbench используется для обучения модели [MMLSpark](https://github.com/Azure/mmlspark), предназначенной для классификации изображений. Сначала скрипт создает признаки изображений в обучающем наборе с помощью классификатора изображений DNN, предварительно обученного на наборе данных ImageNet (AlexNet или ResNet с 18 слоями). Затем он использует изображения с признаками для обучения модели MMLSpark (модель случайного леса или модель логистической регрессии), чтобы классифицировать изображения. После этого создаются признаки набора изображений тестирования, которые и оцениваются с помощью обученной модели. Точность прогнозов модели на основе тестового набора вычисляется и регистрируется в журнале выполнения Azure Machine Learning Workbench. Наконец, обученная модель MMLSpark и ее прогнозы на основе тестового набора сохраняются в хранилище BLOB-объектов.

Выберите уникальное имя модели вывода для обученной модели, типа предварительно обученной модели и типа модели MMLSpark. Запишите необходимые значения, как показано в шаблоне указанной ниже команды, а затем начните переобучение, выполнив команду в интерфейсе командной строки Машинного обучения Azure.

```
az ml experiment submit -c myhdi Code\02_Modeling\run_mmlspark.py --config_filename Code/settings.cfg --output_model_name [unique model name, alphanumeric characters only] --pretrained_model_type {alexnet,resnet18} --mmlspark_model_type {randomforest,logisticregression}
```

Дополнительный параметр `--sample_frac` можно использовать для обучения и тестирования модели с подмножеством доступных данных. Использование небольшой выборки данных уменьшает требования к среде выполнения и памяти, хотя и за счет точности обученной модели. (Например, выполнение с `--sample_frac 0.1` займет примерно двадцать минут.) Чтобы получить дополнительные сведения об этом и других параметрах, выполните команду `python Code\02_Modeling\run_mmlspark.py -h`.

Пользователям рекомендуется выполнить этот скрипт несколько раз, используя разные входные параметры. Эффективность итоговых моделей затем можно сравнить с помощью компонента "Журнал выполнения" приложения Azure Machine Learning Workbench.

### <a name="comparing-model-performance-using-the-workbench-run-history-feature"></a>Сравнение производительности модели с помощью журнала выполнения Workbench

Выполнив два или больше запусков для обучения каждого типа, перейдите к функции "Журнал выполнения" в Workbench, щелкнув значок часов в левой строке меню. Выберите `run_mmlspark.py` из списка скриптов слева. В области будет представлено сравнение точности тестовых наборов для всех запусков. Чтобы просмотреть дополнительные сведения, щелкните имя отдельного запуска.

## <a name="deployment"></a>Развертывание

Чтобы применить одну из ваших обученных моделей к изображениям аэросъемки, охватывающим округ Мидлсекс в штате Массачусетс, используя удаленное выполнение в HDInsight, вставьте имя нужной модели в следующую команду и выполните ее.

```
az ml experiment submit -c myhdi Code\03_Deployment\batch_score_spark.py --config_filename Code/settings.cfg --output_model_name [trained model name chosen earlier]
```

Вы можете использовать дополнительный параметр `--sample_frac`, чтобы ввести в эксплуатацию модель с подмножеством доступных данных. Использование небольшой выборки данных уменьшает требования к среде выполнения и памяти, хотя и за счет полноты прогнозирования. Чтобы получить дополнительные сведения об этом и других параметрах, выполните команду `python Code\03_Deployment\batch_score_spark -h`.

Этот скрипт записывает прогнозы модели в вашу учетную запись хранения. Прогнозы можно проверить, как описано в разделе ниже.

## <a name="visualization"></a>Визуализация:

Записная книжка Jupyter Model prediction analysis (Анализ прогнозирования модели) во вложенной папке Code\04_Result_Analysis проекта Workbench визуализирует прогнозы модели. Загрузите и запустите записную книжку следующим образом:
1. Откройте проект в Workbench и щелкните значок папки ("Файлы") в левом меню, чтобы загрузить список каталогов.
2. Перейдите во вложенную папку Code\04_Result_Analysis и щелкните записную книжку с именем Model prediction analysis (Анализ прогнозирования модели). Должна отобразиться предварительная версия записной книжки.
3. Выберите Start Notebook Server (Запустить сервер записных книжек), чтобы загрузить записную книжку.
4. В первой ячейке в указанной области введите имя модели, результаты которой вы хотите проанализировать.
5. Выберите Cell (Ячейка) > Run All (Запустить все), чтобы запустить все ячейки в записной книжке.
6. Читайте данные, отображаемые в ходе выполнения записной книжки, чтобы получить дополнительные сведения о функциях анализа и визуализации, которые она представляет.

## <a name="cleanup"></a>Очистка
После того как вы выполнили этот пример, мы советуем удалить все созданные ресурсы, запустив указанную ниже команду в интерфейсе командной строки Azure.

  ```
  az group delete --name %AZURE_RESOURCE_GROUP%
  ```

## <a name="references"></a>Ссылки

- [Репозиторий, посвященный классификации изображений с усложненным параллелизмом](https://github.com/Azure/Embarrassingly-Parallel-Image-Classification).
   - Описывает создание набора данных из общедоступных изображений и меток.
- Репозиторий GitHub [MMLSpark](https://github.com/Azure/mmlspark).
   - Содержит дополнительные примеры обучения и проверки модели с помощью MMLSpark.

## <a name="conclusions"></a>Заключение

Azure Machine Learning Workbench помогает специалистам по обработке и анализу данных легко развертывать свой код на удаленных целевых объектах вычислений. В этом примере локальный код обучения MMLSpark был развернут для удаленного выполнения в кластере HDInsight, а локальный сценарий запустил задание обучения в кластере GPU искусственного интеллекта пакетной службы Azure. Журнал выполнения Azure Machine Learning Workbench отслеживает эффективность нескольких моделей и помогает определить наиболее точную модель. Функция записной книжки Jupyter Workbench помогает визуализировать прогнозы моделей в интерактивной графической среде.

## <a name="next-steps"></a>Дополнительная информация
Чтобы глубже изучить этот пример, сделайте следующее:
- В функции "Журнал выполнения" Azure Machine Learning Workbench щелкните значок с шестеренкой, чтобы выбрать графики и метрики для отображения.
- Проанализируйте операторы, используемые в примерах скриптов, вызвав `run_logger`. Убедитесь, что понимаете, как записывается каждая метрика.
- Проанализируйте операторы, используемые в примерах скриптов, вызвав `blob_service`. Разберитесь в том, как обученные модели и прогнозы сохраняются в облаке и извлекаются из него.
- Просмотрите содержимое контейнеров, созданных в учетной записи хранилища BLOB-объектов. Убедитесь, что вы понимаете, какой скрипт или команда отвечает за создание каждой группы файлов.
- Измените скрипт обучения, чтобы обучить другой тип модели MMLSpark или изменить гиперпараметры модели. Журнал выполнения позволяет определить, увеличили или уменьшили ваши изменения точность модели.
