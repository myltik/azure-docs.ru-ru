---
title: Справочник по API ведения журнала службы "Машинное обучение Azure" | Документация Майкрософт
description: Справочник по API ведения журнала.
services: machine-learning
author: akshaya-a
ms.author: akannava
manager: mwinkle
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.component: desktop-workbench
ms.workload: data-services
ms.topic: article
ms.date: 09/25/2017
ms.openlocfilehash: b9ea51139fded3d55f0a73024163b7fa943c0ebb
ms.sourcegitcommit: 944d16bc74de29fb2643b0576a20cbd7e437cef2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/07/2018
ms.locfileid: "34834698"
---
# <a name="logging-api-reference"></a>Справочник по API ведения журнала

Библиотека ведения журнала службы "Машинное обучение Azure" позволяет программе выдавать значения метрик и файлы, отслеживаемые службой истории для последующего анализа. Сейчас поддерживается несколько базовых типов метрик и файлов, но их количество будет расти в будущих выпусках пакета Python.

## <a name="uploading-metrics"></a>Загрузка метрик

```python
# import logging API package
from azureml.logging import get_azureml_logger

# initialize a logger object
logger = get_azureml_logger()

# log "scalar" metrics
logger.log("simple integer value", 7)
logger.log("simple float value", 3.141592)
logger.log("simple string value", "this is a string metric")

# log a list of numerical values. 
# this automatically creates a chart in the Run History details page
logger.log("chart data points", [1, 3, 5, 10, 6, 4])
```

По умолчанию все метрики отправляются асинхронно, за счет чего этот процесс не влияет на выполнение программы. Однако он может вызывать проблемы с порядком при отправке нескольких метрик (в крайних случаях). В качестве примера можно привести две метрики, одновременно записываемые в журнал, но по какой-то причине пользователь захотел сохранить их точный порядок. Другой пример: метрику нужно отследить перед выполнением кода, которое может завершиться при первой ошибке. В обоих случаях следует _дождаться_ полной записи метрики в журнал, а после этого продолжить:

```python
# blocking call
logger.log("my metric 1", 1).wait()
logger.log("my metric 2", 2).wait()
```

## <a name="consuming-metrics"></a>Использование метрик

Метрики хранятся службой журнала и привязаны к выполнению, создавшему их. По завершении выполнения метрики (и приведенные ниже артефакты) можно извлечь на вкладке "Журнал выполнения" или с помощью команды CLI ниже.

```azurecli
# show the last run
$ az ml history last

# list all past runs
$ az ml history list 

# show a paritcular run
$ az ml history info -r <runid>
```

## <a name="artifacts-files"></a>Артефакты (файлы)

Помимо метрик служба "Машинное обучение Azure" позволяет также отслеживать файлы. По умолчанию все файлы, записанные в папку `outputs`, которая относится к рабочей папке программы (папка проекта в контексте вычислений), отправляются в службу истории и отслеживаются для последующего анализа. Следует учитывать, что размер отдельного файла не должен превышать 512 МБ.


```Python
# Log content as an artifact
logger.upload("artifact/path", "This should be the contents of artifact/path in the service")
```

## <a name="consuming-artifacts"></a>Использование артефактов

Чтобы распечатать содержимое отслеживаемого артефакта, пользователь должен **скачать** его или **повысить его уровень** с помощью вкладки "Журнал выполнения" определенного выполнения или команд CLI ниже.

```azurecli
# show all artifacts generated by a run
$ az ml history info -r <runid> -a <artifact/path>

# promote a particular artifact
$ az ml history promote -r <runid> -ap <artifact/prefix> -n <name of asset to create>
```
## <a name="next-steps"></a>Дополнительная информация
- Чтобы увидеть API ведения журнала в действии, ознакомьтесь со статьей [Часть 2. Классификация цветков ириса: создание модели](tutorial-classifying-iris-part-2.md).
- Подробные сведения об использовании API ведения журнала в журнале выполнения см. в статье [Как использовать компоненты "Журнал выполнения" и "Метрики модели" в Azure Machine Learning Workbench](how-to-use-run-history-model-metrics.md).
