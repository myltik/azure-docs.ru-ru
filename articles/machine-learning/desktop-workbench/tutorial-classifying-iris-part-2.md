---
title: Руководство по созданию модели для службы "Машинное обучение Azure" (предварительная версия) | Документация Майкрософт
description: Из этого полного руководства вы узнаете, как использовать службу "Машинное обучение Azure" (предварительная версия). Это вторая часть серии руководств. В ней рассматривается экспериментирование.
services: machine-learning
author: hning86
ms.author: haining
manager: mwinkle
ms.reviewer: jmartens
ms.service: machine-learning
ms.workload: data-services
ms.custom: mvc
ms.topic: tutorial
ms.date: 3/15/2018
ms.openlocfilehash: 24ac4d699a511cc99936cb2cd4b245de01984163
ms.sourcegitcommit: e2adef58c03b0a780173df2d988907b5cb809c82
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2018
---
# <a name="tutorial-2-classify-iris---build-a-model"></a>Руководство 2. Классификация набора данных "Ирисы Фишера". Создание модели
Служба "Машинное обучение Azure" (предварительная версия) — это полнофункциональное интегрированное аналитическое решение для специалистов по обработке и анализу данных. Оно помогает подготавливать данные, разрабатывать эксперименты и развертывать модели в масштабе облака.

Это руководство представляет собой **вторую часть серии, состоящей из трех частей**. В этой части вы будете использовать службу "Машинное обучение Azure", чтобы научиться выполнять следующие задачи:

> [!div class="checklist"]
> * Открытие скриптов и проверка кода
> * Выполнение скриптов в локальной среде
> * Просмотр журналов выполнения
> * Выполнение скриптов в локальном окне Azure CLI
> * Выполнение скриптов в локальной среде Docker
> * Выполнение скриптов в удаленной среде Docker
> * Выполнение скриптов в облачной среде Azure HDInsight.

В этом руководстве используется классический [набор данных "Ирисы Фишера"](https://en.wikipedia.org/wiki/Iris_flower_data_set). 

## <a name="prerequisites"></a>предварительным требованиям

Для работы с этим учебником необходимы указанные ниже компоненты.
- Подписка Azure. Если у вас еще нет подписки Azure, [создайте бесплатную учетную запись Azure](https://azure.microsoft.com/free/?WT.mc_id=A261C142F), прежде чем начинать работу. 
- Учетная запись службы экспериментирования и установленное решение Azure Machine Learning Workbench, как указано в этом [кратком руководстве](../service/quickstart-installation.md).
- Проект и подготовленные данные "Ирисы Фишера" из [первой части руководства](tutorial-classifying-iris-part-1.md).
- Установленный и локально запущенный модуль Docker. Достаточно наличия Docker Community Edition. Узнайте, как его установить, здесь: https://docs.docker.com/engine/installation/.

## <a name="review-irissklearnpy-and-the-configuration-files"></a>Просмотр файлов конфигурации и файла iris_sklearn.py

1. Запустите приложение Azure Machine Learning Workbench.

1. Затем откройте проект **myIris**, созданный в [первой части этой серии руководств](tutorial-classifying-iris-part-1.md).

2. Открыв проект, нажмите кнопку **Файлы** (значок папки) на крайней левой панели, чтобы открыть список файлов в папке проекта.

   ![Открытие проекта в Azure Machine Learning Workbench](media/tutorial-classifying-iris/2-project-open.png)

3. Выберите файл сценария Python **iris_sklearn.py**. 

   ![Выбор сценария](media/tutorial-classifying-iris/2-choose-iris_sklearn.png)

   На новой вкладке текстового редактора в Workbench откроется код. Это скрипт, который используется в рамках этой части руководства. 

   >[!NOTE]
   >Код, который вы увидите, может не совпадать с кодом на снимке экрана выше, так как пример проекта постоянно обновляется.
   
   ![Открытие файла](media/tutorial-classifying-iris/open_iris_sklearn.png)

4. Проверьте код скрипта Python, чтобы ознакомиться со стилем программирования. 

   Скрипт **iris_sklearn.py** выполняет следующие задачи.

   * Загружает пакет подготовки данных по умолчанию с именем **iris.dprep** для создания [pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html). 

   * Добавляет случайные компоненты, чтобы усложнить задачу. Случайность необходима, так как "Ирисы Фишера" — это небольшой набор данных, который можно легко классифицировать почти со 100 %-й точностью.

   * Использует библиотеку машинного обучения [scikit-learn](http://scikit-learn.org/stable/index.html), чтобы создать модель логистической регрессии.  Эта библиотека поставляется с Azure Machine Learning Workbench по умолчанию.

   * Сериализует модель путем вставки библиотеки [pickle](https://docs.python.org/3/library/pickle.html) в файл в папке `outputs`. 
   
   * Загружает сериализованную модель, а затем десериализирует ее обратно во временную память.

   * Использует десериализованную модель для прогнозирования на основе новой записи. 

   * Отображает два графика, матрицу неточностей и многоклассовую кривую рабочих характеристик приемника (ROC) с помощью библиотеки [matplotlib](https://matplotlib.org/), а затем сохраняет их в папку `outputs`. Если вы еще не сделали этого, установите эту библиотеку в своей среде.

   * Автоматически отображает графики скорости регуляризации и точности модели в журнале выполнения. Объект `run_logger` используется во всех операциях для записи коэффициента регуляризации и точности модели в журналы. 


## <a name="run-irissklearnpy-in-your-local-environment"></a>Запуск файла iris_sklearn.py в локальной среде

1. Запустите интерфейс командной строки (CLI) службы "Машинное обучение Azure".
   1. Запустите Azure Machine Learning Workbench.

   1. В меню Workbench выберите **Файл** > **Open Command Prompt** (Открыть командную строку). 
   
   Окно интерфейса командной строки службы "Машинное обучение Azure" запускается в папке проекта `C:\Temp\myIris\>` в Windows. Этот проект такой же, как и созданный в первой части этого руководства.

   >[!IMPORTANT]
   >Для выполнения следующих действий необходимо использовать это окно интерфейса командной строки.

1. Если у вас нет библиотеки, в окне интерфейса командной строки установите библиотеку построения Python **matplotlib**.

   Скрипт **iris_sklearn.py** имеет зависимости от двух пакетов Python (**scikit-learn** и **matplotlib**).  Пакет **scikit-learn** устанавливается с помощью Azure Machine Learning Workbench (на ваше усмотрение). Однако необходимо установить **matplotlib** (если вы еще не сделали этого).

   Если продолжить работу, не установив **matplotlib**, код в этом руководстве все равно может выполняться успешно. Тем не менее код не сможет создать выходные данные матрицы неточностей и графики многоклассовой кривой ROC, как показано в визуализациях журнала.

   ```azurecli
   pip install matplotlib
   ```

   Процесс установки может занять около минуты.

1. Вернитесь к приложению Workbench. 

1. Найдите вкладку с именем **iris_sklearn.py**. 

   ![Поиск вкладки со скриптом](media/tutorial-classifying-iris/2-iris_sklearn-tab.png)

1. На панели инструментов выберите **локальную** среду выполнения и `iris_sklearn.py` в качестве скрипта для выполнения. Эти параметры могут быть уже выбранными.

   ![Выбор локальной среды и скрипта](media/tutorial-classifying-iris/2-local-script.png)

1. Перейдите к правой части панели инструментов и введите `0.01` в поле **Аргументы**. 

   Это значение соответствует коэффициенту регуляризации модели логистической регрессии.

   ![Выбор локальной среды и скрипта](media/tutorial-classifying-iris/2-local-script-arguments.png)

1. Нажмите кнопку **Запустить**. Будет запланировано выполнение задания. Задания перечислены на панели **Задания** с правой стороны окна Workbench. 

   ![Выбор локальной среды и скрипта](media/tutorial-classifying-iris/2-local-script-arguments-run.png)

   Через несколько секунд состояние задания изменится с **Отправка** на **Выполнение**, а затем — на **Завершено**.

1. Выберите **Завершено** в тексте состояния задания на панели **Задания**. 

   ![Запуск sklearn](media/tutorial-classifying-iris/2-completed.png)

   Откроется всплывающее окно, отображающее текст стандартного потока вывода (stdout) этого запуска. Чтобы закрыть текст stdout, нажмите кнопку **Закрыть** (**x**) в правом верхнем углу всплывающего окна.

   ![Стандартные выходные данные](media/tutorial-classifying-iris/2-standard-output.png)

9. В том же состоянии задания на панели **Задания** выберите синий текст **iris_sklearn.py [n]** (_n_ — это номер запуска) над разделом с состоянием **Завершено** и временем начала. Откроется окно **свойств запуска**, в котором отобразятся следующие сведения об этом запуске:
   - сведения о **свойствах запуска**;
   - **Outputs**
   - **Метрики**
   - **визуализации** (если есть);
   - **Журналы** 

   По завершении запуска во всплывающем окне отобразятся следующие результаты:

   >[!NOTE]
   >Так как выше в этом руководстве вы включили случайный выбор компонентов в набор для обучения, ваши результаты могут отличаться от приведенных здесь.

   ```text
   Python version: 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]
   
   Iris dataset shape: (150, 5)
   Regularization rate is 0.01
   LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
          verbose=0, warm_start=False)
   Accuracy is 0.6792452830188679
   
   ==========================================
   Serialize and deserialize using the outputs folder.
   
   Export the model to model.pkl
   Import the model from model.pkl
   New sample: [[3.0, 3.6, 1.3, 0.25]]
   Predicted class is ['Iris-setosa']
   Plotting confusion matrix...
   Confusion matrix in text:
   [[50  0  0]
    [ 1 37 12]
    [ 0  4 46]]
   Confusion matrix plotted.
   Plotting ROC curve....
   ROC curve plotted.
   Confusion matrix and ROC curve plotted. See them in Run History details pane.
   ```
    
10. Закройте вкладку **свойств запуска** и вернитесь на вкладку **iris_sklearn.py**. 

11. Повторите для дополнительных запусков. 

    Введите ряд значений в поле **Аргументы** в диапазоне от `0.001` до `10`. Нажмите кнопку **Запустить**, чтобы запустить код еще несколько раз. Значение аргумента, который вы каждый раз меняете, передается модели логистической регрессии в виде кода, в результате чего вы каждый раз получаете разные результаты.

## <a name="review-the-run-history-in-detail"></a>Подробный просмотр журнала выполнения
В Azure Machine Learning Workbench каждое выполнение скрипта записывается в журнале выполнения. Откройте представление **Запуски**, чтобы просмотреть журнал выполнения определенного скрипта.

1. Нажмите кнопку **Запуски** (значок часов) на панели инструментов слева, чтобы открыть список **Запуски**. Затем выберите **iris_sklearn.py**, чтобы отобразить **панель мониторинга запусков** для `iris_sklearn.py`.

   ![Представление "Запуски"](media/tutorial-classifying-iris/run_view.png)

1. Откроется вкладка **Панель мониторинга запусков**. 

   Просмотрите статистику, записанную для нескольких запусков. Графики отображаются в верхней части вкладки. Каждому запуску присвоен порядковый номер, а сведения о запуске отображаются в таблице в нижней части экрана.

   ![Панель мониторинга запуска](media/tutorial-classifying-iris/run_dashboard.png)

1. Отфильтруйте таблицу. Затем выберите любой из графиков, чтобы просмотреть состояние, длительность, точность и частоту регуляризации для каждого запуска. 

1. Установите флажки рядом с двумя или несколькими выполнениями в таблице **Запуски**. Нажмите кнопку **Сравнить**, чтобы открыть панель подробного сравнения. Сравните результаты. 

1. Чтобы вернуться к разделу **Run Dashboard** (Панель мониторинга запусков), нажмите кнопку **Список запуска** со стрелкой назад в верхней левой части панели **Comparison** (Сравнение).

   ![Возвращение к списку запусков](media/tutorial-classifying-iris/2-compare-back.png)

1. Выберите отдельный запуск, чтобы просмотреть подробные сведения о запуске. Обратите внимание: статистика для выбранного запуска доступна в разделе **Свойства запуска**. Файлы, записанные в выходную папку, перечислены в разделе **Выходные данные**, где их можно скачать.

   ![Сведения о запуске](media/tutorial-classifying-iris/run_details.png)

   Два графика, матрица неточностей и многоклассовая кривая ROC отображаются в разделе **Визуализации**. Все файлы журнала также доступны в разделе **Журналы**.


## <a name="run-scripts-in-local-docker-environments"></a>Запуск скриптов в локальной среде Docker

Кроме того, можно попробовать выполнить скрипты с использованием локального контейнера Docker. Вы можете настраивать дополнительные среды выполнения, например Docker, и запускать в них скрипты. 

>[!NOTE]
>Чтобы запустить выполнение скриптов в контейнере Docker на удаленной виртуальной машине Azure или в кластере HDInsight Spark, следуйте [инструкциям по созданию виртуальной машины Azure для обработки и анализа данных на базе Ubuntu или кластера HDInsight](how-to-create-dsvm-hdi.md).

1. Если вы еще этого не сделали, установите и запустите Docker локально на компьютере Windows или MacOS. Дополнительные сведения см. в инструкциях по установке Docker здесь: https://docs.docker.com/install/. Достаточно наличия Community Edition.

1. На панели инструментов слева выберите значок **папки**, чтобы открыть список **файлов** проекта. Разверните папку `aml_config`. 

2. Вы увидите несколько предварительно настроенных сред: **docker-python**, **docker-spark** и **local**. 

   В каждой среде есть два файла, такие как `docker.compute` (и в **docker python**, и в **docker spark**) и `docker-python.runconfig`. Откройте каждый файл. Вы увидите, что некоторые параметры можно изменить в текстовом редакторе.  

   Чтобы выполнить очистку, выберите значок **Закрыть** (**x**) на вкладках в открытых текстовых редакторах.

3. Запустите скрипт **iris_sklearn.py** с помощью среды **docker-python**. 

   - На панели инструментов слева щелкните значок **часов**, чтобы открыть панель **Запуски**. Выберите **Все запуски**. 

   - В верхней части представления **Все запуски** выберите **docker-python** как целевую среду вместо стандартного значения **local**. 

   - Затем справа выберите **iris_sklearn.py** в качестве скрипта для запуска. 

   - Оставьте поле **Аргументы** пустым, так как скрипт определит значение по умолчанию. 

   - Нажмите кнопку **Запустить**.

4. Понаблюдайте за запуском нового задания. Оно отобразится на панели **Задания** в правой части окна Workbench.

   Первый запуск в Docker выполняется на несколько минут дольше. 

   Azure Machine Learning Workbench в фоновом режиме создает файл Docker. 
   Новый файл ссылается на базовый образ Docker, указанный в файле `docker.compute`, и пакеты зависимостей Python, указанные в файле `conda_dependencies.yml`. 
   
   Подсистема Docker выполняет следующие задачи:

    - скачивает базовый образ из Azure;
    - устанавливает пакеты Python, указанные в файле `conda_dependencies.yml`;
    - запускает контейнер Docker;
    - копирует локальную копию папки проекта (или создает ссылку на нее в зависимости от конфигурации запуска);      
    - выполняет скрипт `iris_sklearn.py`.

   В итоге вы увидите результат, аналогичный результату при выборе **локальной** среды.

5. Теперь поработаем со Spark. Базовый образ Docker содержит предварительно установленный и настроенный экземпляр Spark, который можно использовать для выполнения скрипта PySpark. С помощью этого базового образа можно легко разработать и протестировать программу Spark, не тратя время на самостоятельные установку и настройку Spark. 

   Откройте файл `iris_spark.py` . Этот скрипт загружает файл данных `iris.csv` и использует алгоритм логистической регрессии из библиотеки службы машинного обучения Spark для классификации набора данных "Ирисы Фишера". Теперь измените среду выполнения на **docker-spark**, а скрипт — на **iris_spark.py** и повторите запуск. Этот процесс займет немного больше времени, так как сеанс Spark должен быть создан и запущен в контейнере Docker. Как видите, stdout отличается от stdout из `iris_spark.py`.

6. Выполните еще несколько запусков, используя различные аргументы. 

7. Откройте файл `iris_spark.py`, чтобы просмотреть модель логистической регрессии, созданную с использованием библиотеки службы машинного обучения Spark. 

8. Поработайте с панелью **Задания**, откройте представление списка журналов выполнения и представление сведений о запусках в разных средах выполнения.

## <a name="run-scripts-in-the-cli-window"></a>Выполнение скриптов в окне CLI

1. Запустите интерфейс командной строки (CLI) службы "Машинное обучение Azure".
   1. Запустите Azure Machine Learning Workbench.

   1. В меню Workbench выберите **Файл** > **Open Command Prompt** (Открыть командную строку). 
   
   Командная строка CLI запускается в папке проекта `C:\Temp\myIris\>` в Windows. Это и есть проект, созданный в первой части этого руководства.

   >[!IMPORTANT]
   >Для выполнения следующих действий необходимо использовать это окно интерфейса командной строки.

1. В окне CLI войдите в Azure. [Подробнее о команде az login](https://docs.microsoft.com/cli/azure/authenticate-azure-cli?view=azure-cli-latest).

   Возможно, вы уже вошли в систему. В этом случае этот шаг можно пропустить.

   1. В командной строке введите:
      ```azurecli
      az login
      ```

      Эта команда возвращает код, который можно использовать в браузере на сайте https://aka.ms/devicelogin.

   1. В вашем браузере перейдите по ссылке https://aka.ms/devicelogin.

   1. При появлении запроса введите код, который вы получили в CLI, в браузер.

   Приложение Workbench и CLI используют независимые кэши учетных данных для аутентификации пользователя ресурсов Azure. После входа в систему не требуется повторная проверка подлинности до истечения срока действия кэшированного маркера. 

1. Если у организации есть несколько подписок Azure (корпоративная среда), необходимо задать используемую подписку. Найдите подписку, задайте ее с помощью идентификатора подписки, а затем проверьте ее.

   1. Отобразите список всех подписок Azure, к которым имеется доступ, с помощью этой команды:
   
      ```azurecli
      az account list -o table
      ```

      Команда **az account list** возвращает список доступных подписок для вашего имени входа. 
      Если имеется несколько подписок, определите значение идентификатора для подписки, которую нужно использовать.

   1. Задайте подписку Azure, которую вы хотите использовать в качестве учетной записи по умолчанию:
   
      ```azurecli
      az account set -s <your-subscription-id>
      ```
      где \<your-subscription-id\> — значение идентификатора, используемого для подписки. Не используйте квадратные скобки.

   1. Подтвердите новые параметры подписки, отправив запрос на получение сведений о текущей подписке. 

      ```azurecli
      az account show
      ```    

1. Если у вас нет библиотеки, в окне интерфейса командной строки установите библиотеку построения Python **matplotlib**.

   ```azurecli
   pip install matplotlib
   ```

1. В окне CLI отправьте скрипт **iris_sklearn.py** в качестве эксперимента.

   Начнется выполнение iris_sklearn.py в контексте локального вычисления.

   + Действия для ОС Windows.
     ```azurecli
     az ml experiment submit -c local .\iris_sklearn.py
     ```

   + В MacOS:
     ```azurecli
     az ml experiment submit -c local iris_sklearn.py
     ```
   
   Вы должны получить примерно такие выходные данные:
    ```text
    RunId: myIris_1521077190506
    
    Executing user inputs .....
    ===========================
    
    Python version: 3.5.2 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:52:12) 
    [GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)]
    
    Iris dataset shape: (150, 5)
    Regularization rate is 0.01
    LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,
              intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
              penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
              verbose=0, warm_start=False)
    Accuracy is 0.6792452830188679
        
    ==========================================
    Serialize and deserialize using the outputs folder.
    
    Export the model to model.pkl
    Import the model from model.pkl
    New sample: [[3.0, 3.6, 1.3, 0.25]]
    Predicted class is ['Iris-setosa']
    Plotting confusion matrix...
    Confusion matrix in text:
    [[50  0  0]
     [ 1 37 12]
     [ 0  4 46]]
    Confusion matrix plotted.
    Plotting ROC curve....
    ROC curve plotted.
    Confusion matrix and ROC curve plotted. See them in Run History details page.
    
    Execution Details
    =================
    RunId: myIris_1521077190506
    ```

1. Просмотрите выходные данные. Вы получите те же выходные данные, что и при использовании приложения Workbench для запуска скрипта. 

1. В окне CLI выполните сценарий Python **iris_sklearn.py** снова, используя среду выполнения Docker (при наличии установленного на компьютере модуля Docker).

   + Если контейнер применяется в Windows: 
     |Выполнение<br/>Среда|Команда в Windows|
     |---------------------|------------------|
     |Python|`az ml experiment submit -c docker-python .\iris_sklearn.py 0.01`|
     |Spark|`az ml experiment submit -c docker-spark .\iris_spark.py 0.1`|

   + Если контейнер выполняется в MacOS: 
     |Выполнение<br/>Среда|Команда в Windows|
     |---------------------|------------------|
     |Python|`az ml experiment submit -c docker-python iris_sklearn.py 0.01`|
     |Spark|`az ml experiment submit -c docker-spark iris_spark.py 0.1`|

1. Вернитесь к Workbench и сделайте следующее.
   1. Выберите значок папки на левой панели, чтобы вывести список файлов проекта.
   
   1. Откройте скрипт Python с именем **run.py**. Этот скрипт можно использовать для повторного запуска с разной частотой регуляризации. 

   ![Возвращение к списку запусков](media/tutorial-classifying-iris/2-runpy.png)

1. Запустите эксперимент несколько раз с разной частотой. 

   Этот скрипт начинается с задания `iris_sklearn.py` с частотой регуляризации `10.0` (очень большое число). Затем скрипт сокращает частоту наполовину в следующем запуске и продолжает сокращать ее в последующих запусках, пока ее значение не дойдет до `0.005`. 

   Скрипт содержит следующий код:

   ![Возвращение к списку запусков](media/tutorial-classifying-iris/2-runpy-code.png)

1. Запустите скрипт **run.py** из командной строки следующим образом.

   ```cmd
   python run.py
   ```

   Эта команда отправляет iris_sklearn.py несколько раз с разной частотой регуляризации.

   По выполнении `run.py` вы увидите графики разных метрик в представлении списка журнала выполнения в Workbench.

## <a name="run-scripts-in-a-remote-docker-container"></a>Выполнение скриптов в удаленном контейнере Docker
Чтобы выполнить скрипт в контейнере Docker на удаленном компьютере Linux, необходимо иметь доступ SSH (имя пользователя и пароль) к этому компьютеру. Кроме того, на удаленном компьютере должна быть установлена и запущена подсистема Docker. Самый простой способ получить доступ к такому компьютеру Linux — создать виртуальную машину для обработки и анализа данных на базе Ubuntu в Azure. См. дополнительные сведения о [создании виртуальной машины для обработки и анализа данных Ubuntu для использования в Azure ML Workbench](how-to-create-dsvm-hdi.md#create-an-ubuntu-dsvm-in-azure-portal).

>[!NOTE] 
>Виртуальная машина для обработки и анализа данных на базе CentOS *не* поддерживается.

1. Созданную виртуальную машину можно присоединить в качестве среды выполнения, создав пару файлов — `.runconfig` и `.compute`. Для создания этих файлов выполните следующую команду. 

 Назовите новый целевой объект вычислений `myvm`.
 
   ```azurecli
   az ml computetarget attach remotedocker --name myvm --address <your-IP> --username <your-username> --password <your-password>
   ```
   
   >[!NOTE]
   >IP-адрес также может быть общедоступным полным доменным именем (FQDN), например `vm-name.southcentralus.cloudapp.azure.com`. Рекомендуем добавить полное доменное имя виртуальной машины для обработки и анализа данных и использовать его вместо IP-адреса. Такой подход очень удобен, так как вы можете в любой момент отключить виртуальную машину, чтобы сэкономить на оплате. Кроме того, при очередном запуске виртуальной машины, IP-адрес может быть изменен.

   >[!NOTE]
   >В дополнение к проверке подлинности по имени пользователя и паролю можно указать закрытый ключ и соответствующую парольную фразу (если есть) с помощью параметров `--private-key-file` и (необязательно) `--private-key-passphrase`.

   Затем подготовьте целевой объект вычислений **myvm**, запустив следующую команду.
   
   ```azurecli
   az ml experiment prepare -c myvm
   ```
   
   Предыдущая команда создает образ Docker на виртуальной машине и подготавливает ее для выполнения скриптов:
   
   >[!NOTE]
   >Можно также изменить значение `PrepareEnvironment` в `myvm.runconfig` со значения по умолчанию `false` на `true`. После этого изменения при первом запуске автоматически создается контейнер Docker.

2. Измените автоматически созданный файл `myvm.runconfig` в разделе `aml_config` и измените значение параметра Framework с `PySpark` (по умолчанию ) на `Python`:

   ```yaml
   Framework: Python
   ```
   >[!NOTE]
   >Хотя PySpark также подойдет, использовать Python все же более эффективно, если только вам не нужен именно сеанс Spark для выполнения скрипта Python.

3. Выполните ту же команду, что и в окне CLI, только на этот раз используйте _myvm_, чтобы выполнить iris_sklearn.py в удаленном контейнере Docker:
   ```azurecli
   az ml experiment submit -c myvm iris_sklearn.py
   ```
   Команда выполняется, как и при использовании среды `docker-python`, но сейчас это происходит на удаленной виртуальной машине Linux. Окно CLI отображает те же выходные данные.

4. Попробуем использовать Spark в контейнере. Откройте проводник. Создайте копию файла `myvm.runconfig` и назовите ее `myvm-spark.runconfig`. Отредактируйте новый файл, чтобы изменить значение параметра `Framework` с `Python` на `PySpark`:
   ```yaml
   Framework: PySpark
   ```
   Не вносите изменения в файл `myvm.compute`. Для выполнения Spark используется тот же образ Docker на той же виртуальной машине. В новом файле `myvm-spark.runconfig` поле `Target` указывает на тот же файл `myvm.compute`, ссылаясь на его имя `myvm`.

5. Введите следующую команду для запуска скрипта **iris_spark.py** в экземпляре Spark, работающем в удаленном контейнере Docker:
   ```azureli
   az ml experiment submit -c myvm-spark .\iris_spark.py
   ```

## <a name="run-scripts-in-hdinsight-clusters"></a>Запуск скриптов в кластерах HDInsight
Этот скрипт также можно выполнить в кластере HDInsight. См. дополнительные сведения о [создании кластера HDInsight Spark в Azure ML Workbench](how-to-create-dsvm-hdi.md#create-an-apache-spark-for-azure-hdinsight-cluster-in-azure-portal).

>[!NOTE] 
>Кластер HDInsight должен использовать в качестве основного хранилища хранилище BLOB-объектов Azure. Использование хранилища Azure Data Lake еще не поддерживается.

1. Если у вас есть доступ к Spark для кластера Azure HDInsight, запустите команду конфигурации HDInsight, как показано ниже. Укажите в качестве параметров имя кластера HDInsight, имя пользователя HDInsight и пароль. 

   Используйте следующую команду, чтобы создать целевой объект, который указывает на кластер HDInsight.

   ```azurecli
   az ml computetarget attach cluster --name myhdi --address <cluster head node FQDN> --username <your-username> --password <your-password>
   ```

   Чтобы подготовить кластер HDInsight, выполните следующую команду:

   ```
   az ml experiment prepare -c myhdi
   ```

   Полное доменное имя головного узла кластера обычно выглядит так: `<your_cluster_name>-ssh.azurehdinsight.net`.

   >[!NOTE]
   >`username` — имя пользователя для SSH кластера, определяемое во время установки HDInsight. Значение по умолчанию — `sshuser`. Это не пользователь `admin`, который был создан при настройке для включения доступа к веб-сайту администрирования кластера. 

2. Выполните следующую команду для запуска скрипта **iris_spark.py** в кластере HDInsight:

   ```azurecli
   az ml experiment submit -c myhdi .\iris_spark.py
   ```

   >[!NOTE]
   >Выполняя скрипт в удаленном кластере HDI, вы можете просмотреть подробные сведения о выполнении задания Yet Another Resource Negotiator (YARN) в `https://<your_cluster_name>.azurehdinsight.net/yarnui` с помощью учетной записи `admin`.

## <a name="clean-up-resources"></a>Очистка ресурсов

[!INCLUDE [aml-delete-resource-group](../../../includes/aml-delete-resource-group.md)]

## <a name="next-steps"></a>Дополнительная информация
Во второй части этой серии руководств, состоящей из 3 частей, вы узнали, как выполнить такие задачи:
> [!div class="checklist"]
> * Открытие скриптов и просмотр кода в Workbench.
> * Выполнение скриптов в локальной среде
> * Просмотр журнала выполнения.
> * Выполнение скриптов в локальной среде Docker

Теперь вы можете приступить к изучению третьей части этой серии руководств, в которой вы узнаете, как развернуть модель логистической регрессии, созданной в режиме реального времени веб-службы.

> [!div class="nextstepaction"]
> [Руководство. Часть 3. Классификация цветков ириса: развертывание модели](tutorial-classifying-iris-part-3.md)
