---
title: Общие сведения о службе управления моделями Машинного обучения Azure | Документация Майкрософт
description: В этом документе описаны основные понятия службы управления моделями для Машинного обучения Azure.
services: machine-learning
author: nk773
ms.author: padou
manager: mwinkle
ms.reviewer: jasonwhowell, mldocs
ms.service: machine-learning
ms.component: desktop-workbench
ms.workload: data-services
ms.topic: article
ms.date: 09/20/2017
ms.openlocfilehash: 6fac3fa0207d942c5a7f5fa438ba8262ea5b7a22
ms.sourcegitcommit: 944d16bc74de29fb2643b0576a20cbd7e437cef2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/07/2018
ms.locfileid: "34832233"
---
# <a name="azure-machine-learning-model-management"></a>Служба управления моделями Машинного обучения Azure

Служба управления моделями Машинного обучения Azure позволяет развертывать рабочие процессы машинного обучения и модели, а также управлять ими. 

Служба управления моделями предоставляет возможности для:
- управления версиями моделей;
- отслеживания моделей в рабочей среде;
- развертывания моделей в рабочей среде с использованием среды вычислений AzureML со [Службой контейнеров Azure](https://azure.microsoft.com/services/container-service/) и [Kubernetes](https://docs.microsoft.com/azure/container-service/kubernetes/container-service-kubernetes-walkthrough);
- создания контейнеров Docker с моделями и их тестирования в локальной среде;
- автоматического переобучения моделей;
- сохранения телеметрии моделей для практической аналитической информации. 

Служба управления моделями Машинного обучения Azure предоставляет реестр версий модели. Она также предоставляет автоматизированные рабочие процессы для упаковки и развертывания контейнеров машинного обучения в виде интерфейсов REST API. Модели и их зависимости среды выполнения упаковываются в контейнер Docker на основе Linux с API-интерфейсами прогнозирования. 

Вычислительные среды Машинного обучения Azure помогают настраивать и администрировать масштабируемые кластеры для размещения моделей. Вычислительная среда основана на Службе контейнеров Azure. Служба контейнеров Azure обеспечивает автоматическую доступность API-интерфейсов машинного обучения в виде конечных точек REST API со следующими функциями:

- Authentication
- Балансировка нагрузки.
- автоматическое масштабирование;
- Шифрование

Служба управления моделями Машинного обучения Azure позволяет использовать эти возможности с помощью командной строки, API и портала Azure. 

Эта служба использует следующие сведения:

 - файл модели или каталог с файлами модели;
 - созданный пользователем файл Python, реализующий функцию оценки модели;
 - файл зависимостей Conda, содержащий зависимости среды выполнения;
 - выбранная среда выполнения; 
 - файл схемы для параметров API. 

Эти сведения используются при выполнении следующих действий:

- регистрация модели;
- создание манифеста, используемого при создании контейнера;
- создание образа контейнера Docker;
- развертывание контейнера в Службе контейнеров Azure.
 
Ниже показано представление того, как модели регистрируются и развертываются в кластере. 

![](media/model-management-overview/modelmanagement.png)

## <a name="create-and-manage-models"></a>Создание моделей и управление ими 
Модели можно регистрировать с помощью службы управления моделями Машинного обучения Azure для отслеживания версий моделей в рабочей среде. Для упрощения воспроизводимости и контроля служба фиксирует все зависимости и связанные данные. Чтобы получить подробные сведения о производительности, вы можете сохранить телеметрию модели с помощью предоставленного пакета SDK. Телеметрия модели архивируется в предоставляемом пользователем хранилище. Ее можно использовать позже для анализа эффективности модели, переобучения и получения бизнес-аналитики.

## <a name="create-and-manage-manifests"></a>Создание манифестов и управление ими 
Моделям требуются дополнительные артефакты для развертывания в производственной среде. Система предоставляет возможность создания манифеста, который включает в себя модель, зависимости, скрипт определения (так называемый скрипт оценки), примеры данных, схемы и т. д. Этот манифест выступает в качестве набора команд для создания образа контейнера Docker. Предприятия могут автоматически создавать манифест, создавать различные версии и управлять манифестами. 

## <a name="create-and-manage-docker-container-images"></a>Создание образов контейнеров Docker и управление ими 
Вы можете использовать манифест из предыдущего шага для создания образов контейнеров на основе Docker в соответствующих средах. Контейнерные образы на основе Docker предоставляют предприятиям гибкость благодаря возможности запуска в следующих вычислительных средах:

- [Служба контейнеров Azure на основе Kubernetes](https://docs.microsoft.com/azure/container-service/kubernetes/container-service-kubernetes-walkthrough);
- локальные службы контейнеров;
- среды разработки;
- устройства Интернета вещей.

Эти контейнерные образы на основе Docker являются автономными и содержат все необходимые зависимости, необходимые для создания прогнозов. 

## <a name="deploy-docker-container-images"></a>Развертывание образов контейнеров Docker 
Используя службу управления моделями Машинного обучения Azure, можно с помощью одной команды развернуть образы контейнеров на основе Docker в Службе контейнеров Azure, управляемой вычислительной средой машинного обучения. Эти развертывания создаются с помощью сервера переднего плана, который предоставляет следующие возможности:

- формирование прогнозов с низкой задержкой с поддержкой масштабирования;
- Балансировка нагрузки.
- автоматическое масштабирование конечных точек службы машинного обучения;
- Проверка подлинности с помощью ключа API
- документ API Swagger.

Вы можете управлять масштабированием развертывания и телеметрией с помощью следующих параметров конфигурации:

- Ведение системного журнала и данные телеметрии модели для каждого уровня веб-службы. Если параметр включен, все журналы stdout передаются потоком в [Azure Application Insights](https://azure.microsoft.com/services/application-insights/). Телеметрия модели архивируется в предоставляемом вами хранилище. 
- Ограничения автоматического масштабирования и параллелизма. Эти параметры автоматически увеличивают количество развернутых контейнеров на основе нагрузки в пределах существующего кластера. Они также управляют пропускной способностью и согласованностью задержки прогнозирования.

## <a name="consumption"></a>Потребление 
Служба управления моделями Машинного обучения Azure создает REST API для развернутой модели вместе с документом Swagger. Вы можете использовать развернутые модели, вызывая REST API с помощью ключа API и входных данных модели, чтобы получать прогнозы как часть бизнес-приложений. Пример кода доступен на GitHub для языков Java, [Python](https://github.com/CortanaAnalyticsGallery-Int/digit-recognition-cnn-tf/blob/master/client.py) и C# для вызова интерфейсов REST API. Интерфейс командной строки службы управления моделями Машинного обучения Azure предоставляет простой способ работы с этими REST API. Чтобы работать с ними, можно использовать одну команду интерфейса командной строки, приложения с поддержкой Swagger или curl. 

## <a name="retraining"></a>Переобучение 
Служба управления моделями Машинного обучения Azure предоставляет интерфейсы API, которые можно использовать для переобучения моделей. Также можно использовать API-интерфейсы для добавления в существующие развертывания обновленных версий модели. В рамках процесса обработки и анализа данных повторно создайте модель в среде экспериментов. Затем зарегистрируйте модель в службе управления моделями и обновите существующие развертывания. Обновления выполняются с помощью команды CLI UPDATE. Команда UPDATE обновляет существующие развертывания без изменения URL-адреса API или ключа. Приложения, использующие модель, продолжают работать без какого-либо изменения кода и начинают получать лучшие прогнозы благодаря использованию новой модели.

Весь рабочий процесс, описывающий эти понятия, представлен на следующем рисунке.

![](media/model-management-overview/modelmanagementworkflow.png)

## <a name="frequently-asked-questions-faq"></a>Часто задаваемые вопросы 
- **Какие типы данных поддерживаются? Можно ли передать массивы NumPy непосредственно в качестве входных данных в веб-службу?**

   Если вы предоставляете файл схемы, который был создан с помощью пакета SDK generate_schema, вы можете передать NumPy или Pandas DF. Можно также передать сериализуемые входные данные JSON. Образы можно передать в качестве строки в двоичном формате.

- **Поддерживает ли веб-служба несколько наборов входных данных или анализирует разные входные данные?**

   Да, вы можете взять несколько наборов входных данных, упакованных в один запрос JSON в качестве словаря. Каждый набор входных данных соответствует одному уникальному ключу словаря.

- **Каким является вызов, активированный запросом к веб-службе: блокирующим или асинхронным?**

   Если служба создана с помощью параметра в реальном времени в рамках интерфейса командной строки или API, тогда вызов является блокирующим или синхронным. Ожидается, что он будет происходить в реальном времени. Хотя на стороне клиента вы можете делать вызов, используя асинхронную HTTP-библиотеку, чтобы избежать блокировки клиентского потока.

- **Сколько запросов может обрабатывать веб-служба одновременно?**

   Это зависит от масштаба кластера и веб-службы. Можно расширить службу до 100 реплик, после чего она сможет обрабатывать множество запросов одновременно. Вы также можете настроить максимум параллельных запросов на реплику для увеличения пропускной способности.

- **Сколько запросов может поставить в очередь веб-служба?**

   Это можно настроить. По умолчанию — приблизительно 10 запросов на одну реплику, но вы можете увеличить или уменьшить это значение в соответствии с требованиями вашего приложения. Как правило, увеличение количества запросов в очереди повышает пропускную способность службы, но делает задержки более высокими при более высоких процентилях. Чтобы задержки оставались согласованными, можно настроить низкое значение для очереди (1–5) и увеличить количество реплик для обработки пропускной способности. Можно также включить автоматическое масштабирование, чтобы автоматически корректировать количество реплик в зависимости от нагрузки. 

- **Можно ли использовать один и тот же компьютер или кластер для нескольких конечных точек веб-службы?**

   Конечно. Вы можете запустить 100 экземпляров служб или конечных точек в одном кластере. 

## <a name="next-steps"></a>Дополнительная информация
Сведения о том, как приступить к работе со службой управления моделями, см. в статье [Установка службы управления моделями](deployment-setup-configuration.md).
