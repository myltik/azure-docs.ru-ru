---
title: Настройка службы "Экспериментирование в Машинном обучении Azure" | Документация Майкрософт
description: Статья содержит обзор службы "Экспериментирование в Машинном обучении Azure" и инструкции по ее настройке.
services: machine-learning
author: gokhanuluderya-msft
ms.author: gokhanu
manager: haining
ms.reviewer: jmartens, jasonwhowell, mldocs
ms.service: machine-learning
ms.component: desktop-workbench
ms.workload: data-services
ms.topic: article
ms.date: 09/28/2017
ms.openlocfilehash: 6903a02a2f714dc6a8de7bcdd6a81cdd14f2cb0a
ms.sourcegitcommit: 944d16bc74de29fb2643b0576a20cbd7e437cef2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/07/2018
ms.locfileid: "34831360"
---
# <a name="configuring-azure-machine-learning-experimentation-service"></a>Настройка службы "Экспериментирование в Машинном обучении Azure"

## <a name="overview"></a>Обзор
Служба "Экспериментирование в Машинном обучении Azure" позволяет специалистам по обработке и анализу данных проводить эксперименты, управляя их выполнением и запусками при помощи функций службы "Машинное обучение Azure". Она предоставляет платформу для гибкого экспериментирования и быстрых итераций. Приложение Azure Machine Learning Workbench позволяет начать выполнение эксперимента на локальном компьютере, а затем легко увеличить его масштаб путем развертывая в других окружениях. Например, на удаленных виртуальных машинах для обработки и анализа данных с поддержкой графических процессоров или в кластерах HDInsight под управлением Spark.

Служба "Экспериментирование" обеспечивает изолированные, воспроизводимые и согласованные запуски экспериментов. Она помогает управлять целевыми объектами вычислений, средами выполнения и конфигурациями запуска. Функции Azure Machine Learning Workbench для управления выполнением и запусками позволяют легко переходить из одной среды в другую. 

Вы можете выполнить скрипт Python или PySpark в проекте Workbench и локально, и в облаке с применением масштабирования. 

Для запуска скриптов доступны следующие среды. 

* Окружение Python (3.5.2) на локальном компьютере, которое устанавливается вместе с Workbench.
* Среда Conda Python в контейнере Docker на локальном компьютере.
* Окружение Python, которым вы владеете и управляете на удаленном компьютере Linux.
* Среда Conda Python в контейнере Docker на удаленном компьютере под управлением Linux. Например, [виртуальная машина для обработки и анализа данных на основе Ubuntu в Azure] (https://azuremarketplace.microsoft.com/marketplace/apps/microsoft-ads.linux-data-science-vm-ubuntu).
* [HDInsight для Spark](https://azure.microsoft.com/services/hdinsight/apache-spark/) в Azure

>[!IMPORTANT]
>Служба "Экспериментирование в Машинном обучении Azure" в настоящее время поддерживает версии сред выполнения Python 3.5.2 и Spark 2.1.11. 


### <a name="key-concepts-in-experimentation-service"></a>Основные понятия службы "Экспериментирование"
При работе со службой "Экспериментирование в Машинном обучении Azure" важно ознакомиться с перечисленными ниже понятиями. В других разделах мы подробно расскажем, как их использовать. 

#### <a name="compute-target"></a>Целевой объект вычисления
_Целевой объект вычисления_ указывает, где будет выполняться программа, например на рабочем столе, в удаленном контейнере Docker на виртуальной машине или в кластере. Целевой объект вычисления должен быть адресуемым и доступным для пользователя. Приложение Workbench позволяет создавать целевые объекты вычисления и управлять ими с помощью приложения Workbench и интерфейса командной строки. 

Команда _az ml computetarget attach_ в интерфейсе командной строки позволяет создать целевой объект вычислений, который затем можно использовать в запусках экспериментов.

Поддерживаются следующие целевые объекты вычислений.
* Локальная среда Python (3.5.2) на компьютере, которая устанавливается вместе с Workbench.
* Локальный контейнер Docker на персональном компьютере.
* Управляемое пользователем окружение Python на удаленных виртуальных машинах Linux Ubuntu. Например, [виртуальная машина для обработки и анализа данных на основе Ubuntu в Azure](https://azuremarketplace.microsoft.com/marketplace/apps/microsoft-ads.linux-data-science-vm-ubuntu).
* Удаленный контейнер Docker на виртуальных машинах Linux или Ubuntu. Например, [виртуальная машина для обработки и анализа данных на основе Ubuntu в Azure](https://azuremarketplace.microsoft.com/marketplace/apps/microsoft-ads.linux-data-science-vm-ubuntu).
* [HDInsight для кластера Spark](https://azure.microsoft.com/services/hdinsight/apache-spark/) в Azure

Служба "Экспериментирование" в настоящее время поддерживает версии сред выполнения Python 3.5.2 и Spark 2.1.11. 

>[!IMPORTANT]
> Виртуальные машины Windows, на которых выполняется контейнер Docker, **не** поддерживаются в качестве удаленных целевых объектов вычислений.

#### <a name="execution-environment"></a>Среда выполнения
_Среда выполнения_ определяет конфигурацию среды выполнения и зависимости, которые обязательны для запуска программы в Workbench.

Вы можете использовать для управления локальной средой выполнения любые удобные средства и диспетчеры пакетов, если они работают в стандартной среде выполнения Workbench. 

Для управления выполнением в локальном или удаленном контейнере Docker или выполнением на основе HDInsight используется среда Conda. В этих целевых объектах вычислений за управление конфигурацией среды выполнения отвечают файлы **Conda_dependencies.yml** и **Spark_dependencies.yml**. Эти файлы находятся в папке **aml_config** внутри проекта.

**Поддерживаются следующие среды выполнения для сред выполнения.**
* Python 3.5.2
* Spark 2.1.11

### <a name="run-configuration"></a>Конфигурация запуска
Помимо целевого объекта вычислений и среды выполнения, служба "Машинное обучение Azure" предоставляет платформу для определения и изменения *конфигураций запуска*. В процессе итеративного экспериментирования для разных выполнений эксперимента могут потребоваться разные конфигурации. Вы можете применять разные диапазоны параметров, использовать разные источники данных или изменять настройки Spark. Служба "Экспериментирование" предоставляет платформу для управления конфигурациями запуска.

Команда _az ml computetarget attach_ создает в каталоге **aml_config** для вашего проекта файлы COMPUTE и RUNCONFIG со следующими именами: _<имя_целевого_объекта_вычислений>.compute_ и _<имя_целевого_объекта_вычислений>.runconfig_. RUNCONFIG-файл создается автоматически при создании целевого объекта вычислений. Вы можете создавать дополнительные конфигурации и управлять ими с помощью команды _az ml runconfigurations_ в интерфейсе командной строки. Также вы можете создавать и редактировать их средствами файловой системы.

Конфигурация запуска в Workbench позволяет настраивать переменные среды. Вы можете указать нужные переменные среды в соответствующем разделе RUNCONFIG-файла, чтобы затем использовать их в коде. 

```
EnvironmentVariables:
    "EXAMPLE_ENV_VAR1": "Example Value1"
    "EXAMPLE_ENV_VAR2": "Example Value2"
```

Эти переменные среды становятся доступными в пользовательском коде. Например, этот фрагмент кода Phyton выводит значение переменной среды с именем EXAMPLE_ENV_VAR1:
```
print(os.environ.get("EXAMPLE_ENV_VAR1"))
```

_**На следующем рисунке показан обобщенный процесс для начального запуска эксперимента.**_
![](media/experimentation-service-configuration/experiment-execution-flow.png)

## <a name="experiment-execution-scenarios"></a>Сценарии выполнения экспериментов
В этом разделе мы подробно рассмотрим сценарии выполнения и узнаем, как эксперименты запускаются в службе "Машинное обучение Azure" в локальной среде, на удаленной виртуальной машине и в кластере HDInsight. Этот раздел содержит пошаговое руководство с момента создания целевого объекта вычислений до выполнения экспериментов.

>[!NOTE]
>В оставшейся части этой статьи мы расскажем об основных понятиях и возможностях на примерах интерфейса командной строки. Все эти возможности также можно использовать в приложении Workbench.

## <a name="launching-the-cli"></a>Запуск интерфейса командной строки
Чтобы запустить интерфейс командной строки, откройте проект в приложении Workbench и перейдите к пункту меню **Файл-->Открыть командную строку**.

![](media/experimentation-service-configuration/opening-cli.png)

Эта команда открывает окно терминала, в котором можно вводить команды для выполнения скриптов в текущей папке проекта. Для настройки окна терминала используется среда Python 3.5.2, которая устанавливается вместе с Workbench.

>[!NOTE]
> Для выполнения любой команды _az ml_ в командном окне необходимо пройти аутентификацию в Azure. Интерфейс командной строки использует отдельный кэш аутентификации, независимый от классического приложения. Поэтому выполнение входа в приложении Workbench не считается аутентификацией в среде CLI. Чтобы выполнить аутентификацию, сделайте следующее. Токен аутентификации кэшируется локально на некоторый период времени, поэтому этот процесс нужно повторять не каждый раз, а только по истечении срока действия токена. Когда истекает срок действия токена или появляются ошибки аутентификации, выполните следующие команды:

```
# to authenticate 
$ az login

# to list subscriptions
$ az account list -o table

# to set current subscription to a particular subscription ID 
$ az account set -s <subscription_id>

# to verify your current Azure subscription
$ az account show
```

>[!NOTE] 
>Перед выполнением команды _az ml_ в папке проекта убедитесь, что он относится к учетной записи службы "Экспериментирование в Машинном обучении Azure", которая включена в _текущую_ подписку Azure. В противном случае могут возникнуть ошибки выполнения.


## <a name="running-scripts-and-experiments"></a>Выполнение скриптов и экспериментов
С помощью Workbench вы можете выполнить скрипты Python и PySpark для разных целевых объектов вычислений, используя команду _az ml experiment submit_. Для этой команды нужно определить конфигурацию запуска. 

Приложение Workbench создает соответствующий RUNCONFIG-файл при создании целевого объекта вычислений. Но вы всегда можете создать дополнительные конфигурации запуска с помощью команды _az ml runconfiguration create_. Можно также вручную изменить файлы конфигурации запуска.

Конфигурации запуска отображаются в интерфейсе запуска эксперимента в приложении Workbench. 

>[!NOTE]
>Дополнительные сведения о файле конфигурации запуска вы найдете в статье о [конфигурации выполнения экспериментов](experimentation-service-configuration-reference.md).

## <a name="running-a-script-locally-on-workbench-installed-runtime"></a>Локальное выполнение скрипта в среде выполнения, которая установлена вместе с Workbench
Приложение Workbench позволяет выполнять скрипты непосредственно в среде выполнения Python 3.5.2, которая установлена вместе с Workbench. Эта среда выполнения по умолчанию устанавливается одновременно с Workbench и включает все библиотеки и зависимости службы "Машинное обучение Azure". Результаты запусков и артефакты для локального выполнения по-прежнему сохраняются в облачной службе журнала запусков.

В отличие от выполнений на основе Docker эта конфигурация _не_ использует Conda. Пакеты зависимостей для локальной среды Python в Workbench нужно подготовить вручную.

Для локального запуска скрипта в среде Python, которая установлена вместе с Workbench, выполните следующую команду: 

```
$az ml experiment submit -c local myscript.py
```

Чтобы определить путь к среде Python по умолчанию, введите следующую команду в окне командной строки в Workbench:
```
$ conda env list
```

>[!NOTE]
>Локальное выполнение PySpark с прямым обращением к локальной среде Spark в данный момент **не** поддерживается. Приложение Workbench поддерживает запуск скриптов PySpark в локальном контейнере Docker. Базовый образ Docker для службы "Машинное обучение Azure" поставляется с предустановленным проектом Spark 2.1.11. 

_**Обзор локального выполнения скриптов Python.**_
![](media/experimentation-service-configuration/local-native-run.png)

## <a name="running-a-script-on-local-docker"></a>Выполнение скрипта на локальном Docker
Вы можете выполнять проекты в контейнере Docker на локальном компьютере при помощи службы "Экспериментирование". Приложение Workbench содержит базовый образ Docker в комплекте с библиотеками службы "Машинное обучение Azure" и средой выполнения Spark 2.1.11, что упрощает локальное выполнение Spark. На локальном компьютере уже должен работать Docker.

Чтобы запустить скрипт Python или PySpark на локальном Docker, выполните следующие команды в интерфейсе командной строки.

```
$az ml experiment submit -c docker myscript.py
```
или
```
az ml experiment submit --run-configuration docker myscript.py
```

Среда выполнения в локальном контейнере Docker подготавливается на основе базового образа Docker для службы "Машинное обучение Azure". Приложение Workbench загружает этот образ при первом запуске и дополняет его пакетами, указанными в пользовательском файле conda_dependencies.yml. Этот процесс замедляет первый запуск среды, но все последующие запуски будут значительно быстрее благодаря кэшированию слоев в Workbench. 

>[!IMPORTANT]
>Для подготовки образа Docker к первому запуску нужно запустить команду _az ml experiment prepare -c docker_. Также вы можете задать значение true для параметра **PrepareEnvironment** в файле docker.runconfig. В этом случае среда будет автоматически подготавливаться в процессе запуска.  

>[!NOTE]
>Если вы запускаете скрипт PySpark на Spark, помимо файла conda_dependencies.yml будет использоваться еще и spark_dependencies.yml.

Выполнение скриптов в образе Docker дает вам следующие преимущества.

1. Вы можете быть уверены, что скрипт можно выполнять в других средах выполнения. Контейнер Docker помогает обнаружить и обойти любые локальные ссылки, которые плохо влияют на переносимость. 

2. Вы можете быстро проверить код для разных сред выполнения и платформ, которые требуют сложной установки и настройки, таких как Apache Spark, без необходимости устанавливать их.


_**Обзор выполнения на локальном Docker скриптов Python.**_
![](media/experimentation-service-configuration/local-docker-run.png)

## <a name="running-a-script-on-a-remote-docker"></a>Выполнение скрипта на удаленном Docker
Иногда для обучения используемой модели ресурсов локального компьютера недостаточно. Для таких случаев в службе "Экспериментирование" предусмотрена возможность запустить скрипт Python или PySpark на более мощной виртуальной машине с выполнением в удаленном контейнере Docker. 

Удаленная виртуальная машина должна соответствовать следующим требованиям.
* Удаленная виртуальная машина должна работать под управлением Linux Ubuntu и должна быть доступна по протоколу SSH. 
* На удаленной виртуальной машине должен выполняться Docker.

>[!IMPORTANT]
> Виртуальные машины Windows, на которых выполняется Docker, **не** поддерживаются в качестве удаленных целевых объектов вычислений.


Вы можете создать определение целевого объекта вычислений и конфигурации запуска для удаленного выполнения на основе Docker, используя следующую команду:

```
az ml computetarget attach remotedocker --name "remotevm" --address "remotevm_IP_address" --username "sshuser" --password "sshpassword" 
```

Когда вы завершите настройку целевого объекта вычислений, используйте следующую команду для запуска скрипта.
```
$ az ml experiment submit -c remotevm myscript.py
```
>[!NOTE]
>Следует помнить, что среда выполнения настраивается по параметрам, указанным в файле conda_dependencies.yml. Также используется файл spark_dependencies.yml, если в файле .runconfig указана платформа PySpark. 

Процесс построения Docker для удаленных виртуальных машин выполняется точно так же, как и для локального Docker, поэтому и выполнение будет проходить одинаково.

>[!TIP]
>Если вы хотите избежать задержки на построение образа Docker для первого запуска, используйте следующую команду для подготовки целевого объекта вычислений перед запуском скрипта. az ml experiment prepare -c remotedocker

_**Обзор удаленного выполнения скриптов Python на виртуальных машинах.**_
![](media/experimentation-service-configuration/remote-vm-run.png)

## <a name="running-a-script-on-a-remote-vm-targeting-user-managed-environments"></a>Выполнение скрипта на удаленной виртуальной машине с поддержкой окружений, управляемых пользователем
Служба "Экспериментирование" также поддерживает выполнение скрипта в собственном пользовательском окружении Python на удаленной виртуальной машине Ubuntu. Это позволяет управлять окружением для выполнения и при этом использовать возможности службы "Машинное обучение Azure". 

Выполните следующие действия, чтобы запустить скрипт в собственном окружении.
* Подготовьте окружение Python на удаленной виртуальной машине Ubuntu или на виртуальной машине для обработки и анализа данных, устанавливающей зависимости.
* Установите требования службы "Машинное обучение Azure" с помощью следующей команды.

```
pip install -I --index-url https://azuremldownloads.azureedge.net/python-repository/preview --extra-index-url https://pypi.python.org/simple azureml-requirements
```

>[!TIP]
>В некоторых случаях может потребоваться выполнить эту команду в режиме sudo в зависимости от ваших прав доступа. 
```
sudo pip install -I --index-url https://azuremldownloads.azureedge.net/python-repository/preview --extra-index-url https://pypi.python.org/simple azureml-requirements
```
 
* Используйте следующую команду, чтобы создать определение целевого объекта вычислений и конфигурацию запуска для управляемого пользователем выполнения на удаленной виртуальной машине.
```
az ml computetarget attach remote --name "remotevm" --address "remotevm_IP_address" --username "sshuser" --password "sshpassword" 
```
>[!NOTE]
>Эта команда присвоит значение true параметру userManagedEnvironment в файле конфигурации .compute.

* Задайте расположение исполняемого файла среды выполнения Python в файле .compute. Вы должны проверить полный путь к исполняемому файлу Python. 
```
pythonLocation: python3
```

Когда вы завершите настройку целевого объекта вычислений, используйте следующую команду для запуска скрипта.
```
$ az ml experiment submit -c remotevm myscript.py
```

>[!NOTE]
> При выполнении скрипта на виртуальной машине для обработки и анализа данных используйте следующие команды:

Если вы хотите выполнить скрипт непосредственно в глобальной среде Python DSVM виртуальной машины для обработки и анализа данных, выполните следующую команду.
```
sudo /anaconda/envs/py35/bin/pip install <package>
```


## <a name="running-a-script-on-an-hdinsight-cluster"></a>Запуск скрипта в кластере HDInsight
HDInsight — это популярная платформа для анализа больших данных, которая поддерживает Apache Spark. Приложение Workbench позволяет выполнять эксперименты с большими данными в кластерах HDInsight Spark. 

>[!NOTE]
>Кластер HDInsight должен использовать в качестве основного хранилища хранилище BLOB-объектов Azure. Использование хранилища Azure Data Lake еще не поддерживается.

Вы можете создать целевой объект вычислений и запустить конфигурацию кластера HDInsight Spark с помощью следующей команды:

```
$ az ml computetarget attach cluster --name "myhdi" --address "<FQDN or IP address>" --username "sshuser" --password "sshpassword"  
```

>[!NOTE]
>Если вы будете использовать полное доменное имя вместо IP-адреса, имя кластера HDI Spark с именем _foo_ узел драйвера, на котором располагается конечная точка SSH, будет таким: _foo-ssh.azurehdinsight.net_. Не забывайте про постфикс **-ssh** в имени сервера, когда используете полное доменное имя для параметра _--address_.


Получив контекст вычислений, вы можете использовать следующую команду для выполнения скрипта PySpark.

```
$ az ml experiment submit -c myhdi myscript.py
```

Приложение Workbench подготавливает среду выполнения HDInsight и управляет ею с помощью Conda. Конфигурация определяется файлами _conda_dependencies.yml_ и _spark_dependencies.yml_. 

Чтобы выполнять эксперименты в этом режиме, нужен доступ к кластеру HDInsight по протоколу SSH. 

>[!NOTE]
>Поддерживается только выполнение кластеров HDInsight Spark под управлением Linux (Ubuntu для Python и PySpark 3.5.2 и Spark 2.1.11).

_**Общие сведения о выполнении скриптов PySpark под управлением PySpark**_
![](media/experimentation-service-configuration/hdinsight-run.png)


## <a name="running-a-script-on-gpu"></a>Выполнение скрипта на графическом процессоре
Чтобы выполнить скрипты на графическом процессоре, следуйте инструкциям в статье [Как использовать GPU в службе "Машинное обучение Azure"](how-to-use-gpu.md).

## <a name="using-ssh-key-based-authentication-for-creating-and-using-compute-targets"></a>Выполнение аутентификации на основе ключа SSH для создания и использования целевых объектов вычислений
Рабочая среда Azure Machine Learning Workbench позволяет создавать и использовать целевые объекты вычислений с помощью аутентификации на основе ключа SSH в дополнение к схеме на основе имени пользователя и пароля. Эту возможность можно задействовать при использовании remotedocker или кластера в качестве целевого объекта вычислений. При использовании этой схемы среда Workbench создает пару открытого и закрытого ключей и передает открытый ключ обратно. Открытый ключ следует присоединить к файлам ~/.ssh/authorized_keys для вашего имени пользователя. Затем Azure Machine Learning Workbench использует аутентификацию на основе ключей ssh для доступа и выполнения на этом целевом объекте вычислений. Так как закрытый ключ для целевого объекта вычислений сохраняется в хранилище ключей для рабочей области, другие пользователи рабочей области могут использовать целевой объект вычислений таким же образом, предоставляя указанное имя пользователя для создания целевого объекта вычислений.  

Для использования этой функции нужно сделать следующее: 

- Создайте целевой объект вычислений с помощью одной из следующих команд.

```
az ml computetarget attach remotedocker --name "remotevm" --address "remotevm_IP_address" --username "sshuser" --use-azureml-ssh-key
```
или
```
az ml computetarget attach remotedocker --name "remotevm" --address "remotevm_IP_address" --username "sshuser" -k
```
- Добавьте открытый ключ, созданный средой Workbench, в файл ~/.ssh/authorized_keys в подключенном целевом объекте вычислений. 

>[!IMPORTANT]
>Необходимо войти в целевой объект вычислений с тем же именем пользователя, которое использовалось для создания целевого объекта вычислений. 

- Теперь можно подготовить и использовать целевой объект вычислений с применением аутентификации на основе ключей SSH.

```
az ml experiment prepare -c remotevm
```

## <a name="next-steps"></a>Дополнительная информация
* [Create Azure Machine Learning preview accounts and install Azure Machine Learning Workbench](../service/quickstart-installation.md) (Создание учетных записей для предварительной версии Машинного обучения Azure и установка Azure Machine Learning Workbench).
* [Управление моделями](model-management-overview.md)
