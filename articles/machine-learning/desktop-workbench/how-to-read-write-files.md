---
title: Чтение и запись больших файлов данных | Документация Майкрософт
description: Чтение и запись больших файлов в экспериментах службы "Машинное обучение Azure".
services: machine-learning
author: hning86
ms.author: haining
manager: mwinkle
ms.reviewer: jmartens, jasonwhowell, mldocs
ms.service: machine-learning
ms.component: desktop-workbench
ms.workload: data-services
ms.topic: article
ms.date: 09/10/2017
ms.openlocfilehash: 3e7436c4b69a27931238ea80304231394074ffe3
ms.sourcegitcommit: 944d16bc74de29fb2643b0576a20cbd7e437cef2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/07/2018
ms.locfileid: "34831100"
---
# <a name="persisting-changes-and-working-with-large-files"></a>Сохранение изменений и работа с большими файлами
В службе "Экспериментирование в Машинном обучении Azure" можно настраивать различные целевые объекты выполнения. Некоторые из целевых объектов являются локальными, например локальный компьютер или контейнер Docker на локальном компьютере. Другие — удаленными, например контейнер Docker на удаленном компьютере или кластер HDInsight. Дополнительные сведения см. в разделе [Общие сведения о службе выполнения экспериментов в Машинном обучении Azure](experimentation-service-configuration.md). 

Перед выполнением для выбранного целевого объекта необходимо скопировать папку проекта в целевой объект вычислений. Это нужно выполнить даже при локальном выполнении, для которого в этих целях используется локальная временная папка. 

## <a name="execution-isolation-portability-and-reproducibility"></a>Изоляция, переносимость и воспроизводимость выполнения
Цель данной схемы — обеспечить изоляцию, повторяемость и переносимость выполнения. Если дважды выполнить один и тот же сценарий для того же или другого целевого объекта вычислений, то полученные результаты будут одинаковыми. Изменения, внесенные во время первого выполнения, не должны влиять на второе выполнение. Такая схема работы позволяет использовать целевые объекты вычислений как вычислительные ресурсы без сохранения состояния, которые не сопоставляются с уже завершенными заданиями.

## <a name="challenges"></a>Сложности
Наряду с преимуществами переносимости и повторяемости такой подход вызывает некоторые уникальные трудности.

### <a name="persisting-state-changes"></a>Сохранение изменений состояния
Если сценарий изменяет состояние в контексте вычислений, эти изменения не сохраняются для следующего выполнения и не распространяются автоматически обратно на клиентский компьютер. 

В частности, если сценарий создает вложенную папку или записывает файл, то эта папка или файл будет отсутствовать в каталоге проекта после выполнения. Файлы хранятся во временной папке в среде целевого объекта вычислений. Их можно использовать для отладки, но не следует полагаться на их постоянное наличие.

### <a name="working-with-large-files-in-the-project-folder"></a>Работа с большими файлами в папке проекта

Если папка проекта содержит большие файлы, это увеличивает задержку при копировании папки в целевую вычислительную среду перед началом каждого выполнения. Даже если выполнение происходит локально, это приводит к ненужной нагрузке на диск, которой следует избежать. По этой причине в настоящее время мы ограничиваем максимальный размер проекта 25 мегабайтами.

## <a name="option-1-use-the-outputs-folder"></a>Вариант 1. Папка *outputs*
Этот вариант является предпочтительным, если выполняются следующие условия:
* сценарий создает файлы;
* ожидается, что файлы будут изменяться при каждом эксперименте;
* вы хотите сохранить журнал этих файлов. 

Типичные варианты использования:
* Обучение модели
* создание набора данных;
* отображение диаграммы в виде файла изображения при обучении модели. 

Кроме того, вы хотите сравнить выходные данные разных выполнений или выбрать файл выходных данных (например, модель), полученный при предыдущем выполнении, чтобы использовать его для следующей задачи (например, для оценки).

Вы можете записать нужные файлы в папку *outputs*, расположенную в корневом каталоге. С этой папкой служба "Экспериментирование" взаимодействует особо. После завершения выполнения все _артефакты_, которые создаются в ней во время выполнения сценария (файл модели, файл данных или файл изображения), копируются в учетную запись хранения больших двоичных объектов, связанную с учетной записью службы "Экспериментирование". Эти файлы становятся частью записи в журнале выполнения.

Ниже приведен краткий пример кода для сохранения модели в папке *outputs*.
```python
import os
import pickle

# m is a scikit-learn model. 
# we serialize it into a mode.plk file under the ./outputs folder.
with open(os.path.join('.', 'outputs', 'model.pkl'), 'wb') as f:    
    pickle.dump(m, f)
```
Вы можете скачать любой артефакт, перейдя к разделу **Выходные файлы** на странице информации о конкретном выполнении в Azure Machine Learning Workbench. Просто выберите нужное выполнение и нажмите кнопку **Скачать**. Кроме того, можно ввести команду `az ml asset download` в окне интерфейса командной строки.

Более подробный пример представлен в сценарии Python `iris_sklearn.py` в примере проекта _Классификация цветков ириса_.

## <a name="option-2-use-the-shared-folder"></a>Вариант 2. Общая папка
В некоторых случаях, перечисленных ниже, очень удобно использовать общую папку, к которой можно обращаться из разных независимых выполнений, если вам не нужно сохранять в журнале состояние этих файлов после каждого выполнения. 
- Ваш сценарий использует данные для обучения или тестирования из локальных файлов, например CSV-файлов, текстовых или графических файлов. 
- Ваш сценарий принимает необработанные данные и сохраняет промежуточные результаты, например для присвоения признаков по обучающим данным из текстовых или графических файлов, и эти сохраненные результаты используются в последующих обучающих запусках. 
- Ваш сценарий выдает модель, а следующий сценарий оценки выбирает одну из нескольких моделей и использует ее для оценки. 

Важно отметить, что общая папка размещается локально в выбранном целевом объекте вычислений. Поэтому этот вариант подходит только в том случае, если все ваши сценарии, ссылающиеся на эту общую папку, выполняются на одном целевом объекте вычислений, и который не очищается между выполнениями.

Используя преимущества общей папки, можно выполнять чтение или запись в специальную папку, путь к которой определяется переменной среды `AZUREML_NATIVE_SHARE_DIRECTORY`. 

### <a name="example"></a>Пример
Ниже приведен пример кода Python для чтения и записи текстового файла в общей папке.
```python
import os

# write to the shared folder
with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + 'test.txt', 'wb') as f:
    f.write(“Hello World”)

# read from the shared folder
with open(os.environ['AZUREML_NATIVE_SHARE_DIRECTORY'] + 'test.txt', 'r') as f:
    text = file.read()
```

Более подробный пример представлен в файле *iris_sklearn_shared_folder.py* в примере проекта _Классификация цветков ириса_.

Прежде чем использовать эту функцию, нужно внести в *COMPUTE-файл* несколько несложных изменений, которые описывают целевой контекст выполнения в папке *aml_config*. Фактический путь к этой папке вы можете настроить произвольно с учетом особенностей целевого объекта вычислений.

### <a name="configure-local-compute-context"></a>Настройка локального контекста вычислений

Чтобы включить эту функцию в локальном контексте вычислений, просто добавьте в *COMPUTE-файл* следующую строку, которая описывает _локальную_ среду (обычно с именем *local.compute*).
```
# local.runconfig
...
nativeSharedDirectory: ~/.azureml/share
...
```

По умолчанию используется путь ~/.azureml/share к базовой папке. Вы можете указать вместо него любой полный локальный путь, к которому есть доступ у выполняемого сценария. Чтобы получить полный путь к общей папке, к имени базовой папки автоматически добавляются имя учетной записи службы "Экспериментирование", имя рабочей области и имя проекта. Например, если вы сохраните указанное выше значение по умолчанию, файлы можно будет записывать в папку по следующему пути (и потом считывать оттуда):

```
# on Windows
C:\users\<username>\.azureml\share\<exp_acct_name>\<workspace_name>\<proj_name>\

# on macOS
/Users/<username>/.azureml/share/<exp_acct_name>/<workspace_name>/<proj_name>/
```

### <a name="configure-the-docker-compute-context-local-or-remote"></a>Настройка контекста вычислений Docker (локального или удаленного)
Чтобы включить эту функцию в контексте вычислений Docker, следует добавить следующие две строки в *COMPUTE-файл* для локального или удаленного Docker.

```
# docker.compute
...
sharedVolumes: true
nativeSharedDirectory: ~/.azureml/share
...
```
>[!IMPORTANT]
>Свойство **sharedVolumes** должно иметь значение *true*, если вы используете переменную среды `AZUREML_NATIVE_SHARE_DIRECTORY` для доступа к общей папке. В противном случае произойдет сбой выполнения.

Код, выполняющийся в контейнере Docker, всегда видит эту общую папку по адресу */azureml-share/*. Путь к папке, который используется в контейнере Docker, настроить невозможно. Не используйте это имя папки в коде. Для ссылки на эту папку всегда используйте имя переменной среды `AZUREML_NATIVE_SHARE_DIRECTORY`. Она сопоставляется с локальной папкой в контексте хост-компьютера Docker или контекста вычислений. Имя базовой папки для этой локальной папки можно настроить в параметре `nativeSharedDirectory` в *COMPUTE-файле*. Если используется значение по умолчанию, локальный путь к общей папке на хост-компьютере выглядит следующим образом.
```
# Windows
C:\users\<username>\.azureml\share\<exp_acct_name>\<workspace_name>\<proj_name>\

# macOS
/Users/<username>/.azureml/share/<exp_acct_name>/<workspace_name>/<proj_name>/

# Ubuntu Linux
/home/<username>/.azureml/share/<exp_acct_name>/<workspace_name>/<proj_name>/
```

>[!NOTE]
>Путь к общей папке на локальном диске совпадает в локальном контексте вычислений и в контексте вычислений для локального Docker. Это позволяет даже совместно использовать файлы из запусков в локальном контексте и в локальном Docker.

Вы можете напрямую поместить входные данные в эти папки, и тогда выполняемые локально или в локальном Docker сценарии смогут обращаться к этим данным. И наоборот, выполняемые локально или в локальном Docker скрипты могут записывать файлы в эту папку, чтобы сохранить данные после завершения выполнения.

Дополнительные сведения см. в разделе [Файлы конфигурации выполнения Azure Machine Learning Workbench](experimentation-service-configuration-reference.md).

>[!NOTE]
>Переменная среды `AZUREML_NATIVE_SHARE_DIRECTORY` не поддерживается в контексте вычислений HDInsight. Но вы можете легко получить аналогичный результат, явно указав абсолютный путь к хранилищу BLOB-объектов Azure для чтения данных из подключенного хранилища BLOB-объектов и записи в него.

## <a name="option-3-use-external-durable-storage"></a>Вариант 3. Внешнее долговременное хранилище

Вы всегда можете применить внешнее долговременное хранилище для сохранения состояния во время выполнения. Этот вариант удобен в следующих случаях:
- Входные данные уже хранятся в долговременном хранилище, которое доступно из целевой вычислительной среды.
- Эти файлы не нужны в записях журнала выполнения.
- Эти файлы должны совместно использоваться для выполнений в различных вычислительных средах.
- Эти файлы должны сохраняться даже после удаления контекста вычислений.

Например, вы можете использовать хранилище BLOB-объектов Azure из кода Python или PySpark. Ниже приведен краткий пример.

```python
from azure.storage.blob import BlockBlobService
import glob
import os

ACCOUNT_NAME = "<your blob storage account name>"
ACCOUNT_KEY = "<account key>"
CONTAINER_NAME = "<container name>"

blob_service = BlockBlobService(account_name=ACCOUNT_NAME, account_key=ACCOUNT_KEY)

## Create a new container if necessary, or use an existing one
my_service.create_container(CONTAINER_NAME, fail_on_exist=False, public_access=PublicAccess.Container)

# df is a pandas DataFrame
df.to_csv('mydata.csv', sep='\t', index=False)

# Export the mydata.csv file to Blob storage.
for name in glob.iglob('mydata.csv'):
    blob_service.create_blob_from_path(CONTAINER_NAME, 'single_file.csv', name)
```

Это краткий пример для подключения произвольного хранилища BLOB-объектов Azure к среде выполнения HDI Spark.
```python
def attach_storage_container(spark, account, key):
    config = spark._sc._jsc.hadoopConfiguration()
    setting = "fs.azure.account.key." + account + ".blob.core.windows.net"
    if not config.get(setting):
        config.set(setting, key)
 
attach_storage_container(spark, "<storage account name>", "<storage key>”)
```

## <a name="conclusion"></a>Заключение
Так как служба "Машинное обучение Azure" выполняет сценарии, копируя весь проект в контекст целевого объекта вычислений, следует уделить особое внимание большим входным данным, выходным и временным файлам. Для транзакций с большими файлами вы можете использовать специальную папку выходных данных, общую папку, путь к которой хранится в переменной среды `AZUREML_NATIVE_SHARE_DIRECTORY`, или внешнее долговременное хранилище. 

## <a name="next-steps"></a>Дополнительная информация
- Ознакомьтесь со статьей [Файлы конфигурации выполнения Azure Machine Learning Workbench](experimentation-service-configuration-reference.md).
- Узнайте, как в учебном проекте [Классификация цветков ириса](tutorial-classifying-iris-part-1.md) используется папка выходных данных для долговременного сохранения обученной модели.
