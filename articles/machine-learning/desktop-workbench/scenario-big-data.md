---
title: Прогнозирование рабочей нагрузки сервера в Azure на основе терабайтов данных | Документация Майкрософт
description: Сведения о том, как обучить модель машинного обучения на основе больших данных в Azure Machine Learning Workbench.
services: machine-learning
documentationcenter: ''
author: daden
manager: mithal
editor: daden
ms.assetid: ''
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.component: desktop-workbench
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 09/15/2017
ms.author: daden
ms.openlocfilehash: 450c033fbce3544cdc17ddc6d47ff726b01a4d3e
ms.sourcegitcommit: 944d16bc74de29fb2643b0576a20cbd7e437cef2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/07/2018
ms.locfileid: "34832668"
---
# <a name="server-workload-forecasting-on-terabytes-of-data"></a>Прогнозирование рабочей нагрузки сервера на основе терабайтов данных

В этой статье рассказывается, как специалисты по обработке и анализу данных могут применять Azure Machine Learning Workbench для разработки решений, которые требуют использования больших данных. Взяв выборку из большого набора данных, вы можете подготовить данные, спроектировать признаки, применить модели машинного обучения, а затем выполнить все это для полного большого набора данных. 

Вы узнаете о следующих основных возможностях Machine Learning Workbench:
* Простое переключение между целевыми объектами вычисления. Вы можете настроить различные целевые объекты вычисления и использовать их при экспериментировании. В этом примере как целевые объекты вычисления мы используем виртуальную машину для обработки и анализа данных Ubuntu и кластер Azure HDInsight. Можно также настраивать целевые объекты вычисления в зависимости от доступности ресурсов. В частности, после добавления к кластеру Spark рабочих узлов вы можете использовать ресурсы с помощью Machine Learning Workbench для ускорения экспериментов.
* Отслеживание журнала выполнения. Machine Learning Workbench можно использовать для отслеживания эффективности моделей машинного обучения и других необходимых метрик.
* Ввод модели машинного обучения в эксплуатацию. Встроенные средства Machine Learning Workbench можно использовать, чтобы развернуть обученную модель машинного обучения как веб-службу в Службе контейнеров Azure (ACS). Можно также использовать веб-службу, чтобы получать мини-пакеты прогнозов при помощи вызовов REST API. 
* Поддержка терабайтов данных.

> [!NOTE]
> Примеры кода и другие материалы, относящиеся к этому примеру, см. на [GitHub](https://github.com/Azure/MachineLearningSamples-BigData).
> 

## <a name="use-case-overview"></a>Обзор варианта использования

Прогнозирование рабочей нагрузки серверов — это обычное бизнес-требование для технологических компаний, которые управляют своей собственной инфраструктурой. Чтобы сократить затраты на инфраструктуру, службы, которые выполняются на мало использующихся серверах, нужно сгруппировать, чтобы запускать их на меньшем числе компьютеров. Службам, которые выполняются на серверах с большой нагрузкой, необходимо предоставить больше компьютеров. 

В этом сценарии мы рассмотрим прогноз рабочей нагрузки для каждого компьютера (или сервера). В частности, вы используете данные сеансов для каждого сервера, чтобы спрогнозировать класс его рабочей нагрузки в будущем. Вы присвоите класс (низкий, средний или высокий) нагрузке каждого сервера с помощью классификатора случайного леса в [Apache Spark ML](https://spark.apache.org/docs/2.1.1/ml-guide.html). Методы и рабочий процесс машинного обучения в этом примере можно легко применять для решения других подобных проблем. 


## <a name="prerequisites"></a>предварительным требованиям

Предварительные требования для выполнения этого сценария:

* [Учетная запись Azure](https://azure.microsoft.com/free/) (доступны бесплатные пробные версии).
* Установленная копия [Azure Machine Learning Workbench](../service/overview-what-is-azure-ml.md). Чтобы установить эту программу и создать рабочую область, выполните инструкции из [краткого руководства по установке](../service/quickstart-installation.md). Если у вас несколько подписок, вы можете [указать нужную подписку в качестве текущей активной подписки](https://docs.microsoft.com/cli/azure/account?view=azure-cli-latest#az_account_set).
* Windows 10 (если вы используете macOS, большинство инструкций будут аналогичными).
* Виртуальная машина для обработки и анализа данных для Linux (Ubuntu), желательно в регионе "Восточная часть США", где расположены данные. Вы можете подготовить виртуальную машину для обработки и анализа данных Ubuntu, выполнив эти [инструкции](https://docs.microsoft.com/azure/machine-learning/data-science-virtual-machine/dsvm-ubuntu-intro). Просмотрите также это [краткое руководство](https://ms.portal.azure.com/#create/microsoft-ads.linux-data-science-vm-ubuntulinuxdsvmubuntu). Рекомендуем использовать виртуальную машину с как минимум 8 ядрами и 32 ГБ памяти. 

Выполните [инструкции](../service/known-issues-and-troubleshooting-guide.md#remove-vm-execution-error-no-tty-present), чтобы включить доступ без пароля для пользователя с правами sudo на виртуальной машине для AML Workbench.  Вы также можете использовать [аутентификацию на основе ключей SSH для создания и использования виртуальной машины в AML Workbench](experimentation-service-configuration.md#using-ssh-key-based-authentication-for-creating-and-using-compute-targets). В этом примере для доступа к виртуальной машине мы используем пароль.  Сохраните таблицу ниже с данными виртуальной машины для обработки и анализа данных для выполнения дальнейших действий:

 Имя поля| Значение |  
 |------------|------|
IP-адрес виртуальной машины для обработки и анализа данных | xxx|
 Имя пользователя  | xxx|
 Пароль   | xxx|


 Вы можете использовать любую виртуальную машину с установленной [подсистемой Docker](https://docs.docker.com/engine/).

* Кластер HDInsight Spark с Hortonworks Data Platform 3.6 и Spark 2.1.x, желательно в регионе "Восточная часть США", где расположены данные. Дополнительные сведения по созданию кластеров HDInsight см. в статье [Создание кластера Apache Spark в Azure HDInsight](https://docs.microsoft.com/azure/hdinsight/hdinsight-hadoop-provision-linux-clusters). Рекомендуем использовать кластер с тремя рабочими узлами (по 16 ядер и 112 ГБ памяти в каждом). Или можно выбрать тип виртуальной машины `D12 V2` для головного узла и `D14 V2` для рабочего узла. Развертывание кластера занимает около 20 минут. Чтобы воспользоваться этим примером, необходимо указать имя кластера, имя пользователя SSH и пароль. Сохраните таблицу ниже с данными кластера HDInsight для выполнения дальнейших действий:

 Имя поля| Значение |  
 |------------|------|
 Имя кластера| xxx|
 Имя пользователя  | xxx (по умолчанию — sshuser)|
 Пароль   | xxx|


* Учетная запись хранения Azure. Вы можете создать ее, выполнив [эти инструкции](https://docs.microsoft.com/azure/storage/common/storage-create-storage-account). Кроме того, создайте в этой учетной записи хранения два частных контейнера больших двоичных объектов с именами `fullmodel` и `onemonthmodel`. Учетная запись хранения используется для сохранения промежуточных результатов вычислений и моделей машинного обучения. Чтобы воспользоваться этим примером, необходимо указать имя учетной записи хранения и ключ доступа. Сохраните таблицу ниже с данными учетной записи хранения Azure для выполнения дальнейших действий:

 Имя поля| Значение |  
 |------------|------|
 Имя учетной записи хранения| xxx|
 Ключ доступа  | xxx|


Целевыми объектами вычисления являются созданные в рамках предварительных требований виртуальная машина для обработки и анализа данных Ubuntu и кластер Azure HDInsight. Целевые объекты вычисления — это вычислительные ресурсы, применяемые с Machine Learning Workbench, которые могут быть отличными от компьютера, где выполняется Machine Learning Workbench.   

## <a name="create-a-new-workbench-project"></a>Создание проекта в Workbench

Создайте проект, используя в качестве шаблона следующий пример:
1.  Откройте Machine Learning Workbench.
2.  На странице **Projects** (Проекты) щелкните знак **+** и выберите **New Project** (Создать проект).
3.  В области **Create New Project** (Создание проекта) введите информацию о новом проекте.
4.  В поле поиска **Search Project Templates** (Поиск шаблонов проектов) введите **Workload Forecasting on Terabytes Data** (Прогнозирование рабочей нагрузки на основе терабайтов данных) и выберите шаблон.
5.  Нажмите кнопку **Создать**.

Можно создать проект Machine Learning Workbench с предварительно созданным репозиторием Git, выполнив эти [инструкции](./tutorial-classifying-iris-part-1.md).  
Запустите проверку состояния `git status`, чтобы просмотреть данные состояния файлов для отслеживания версий.

## <a name="data-description"></a>Описание данных

Данные, которые используются в этом примере, — это синтезированные данные рабочей нагрузки сервера, размещенные в общедоступной учетной записи хранилища BLOB-объектов Azure в регионе "Восточная часть США". Сведения об учетной записи хранения представлены в формате wasb://<BlobStorageContainerName>@<StorageAccountName>.blob.core.windows.net/<path> в поле `dataFile` файла [`Config/storageconfig.json`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Config/fulldata_storageconfig.json). Можно использовать данные непосредственно из хранилища BLOB-объектов. Если с хранилищем одновременно работают несколько пользователей, вы можете использовать [azcopy](https://docs.microsoft.com/azure/storage/common/storage-use-azcopy-linux), чтобы скачать данные в собственное хранилище для удобства работы с экспериментом. 

Общий объем данных — около 1 ТБ. Каждый файл занимает около 1–3 ГБ и представлен в формате CSV без заголовка. Каждая строка данных представляет нагрузку для транзакции на конкретном сервере. Подробные сведения о схеме данных выглядят следующим образом:

Номер столбца | Имя поля| type | ОПИСАНИЕ |  
|------------|------|-------------|---------------|
1  | `SessionStart` | DateTime |    Время начала сеанса
2  |`SessionEnd`    | DateTime | Время окончания сеанса
3 |`ConcurrentConnectionCounts` | Целое число  | Количество одновременных подключений
4. | `MbytesTransferred` | Double | Нормализованные переданные данные в мегабайтах
5 | `ServiceGrade` | Целое число  |  Уровень службы для сеанса
6 | `HTTP1` | Целое число |  Используемый протокол для сеанса: HTTP1 или HTTP2
7 |`ServerType` | Целое число    |Тип сервера
8 |`SubService_1_Load` | Double |   Нагрузка подслужбы 1
9 | `SubService_2_Load` | Double |  Нагрузка подслужбы 2
10 | `SubService_3_Load` | Double |     Нагрузка подслужбы 3
11 |`SubService_4_Load` | Double |  Нагрузка подслужбы 4
12 | `SubService_5_Load`| Double |      Нагрузка подслужбы 5
13 |`SecureBytes_Load`  | Double | Безопасная нагрузка в байтах
14 |`TotalLoad` | Double | Общая нагрузка на сервер
15 |`ClientIP` | Строка|    IP-адрес клиента
16 |`ServerIP` | Строка|    IP-адрес сервера



Обратите внимание, что в предыдущей таблице перечислены ожидаемые типы данных. Из-за отсутствующих или некорректных значений типы данных могут отличаться от ожидаемых. Это следует учесть при обработке данных. 


## <a name="scenario-structure"></a>Структура сценария

Файлы в этом примере упорядочены следующим образом:

| Имя файла | type | ОПИСАНИЕ |
|-----------|------|-------------|
| `Code` | Папка | Папка содержит весь код в примере. |
| `Config` | Папка | Папка содержит файлы конфигурации. |
| `Image` | Папка | Папка используется для сохранения изображений для файла сведения (README). |
| `Model` | Папка | Папка используется для сохранения файлов модели, которые загружены из хранилища BLOB-объектов. |
| `Code/etl.py` | Файл Python | Файл используется для подготовки данных и проектирования признаков. |
| `Code/train.py` | Файл Python | Файл используется для обучения модели трех классов с множественной классификацией.  |
| `Code/webservice.py` | Файл Python | Файл используется для ввода в эксплуатацию.  |
| `Code/scoring_webservice.py` | Файл Python |  Файл используется для преобразования данных и вызова веб-службы. |
| `Code/O16Npreprocessing.py` | Файл Python | Файл используется для предварительной обработки данных для scoring_webservice.py  |
| `Code/util.py` | Файл Python | Файл содержит код для чтения и записи больших двоичных объектов Azure.  
| `Config/storageconfig.json` | Файл JSON | Файл конфигурации для контейнера больших двоичных объектов Azure. В нем хранятся промежуточные результаты и модель для обработки и обучения на основе данных за один месяц. |
| `Config/fulldata_storageconfig.json` | Файл JSON | Файл конфигурации для контейнера больших двоичных объектов Azure. В нем хранятся промежуточные результаты и модель для обработки и обучения на основе полного набора данных.|
| `Config/webservice.json` | Файл JSON | Файл конфигурации для scoring_webservice.py.|
| `Config/conda_dependencies.yml` | Файл YAML | Файл зависимостей Conda. |
| `Config/conda_dependencies_webservice.yml` | Файл YAML | Файл зависимостей Conda для веб-службы.|
| `Config/dsvm_spark_dependencies.yml` | Файл YAML | Файл зависимостей Spark для виртуальной машины для обработки и анализа данных Ubuntu. |
| `Config/hdi_spark_dependencies.yml` | Файл YAML | Файл зависимостей Spark для кластера HDInsight Spark. |
| `README.md` | Файл Markdown | Файл сведений в формате Markdown. |
| `Code/download_model.py` | Файл Python | Файл используется для загрузки файлов модели из хранилища BLOB-объектов Azure на локальный диск. |
| `Docs/DownloadModelsFromBlob.md` | Файл Markdown | Файл разметки содержит инструкции по запуску `Code/download_model.py`. |



### <a name="data-flow"></a>Поток данных

Код в [`Code/etl.py`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Code/etl.py) предназначен для загрузки данных из общедоступного контейнера (поле `dataFile` файла [`Config/storageconfig.json`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Config/fulldata_storageconfig.json)). Он охватывает подготовку данных и проектирование компонентов. Промежуточные результаты вычислений и модели сохраняются в частном контейнере. Код в [`Code/train.py`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Code/train.py) предназначен для загрузки промежуточных результатов вычислений из частного контейнера, обучения модели с многоклассовой классификацией и записи обученной модели в частный контейнер. 

Рекомендуется использовать отдельные контейнеры для экспериментов с набором данных за месяц и экспериментов с полным набором данных. Данные и модели сохраняются в файле Parquet. Поэтому каждый файл фактически является папкой в контейнере с несколькими большими двоичными объектами. Полученный контейнер выглядит следующим образом:

| Имя префикса большого двоичного объекта | type | ОПИСАНИЕ |
|-----------|------|-------------|
| featureScaleModel | PARQUET | Стандартная модель масштабирования для числовых признаков. |
| stringIndexModel | PARQUET | Модель индексатора строк для нечисловых признаков.|
| oneHotEncoderModel|PARQUET | Модель прямого кодирования для категориальных признаков. |
| mlModel | PARQUET | Обученная модель машинного обучения. |
| info| Сериализованный файл Python | Сведения о преобразованных данных. Включают время начала и окончания обучения, длительность, метку времени для разделения тестового обучения и столбцы для индексирования и прямого кодирования.

Все файлы и большие двоичные объекты в предыдущей таблице используются для ввода в эксплуатацию.


### <a name="model-development"></a>Разработка модели

#### <a name="architecture-diagram"></a>Схема архитектуры


На схеме ниже представлен полный рабочий процесс использования Machine Learning Workbench для разработки модели: ![архитектура](media/scenario-big-data/architecture.PNG)

Далее мы рассмотрим разработку модели с использованием функции для удаленных целевых объектов вычисления в Machine Learning Workbench. Сначала мы загрузим небольшое количество данных и выполним скрипт [`Code/etl.py`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Code/etl.py) на виртуальной машине для обработки и анализа данных Ubuntu для ускорения итерации. Мы можем еще больше сократить число операций в [`Code/etl.py`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Code/etl.py), передав дополнительный аргумент для ускорения итерации. В завершение мы используем кластер HDInsight для обучения на основе полного набора данных.     

Файл [`Code/etl.py`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Code/etl.py) предназначен для загрузки и подготовки данных, а также для проектирования признаков. Он принимает два аргумента:
* Файл конфигурации для контейнера хранилища BLOB-объектов, в котором будут храниться промежуточные результаты вычислений и модели.
* Аргумент конфигурации отладки для ускорения итерации.

Первый аргумент, `configFilename`, —это локальный файл конфигурации, где хранятся данные хранилища BLOB-объектов и указывается расположение для загрузки данных. По умолчанию это файл [`Config/storageconfig.json`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Config/storageconfig.json), который будет использоваться при обработке данных за один месяц. Кроме того, мы включили [`Config/fulldata_storageconfig.json`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Config/fulldatastorageconfig.json), который потребуется при обработке полного набора данных. Содержимое в конфигурации выглядит следующим образом: 

| Поле | type | ОПИСАНИЕ |
|-----------|------|-------------|
| storageAccount | Строка | Имя учетной записи хранения Azure |
| storageContainer | Строка | Контейнер в учетной записи хранения Azure для хранения промежуточных результатов |
| storageKey | Строка |Ключ доступа к учетной записи хранения Azure |
| dataFile|Строка | Файлы источника данных  |
| длительность| Строка | Период, который охватывают данные в файлах источника данных|

Измените `Config/storageconfig.json` и `Config/fulldata_storageconfig.json`, чтобы настроить учетную запись хранения, ключ к хранилищу данных и контейнер больших двоичных объектов для хранения промежуточных результатов. По умолчанию контейнер больших двоичных объектов для обработки данных за месяц — `onemonthmodel`, а контейнер больших двоичных объектов для полного набора данных — `fullmodel`. Убедитесь, что эти два контейнера созданы в учетной записи хранения. В поле `dataFile` файла [`Config/fulldata_storageconfig.json`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Config/fulldatastorageconfig.json) задается тип данных, которые загружаются в [`Code/etl.py`](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Code/etl.py). В поле `duration` задается интервал времени, который охватывают данные. Если установлен период ONE_MONTH, из семи файлов с данными загружаться должен только один CSV-файл за июнь 2016 г. Если для периода задано значение FULL, загружается полный набор данных объемом 1 ТБ. Не нужно изменять `dataFile` и `duration` в двух этих файлах конфигурации.

Второй аргумент — DEBUG. Задав для него значение FILTER_IP, можно ускорить итерацию. Этот параметр полезен при отладке скрипта.

> [!NOTE]
> Во всех командах ниже замените любую переменную аргумента фактическим значением.
> 


#### <a name="model-development-on-the-docker-of-ubuntu-dsvm"></a>Разработка модели при помощи Docker на виртуальной машине для обработки и анализа данных Ubuntu

#####  <a name="1-set-up-the-compute-target"></a>1. Настройка целевого объекта вычисления

Запустите командную строку из Machine Learning Workbench, выбрав **File (Файл)** > **Open Command Prompt (Открыть командную строку)**. Далее выполните: 

```az ml computetarget attach remotedocker --name dockerdsvm --address $DSVMIPaddress  --username $user --password $password ```

В папке проекта aml_config появятся два следующих файла:

-  dockerdsvm.compute: этот файл содержит сведения о подключении и конфигурации для удаленного целевого объекта выполнения.
-  dockerdsvm.runconfig: этот файл представляет собой набор параметров выполнения, используемый в приложении Workbench.

Перейдите к dockerdsvm.runconfig и измените конфигурацию следующих полей, задав такие значения:

    PrepareEnvironment: true 
    CondaDependenciesFile: Config/conda_dependencies.yml 
    SparkDependenciesFile: Config/dsvm_spark_dependencies.yml

Подготовьте среду проекта с помощью команды ниже.

```az ml experiment prepare -c dockerdsvm```


Если для параметра `PrepareEnvironment` задано значение true, Machine Learning Workbench будет создавать среду выполнения при каждой отправке задания. `Config/conda_dependencies.yml` и `Config/dsvm_spark_dependencies.yml` отвечают за настройку среды выполнения. Вы можете в любой момент изменить зависимости Conda, конфигурацию Spark и зависимости Spark, изменив эти два файла YAML. В этом примере мы добавили `azure-storage` и `azure-ml-api-sdk` как дополнительные пакеты Python в `Config/conda_dependencies.yml`. Кроме того, мы добавили `spark.default.parallelism`, `spark.executor.instances` и `spark.executor.cores` в `Config/dsvm_spark_dependencies.yml`. 

#####  <a name="2-data-preparation-and-feature-engineering-on-dsvm-docker"></a>2. Подготовка данных и проектирование компонентов на виртуальной машине для обработки и анализа данных Docker.

Запустите скрипт `etl.py` на виртуальной машине для обработки и анализа данных Docker: Используйте параметр отладки, который фильтрует загруженные данные по определенным IP-адресам серверов:

```az ml experiment submit -t dockerdsvm -c dockerdsvm ./Code/etl.py ./Config/storageconfig.json FILTER_IP```

Перейдите к боковой панели и щелкните **Run** (Выполнение), чтобы просмотреть журнал выполнения `etl.py`. Обратите внимание, что выполнение занимает около двух минут. Если вы планируете изменить код, включив новые признаки, можно указать FILTER_IP как второй аргумент, чтобы ускорить итерацию. При возникновении проблем с собственным машинным обучением вам может потребоваться выполнить этот шаг несколько раз, чтобы просмотреть набор данных или создать признаки. 

Настраиваемые ограничения данных для загрузки и последующая фильтрация данных для обработки ускоряют итерацию при разработке модели. Проводя эксперименты, периодически сохраняйте изменения в коде в репозиторий Git. Обратите внимание, что мы использовали в `etl.py` код ниже для обеспечения доступа к частному контейнеру:

```python
def attach_storage_container(spark, account, key):
    config = spark._sc._jsc.hadoopConfiguration()
    setting = "fs.azure.account.key." + account + ".blob.core.windows.net"
    if not config.get(setting):
        config.set(setting, key)

# attach the blob storage to the spark cluster or VM so that the storage can be accessed by the cluster or VM        
attach_storage_container(spark, storageAccount, storageKey)
```


Затем выполните скрипт `etl.py` на виртуальной машине для обработки и анализа данных Docker без параметра отладки FILTER_IP.

```az ml experiment submit -t dockerdsvm -c dockerdsvm ./Code/etl.py ./Config/storageconfig.json FALSE```

Перейдите к боковой панели и щелкните **Run** (Выполнение), чтобы просмотреть журнал выполнения `etl.py`. Обратите внимание, что выполнение занимает около четырех минут. Обработанный результат этого шага сохраняется в контейнере и загружается для обучения в train.py. Кроме того, индексаторы строк, конвейеры кодировщиков и стандартные средства маршрутизации сохраняются в частном контейнере. Они используются при вводе в эксплуатацию. 


##### <a name="3-model-training-on-dsvm-docker"></a>3. Обучение модели на виртуальной машине для обработки и анализа данных Docker

Запустите скрипт `train.py` на виртуальной машине для обработки и анализа данных Docker:

```az ml experiment submit -t dockerdsvm -c dockerdsvm ./Code/train.py ./Config/storageconfig.json```

При этом загружаются промежуточные результаты вычислений на основе выполнения `etl.py` и обучается модель машинного обучения. Этот этап занимает около двух минут.

После успешного выполнения экспериментов с небольшим объемом данных можно приступать к экспериментам с полным набором данных. Начать можно с того же кода, а затем поэкспериментировать, изменяя аргументы и целевые объекты вычисления.  

####  <a name="model-development-on-the-hdinsight-cluster"></a>Разработка модели в кластере HDInsight

##### <a name="1-create-the-compute-target-in-machine-learning-workbench-for-the-hdinsight-cluster"></a>1. Создание целевого объекта вычисления в Machine Learning Workbench для кластера HDInsight.

```az ml computetarget attach cluster --name myhdi --address $clustername-ssh.azurehdinsight.net --username $username --password $password```

В папке aml_config появятся два следующих файла:
    
-  myhdi.compute: этот файл содержит сведения о подключении и конфигурации для удаленного целевого объекта выполнения.
-  myhdi.runconfig: этот файл представляет собой набор параметров выполнения, используемый в приложении Workbench.


Перейдите к файлу myhdi.runconfig и измените конфигурацию следующих полей, задав такие значения:

    PrepareEnvironment: true 
    CondaDependenciesFile: Config/conda_dependencies.yml 
    SparkDependenciesFile: Config/hdi_spark_dependencies.yml

Подготовьте среду проекта с помощью команды ниже.

```az ml experiment prepare -c myhdi```

Этот этап может занять до семи минут.

##### <a name="2-data-preparation-and-feature-engineering-on-hdinsight-cluster"></a>2. Подготовка данных и проектирование компонентов в кластере HDInsight.

Запустите скрипт `etl.py` с полным набором данных в кластере HDInsight.

```az ml experiment submit -a -t myhdi -c myhdi ./Code/etl.py Config/fulldata_storageconfig.json FALSE```

Так как это задание выполняется в течение длительного периода времени (примерно два часа), можно использовать `-a` для отключения потоковой передачи выходных данных. После выполнения задания в разделе **Run History** (Журнал выполнения) можно просмотреть журналы драйверов и контроллеров. Для большого кластера в любой момент можно перенастроить конфигурации в `Config/hdi_spark_dependencies.yml` для использования нескольких экземпляров или ядер. Например, если в кластере четыре рабочих узла, можно увеличить значение `spark.executor.instances` с 5 до 7. Выходные данные этого действия можно просмотреть в контейнере **fullmodel** в вашей учетной записи хранения. 


##### <a name="3-model-training-on-hdinsight-cluster"></a>3. Обучение модели в кластере HDInsight

Запустите скрипт `train.py` в кластере HDInsight:

```az ml experiment submit -a -t myhdi -c myhdi ./Code/train.py Config/fulldata_storageconfig.json```

Так как это задание выполняется в течение длительного периода времени (примерно 30 минут), можно использовать `-a` для отключения потоковой передачи выходных данных.

#### <a name="run-history-exploration"></a>Просмотр журнала выполнения

Журнал выполнения — это компонент, который позволяет отслеживать ваши эксперименты в Machine Learning Workbench. По умолчанию отслеживается длительность экспериментов. В нашем конкретном примере, когда мы переходим к экспериментам с полным набором данных для `Code/etl.py`, длительность значительно увеличивается. Также можно вносить в журнал определенные метрики для отслеживания. Чтобы включить отслеживание метрики, добавьте в начало файла Python следующие строки кода:
```python
# import logger
from azureml.logging import get_azureml_logger

# initialize logger
run_logger = get_azureml_logger()
```
Ниже приведен пример для отслеживания конкретной метрики:

```python
run_logger.log("Test Accuracy", testAccuracy)
```

Перейдите к элементу **Runs** (Запуски) на правой боковой панели Machine Learning Workbench, чтобы просмотреть журнал выполнения для каждого файла Python. Вы также можете перейти в репозиторий GitHub. В репозитории создается ветвь с именем, которое начинается с AMLHistory. Она используется для отслеживания изменений, вносимых в скрипт при каждом запуске. 


### <a name="operationalize-the-model"></a>Ввод модели в эксплуатацию

В этом разделе вы введете модель, которую создали на предыдущих шагах, в эксплуатацию в качестве веб-службы. Вы также узнаете, как использовать веб-службу для прогнозирования рабочей нагрузки. Используйте интерфейсы командной строки (CLI) для ввода в эксплуатацию моделей машинного обучения, чтобы упаковать код и зависимости как образы Docker и опубликовать эту модель в качестве контейнерной веб-службы.

Чтобы запустить интерфейсы CLI в Azure Machine Learning Workbench, вы можете воспользоваться командной строкой.  Кроме того, можно запустить интерфейсы CLI в Ubuntu Linux, следуя инструкциям в [руководстве по установке](./deployment-setup-configuration.md#using-the-cli). 

> [!NOTE]
> Во всех командах ниже замените любую переменную аргумента фактическим значением. Выполнение задач в этом разделе займет около 40 минут.
> 

Выберите уникальную строку в качестве среды для ввода в эксплуатацию. Для ее представления мы используем строку [unique].

1. Создайте среду для ввода в эксплуатацию и группу ресурсов.

        az ml env setup -c -n [unique] --location eastus2 --cluster -z 5 --yes

   Обратите внимание, что вы можете использовать в качестве среды Службу контейнеров Azure при помощи `--cluster` в команде `az ml env setup`. Вы можете ввести модель машинного обучения в эксплуатацию в [Службе контейнеров Azure](https://docs.microsoft.com/azure/container-service/kubernetes/container-service-intro-kubernetes). Она использует [Kubernetes](https://kubernetes.io/) для автоматического развертывания и масштабирования приложений-контейнеров, а также управления ими. Выполнение этой команды занимает около 20 минут. Используйте следующую команду, чтобы проверить, успешно ли завершено развертывание. 

        az ml env show -g [unique]rg -n [unique]

   Установите среду развертывания так же, как и недавно созданную, выполнив следующую команду:

        az ml env set -g [unique]rg -n [unique]

2. Создайте учетную запись управления моделями и воспользуйтесь ею. Чтобы создать ее, выполните следующую команду:

        az ml account modelmanagement create --location  eastus2 -n [unique]acc -g [unique]rg --sku-instances 4 --sku-name S3 

   Используйте учетную запись управления моделями для ввода в эксплуатацию, выполнив следующую команду:

        az ml account modelmanagement set  -n [unique]acc -g [unique]rg  

   Учетная запись управления моделями используется для управления моделями и веб-службами. На портале Azure появится новая учетная запись управления моделями. Ее можно использовать для просмотра моделей, манифестов, образов Docker и служб, которые создаются с ее помощью.

3. Загрузите и зарегистрируйте модели.

   Загрузите модели в контейнере **fullmodel** на локальный компьютер в каталог кода. Не скачивайте файл данных Parquet с именем vmlSource.parquet. Он не является файлом модели, а содержит промежуточные результаты вычисления. Можно также повторно использовать файлы модели, помещенные в репозиторий Git. Дополнительные сведения см. на сайте [GitHub](https://github.com/Azure/MachineLearningSamples-BigData/blob/master/Docs/DownloadModelsFromBlob.md). 

   Перейдите в CLI в папку `Model` и зарегистрируйте модели, как показано ниже:

        az ml model register -m  mlModel -n vmlModel -t fullmodel
        az ml model register -m  featureScaleModel -n featureScaleModel -t fullmodel
        az ml model register -m  oneHotEncoderModel -n  oneHotEncoderModel -t fullmodel
        az ml model register -m  stringIndexModel -n stringIndexModel -t fullmodel
        az ml model register -m  info -n info -t fullmodel

   Выходные данные каждой команды содержат идентификатор модели, который используется в следующем шаге. Сохраните их в текстовый файл для последующего использования.

4. Создайте манифест для веб-службы.

   Манифест содержит код для веб-службы, всех моделей машинного обучения и зависимостей среды выполнения. В CLI перейдите к папке `Code` и запустите следующую команду:

        az ml manifest create -n $webserviceName -f webservice.py -r spark-py -c ../Config/conda_dependencies_webservice.yml -i $modelID1 -i $modelID2 -i $modelID3 -i $modelID4 -i $modelID5

   Выходные данные содержат идентификатор манифеста для следующего шага. 

   В каталоге `Code` проверьте файл webservice.py, выполнив следующую команду: 

        az ml experiment submit -t dockerdsvm -c dockerdsvm webservice.py

5. Создайте образ Docker. 

        az ml image create -n [unique]image --manifest-id $manifestID

   Выходные данные содержат идентификатор образа для следующего шага, так как этот образ Docker используется в службе контейнеров. 

6. Разверните веб-службу в кластере службы контейнеров.

        az ml service create realtime -n [unique] --image-id $imageID --cpu 0.5 --memory 2G

   Выходные данные предоставляет идентификатор службы. Он потребуется, чтобы получить ключ авторизации и URL-адрес службы.

7. Вызовите веб-службу в коде Python, чтобы выполнить оценку мини-пакетов.

   Чтобы получить ключ авторизации, используйте следующую команду:

         az ml service keys realtime -i $ServiceID 

   Выполните команду ниже, чтобы получить URL-адрес оценки службы.

        az ml service usage realtime -i $ServiceID

   Замените содержимое `./Config/webservice.json` правильным URL-адресом оценки службы и ключом авторизации. Оставьте в исходном файле маркер носителя и замените часть xxx. 
   
   Перейдите в корневую папку проекта и протестируйте веб-службу, выполнив оценку мини-пакетов при помощи следующей команды:

        az ml experiment submit -t dockerdsvm -c dockerdsvm ./Code/scoring_webservice.py ./Config/webservice.json

8. Масштабируйте веб-службу. 

   Дополнительные сведения см. в статье о [масштабировании при вводе в эксплуатацию в кластере ACS](how-to-scale-clusters.md).
 

## <a name="next-steps"></a>Дополнительная информация

На этом примере мы показали, как использовать Machine Learning Workbench, чтобы обучить модель машинного обучения на основе больших данных и ввести ее в эксплуатацию. В частности, вы узнали, как настраивать и использовать различные целевые объекты вычисления и запускать журнал отслеживаемых метрик, а также как применять различные запуски.

Вы можете расширить код и изучить настройки перекрестной проверки и гиперпараметров. Дополнительные сведения о настройке перекрестной проверки и гиперпараметров доступны на [этом ресурсе GitHub](https://github.com/Azure/MachineLearningSamples-DistributedHyperParameterTuning).  

Дополнительные сведения о прогнозировании временных рядов см. на [этом ресурсе GitHub](https://github.com/Azure/MachineLearningSamples-EnergyDemandTimeSeriesForecasting).
