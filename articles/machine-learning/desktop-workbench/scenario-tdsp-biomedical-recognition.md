---
title: Распознавание биомедицинских сущностей. Командный процесс обработки и анализа данных. Машинное обучение Azure | Документация Майкрософт
description: Краткое руководство по проекту командного процесса обработки и анализа данных. В этом руководстве объясняется, как использовать глубинное обучение для распознавания биомедицинских сущностей с помощью Azure Machine Learning Workbench.
services: machine-learning
documentationcenter: ''
author: bradsev
manager: cgronlun
editor: cgronlun
ms.assetid: ''
ms.reviewer: garyericson, jasonwhowell, mldocs
ms.service: machine-learning
ms.component: desktop-workbench
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 09/10/2017
ms.author: bradsev
ms.openlocfilehash: ae8c8ed9d397df0c82b74f051ff14729c0f41623
ms.sourcegitcommit: 944d16bc74de29fb2643b0576a20cbd7e437cef2
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/07/2018
ms.locfileid: "34837286"
---
# <a name="biomedical-entity-recognition-using-team-data-science-process-tdsp-template"></a>Распознавание биомедицинских сущностей с помощью шаблона командного процесса обработки и анализа данных (TDSP)

Извлечение сущностей является подзадачей извлечения информации (также известной как [распознавание именованных сущностей (NER)](https://en.wikipedia.org/wiki/Named-entity_recognition), фрагментирование сущностей и идентификация сущностей). На примере этого реального сценария показано, как использовать Azure Machine Learning Workbench для решения сложной задачи обработки естественного языка (NLP), такой как извлечение сущностей из неструктурированного текста.

1. Обучение нейронной модели векторных представлений слов на основе совокупности текстов, которая включает около 18 млн аннотаций PubMed, с помощью [реализации Word2Vec в Spark](https://spark.apache.org/docs/latest/mllib-feature-extraction.html#word2vec).
2. Создание модели глубинной рекуррентной нейронной сети на основе долгой краткосрочной памяти (LSTM) для извлечения сущностей на виртуальной машине Azure для анализа и обработки данных с поддержкой графического процессора в Azure.
2. Демонстрация того, как предметно-ориентированные модели векторных представлений слов могут превосходить обычные модели векторных представлений слов в задаче распознавания сущностей. 
3. Демонстрация того, как обучать и реализовывать модели глубинного обучения с помощью Azure Machine Learning Workbench.

4. Демонстрация следующих возможностей Azure Machine Learning Workbench:

    * создание экземпляров [структуры и шаблонов TDSP](how-to-use-tdsp-in-azure-ml.md);
    * автоматическое управление зависимостями проекта, включая скачивание и установку;
    * выполнение скриптов Python в различных вычислительных средах;
    * отслеживание журналов выполнения для скриптов Python;
    * выполнение заданий в удаленном контексте вычислений Spark с использованием кластеров Spark 2.1 в HDInsight;
    * выполнение заданий на удаленных виртуальных машинах с поддержкой GPU в Azure;
    * простая реализация моделей глубокого обучения в виде веб-служб в службах контейнеров Azure (ACS).

## <a name="use-case-overview"></a>Обзор варианта использования
Распознавание биомедицинских именованных сущностей является критически важным этапом при выполнении сложных задач обработки естественного языка в области биомедицины, таких как: 
* извлечение упоминаний именованных сущностей, таких как заболевания, препараты, химические вещества и симптомы, из электронных историй болезни или медицинских карточек;
* поиск новых лекарств;
* объяснение взаимодействия между сущностями различных типов, таких как "лекарство — лекарство", "лекарство — заболевание" или "ген — белок".

В нашем сценарии использования рассматривается, как проанализировать большой объем неструктурированных данных, например аннотаций MEDLINE PubMed, для обучения модели векторного представления слов. Полученные в результате векторные представления будут использоваться в качестве автоматически сгенерированных признаков для обучения средства извлечения нейронных сущностей.

Наши результаты показывают, что модели извлечения биомедицинских сущностей, обученные на основе предметно-ориентированных признаков векторного представления слов, превосходят модели, обученные на основе обычных признаков. Предметно-ориентированная модель может правильно обнаружить 7012 сущностей (из 9475) с F1-мерой 0,73, а обычная модель — 5274 сущности с F1-мерой 0,61.

На следующем рисунке показана архитектура, используемая для обработки данных и обучения моделей.

![Архитектура](./media/scenario-tdsp-biomedical-recognition/architecture.png)

## <a name="data-description"></a>Описание данных

### <a name="1-word2vec-model-training-data"></a>1. Данные для обучения модели Word2Vec
Для начала мы скачали необработанные данные аннотаций MEDLINE со страницы [MEDLINE](https://www.nlm.nih.gov/pubs/factsheets/medline.html). Данные доступны для всех в формате XML-файлов на соответствующих [FTP-серверах](https://ftp.ncbi.nlm.nih.gov/pubmed/baseline). На сервере доступно 892 XML-файла, каждый из которых содержит данные 30 000 статей. Дополнительные сведения об этапе сбора данных см. в разделе о структуре проекта. Каждый файл содержит следующие поля: 
        
        abstract
        affiliation
        authors
        country 
        delete: boolean if False means paper got updated so you might have two XMLs for the same paper.
        file_name   
        issn_linking    
        journal 
        keywords    
        medline_ta: this is abbreviation of the journal nam 
        mesh_terms: list of MeSH terms  
        nlm_unique_id   
        other_id: Other IDs 
        pmc: Pubmed Central ID  
        pmid: Pubmed ID
        pubdate: Publication date
        title

### <a name="2-lstm-model-training-data"></a>2. Данные для обучения модели LSTM

При обучении и оценке нейронной модели для извлечения сущностей использовались общедоступные наборы данных. Подробное описание этих наборов данных см. в следующих источниках:
 * [Report on Bio-Entity Recognition Task at BioNLP/NLPBA 2004](http://www.nactem.ac.uk/tsujii/GENIA/ERtask/report.html) (Отчет по задаче распознавания биомедицинских сущностей, представленный на семинаре NLPBA в 2004 г.);
 * [совокупность задач семинара BioCreative V по исследованию связей типа "лекарство — заболевание" (CDR)](http://www.biocreative.org/tasks/biocreative-v/track-3-cdr/);
 * [семинар по семантической оценке (SemEval), 2013 г., задача 9.1 (распознавание названий лекарств)](https://www.cs.york.ac.uk/semeval-2013/task9/).

## <a name="link-to-the-azure-gallery-github-repository"></a>Ссылка на репозиторий коллекции Azure на GitHub
Ниже приведена ссылка на общедоступный репозиторий реального сценария на GitHub, который содержит код и более подробное описание: 

[https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction)


## <a name="prerequisites"></a>предварительным требованиям 

* Подписка [Azure](https://azure.microsoft.com/free/).
* Azure Machine Learning Workbench. Сведения см. в [руководстве по установке](../service/quickstart-installation.md). Сейчас Azure Machine Learning Workbench можно установить только в следующих операционных системах: 
    * Windows 10 или Windows Server 2016;
    * macOS Sierra (или более поздней версии).


### <a name="azure-services"></a>Службы Azure
* [Кластер HDInsight Spark 2.1](https://docs.microsoft.com/azure/hdinsight/hdinsight-apache-spark-jupyter-spark-sql) на платформе Linux (HDI 3.6) для масштабируемых вычислений. Минимальная конфигурация, необходимая для обработки всего объема аннотаций MEDLINE, рассмотренных ниже: 
    * Головной узел размера [D13_V2](https://azure.microsoft.com/pricing/details/hdinsight/).
    * Как минимум 4 рабочих узла [D12_V2](https://azure.microsoft.com/pricing/details/hdinsight/). В нашем случае мы использовали 11 рабочих узлов размера D12_V2.
* [Виртуальная машина для обработки и анализа данных NC6](https://docs.microsoft.com/azure/machine-learning/machine-learning-data-science-linux-dsvm-intro) для масштабируемых вычислений.

### <a name="python-packages"></a>Пакеты Python

Все необходимые зависимости определены в файле aml_config/conda_dependencies.yml в папке проекта сценария. Зависимости, определенные в этом файле, автоматически подготавливаются для выполнения на целевых виртуальных машинах, в контейнере Docker и в кластере HDI. Дополнительные сведения о формате файла среды Conda см. [здесь](https://conda.io/docs/using/envs.html#create-environment-file-by-hand).

* [TensorFlow](https://www.tensorflow.org/install/);
* [CNTK 2.0](https://docs.microsoft.com/cognitive-toolkit/using-cntk-with-keras);
* [Keras](https://keras.io/#installation);
* NLTK;
* Fastparquet.

### <a name="basic-instructions-for-azure-machine-learning-aml-workbench"></a>Общие инструкции по работе с Azure Machine Learning Workbench (AML)
* [Обзор](../service/overview-what-is-azure-ml.md)
* [Установка](../service/quickstart-installation.md)
* [Использование TDSP](how-to-use-tdsp-in-azure-ml.md).
* [Как считывать и записывать файлы](how-to-read-write-files.md).
* [Как использовать записные книжки Jupyter](how-to-use-jupyter-notebooks.md).
* [Как использовать GPU](how-to-use-gpu.md).

## <a name="scenario-structure"></a>Структура сценария
Для этого сценария мы используем шаблоны структуры проекта и документации TDSP (рис. 1), которые соответствуют [жизненному циклу TDSP](https://github.com/Azure/Microsoft-TDSP/blob/master/Docs/lifecycle-detail.md). Проект создан с полным соблюдением инструкций, которые приведены [здесь](./how-to-use-tdsp-in-azure-ml.md).


![Указание сведений о проекте](./media/scenario-tdsp-biomedical-recognition/instantiation-3.png) 

Ниже представлен пошаговый рабочий процесс обработки и анализа данных.

### <a name="1-data-acquisition-and-understanding"></a>1. Получение и изучение данных

См. раздел о [получении и анализе данных](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/blob/master/code/01_data_acquisition_and_understanding/ReadMe.md).

Необработанная совокупность MEDLINE состоит из 27 млн аннотаций, из которых у около 10 млн статей поле аннотации пустое. Кластер Spark в Azure HDInsight используется для обработки больших данных, которые невозможно загрузить в формате [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) в память одного компьютера. Сначала данные скачиваются в кластер Spark. Затем для данных в формате [Pandas DataFrame](https://spark.apache.org/docs/latest/sql-programming-guide.html) выполняются следующие шаги: 
* анализ XML-файлов с помощью средства синтаксического анализа XML-файлов от MEDLINE;
* предварительная обработка текста аннотаций, в том числе разделение на предложения, разметка и нормализация регистра;
* исключение статей, у которых поле аннотации пустое или содержит короткий текст; 
* создание словаря на основе изучаемых аннотаций;
* обучение нейронной модели векторного представления слов (дополнительные сведения о начале работы см. по [ссылке на код на сайте GitHub](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/blob/master/code/01_data_acquisition_and_understanding/ReadMe.md)).


После синтаксического анализа XML-файлов данные будут представлены в следующем формате: 

![Пример данных](./media/scenario-tdsp-biomedical-recognition/datasample.png)

При обучении и оценке нейронной модели для извлечения сущностей использовались общедоступные наборы данных. Подробное описание этих наборов данных см. в следующих источниках:
 * [Report on Bio-Entity Recognition Task at BioNLP/NLPBA 2004](http://www.nactem.ac.uk/tsujii/GENIA/ERtask/report.html) (Отчет по задаче распознавания биомедицинских сущностей, представленный на семинаре NLPBA в 2004 г.);
 * [совокупность задач семинара BioCreative V по исследованию связей типа "лекарство — заболевание" (CDR)](http://www.biocreative.org/tasks/biocreative-v/track-3-cdr/);
 * [семинар по семантической оценке (SemEval), 2013 г., задача 9.1 (распознавание названий лекарств)](https://www.cs.york.ac.uk/semeval-2013/task9/).

### <a name="2-modeling"></a>2. Моделирование

См. раздел о [моделировании](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling).

На этапе моделирования мы покажем, как можно использовать данные, скачанные в предыдущем разделе, для обучения модели векторного представления слов и ее использования в других подчиненных задачах. Несмотря на то что мы используем данные PubMed, конвейер для создания векторных представлений является универсальным и его можно применять при обучении векторных представлений слов для других предметных областей. Чтобы векторные представления точно представляли данные, необходимо обучить алгоритм Word2Vec на основе большого объема данных.
Когда векторные представления слов будут готовы, можно обучить модель глубинной нейронной сети, которая использует обученные векторные представления для инициализации слоя векторного представления. Мы обозначим уровень векторного представления как необучаемый, но это не обязательно. Обучение модели векторного представления слов не контролируется, поэтому мы можем использовать тексты без меток. Но обучение модели для распознавания сущностей — это контролируемая задача, и точность результатов зависит от объема и качества вручную размеченных данных. 


#### <a name="21-feature-generation"></a>2.1. Создание признаков

См. раздел о [создании признаков](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/01_feature_engineering).

Word2Vec — это алгоритм неконтролируемого обучения векторных представлений слов, с помощью которого модель нейронной сети обучается на совокупности учебных данных без меток. В результате создается непрерывный вектор для каждого слова из совокупности, представляющий семантические данные о слове. Эти модели представляют собой простые нейронные сети с одним скрытым слоем. Векторные представления слов обучаются по методам обратного распространения ошибки и вероятностного градиентного спуска. Существует два типа моделей Word2Vec: Skip-Gram и CBOW (Continuous Bag of Words). Дополнительные сведения см. [здесь](https://arxiv.org/pdf/1301.3781.pdf). Так как мы используем алгоритм Word2Vec, реализованный MLlib, который поддерживает модель Skip-Gram, мы приведем краткое описание модели ниже (изображение взято по [этой](https://ahmedhanibrahim.wordpress.com/2017/04/25/thesis-tutorials-i-understanding-word2vec-for-word-embedding-i/) ссылке). 

![Модель Skip-Gram](./media/scenario-tdsp-biomedical-recognition/skip-gram.png)

Модель использует алгоритм Hierarchical SoftMax и отрицательную выборку для оптимизации производительности. Hierarchical SoftMax (H-SoftMax) представляет собой модель наподобие двоичного дерева. В H-SoftMax плоский слой SoftMax заменен на иерархический, на котором слова представлены в виде листьев. Это позволяет разделить подсчет вероятности одного слова на последовательность вычислений вероятности, что избавляет нас от трудоемкого вычисления нормализации по всем словам. Так как глубина сбалансированного двоичного дерева равна log2(|V|) (где V — это словарь), нам требуется оценить лишь большую часть листовых узлов log2(|V|), чтобы получить итоговое значение вероятности слова. Вероятность слова (w) с учетом его контекста (c) — это произведение вероятностей на основе левого и правого потомков соответственно, приводящих к листовому узлу. Мы можем создать дерево Хаффмана, основываясь на частоте слов в наборе данных, чтобы часто встречающиеся слова были представлены в краткой форме. Дополнительные сведения см. по [этой ссылке](http://sebastianruder.com/word-embeddings-softmax/).
Изображение взято с [этой](https://ahmedhanibrahim.wordpress.com/2017/04/25/thesis-tutorials-i-understanding-word2vec-for-word-embedding-i/) страницы.

##### <a name="visualization"></a>Визуализация:

Когда векторные представления слов будут созданы, мы визуализируем их, чтобы увидеть связи между семантически схожими словами. 

![Семантические сходства Word2vec](./media/scenario-tdsp-biomedical-recognition/w2v-sim.png)

Мы продемонстрировали два способа визуализации векторных представлений. В первом способе используется алгоритм PCA для представления многомерного вектора в двухмерном векторном пространстве. Это приводит к значительной потере информации и неточной визуализации. Во втором способе алгоритм PCA используется с [t-SNE](https://distill.pub/2016/misread-tsne/). t-SNE — это нелинейный метод понижения размерности, который отлично подходит для векторного представления многомерных данных в двух- или трехмерном пространстве. В дальнейшем эти данные можно представить в виде точечной диаграммы.  С его помощью каждый многомерный объект моделируется до двух- или трехмерной точки таким образом, что схожие объекты моделируются в соответствии с ближайшими точками, а разнородные объекты — в соответствии с отдаленными точками. Метод выполняется в два этапа. На первом этапе создается распределение вероятностей по парам в многомерном пространстве таким образом, чтобы у схожих объектов была более высокая вероятность выбора, а у разнородных — более низкая. На втором этапе определяется аналогичное распределения вероятностей по точкам на низкоразмерной карте и сводится к минимуму расхождение Кульбака-Лейблера между двумя распределениями с учетом расположения точек на карте. Расположение точек в низкоразмерном пространстве достигается путем сведения к минимуму расхождения Кульбака-Лейблера с помощью метода градиентного спуска. Но метод t-SNE не всегда надежен. Дополнительные сведения о реализации можно найти [здесь](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/01_feature_engineering). 


Как показано на рисунке ниже, при визуализации с помощью t-SNE обеспечивается более явное разделение векторов слов и потенциальных моделей кластеризации. 


* Визуализация с использованием PCA

![PCA](./media/scenario-tdsp-biomedical-recognition/pca.png)

* Визуализация с использованием t-SNE

![t-SNE](./media/scenario-tdsp-biomedical-recognition/tsne.png)

* Точки, наиболее близкие к слову cancer (рак) (все слова являются подтипами рака)

![Точки, наиболее близкие к слову cancer (рак)](./media/scenario-tdsp-biomedical-recognition/nearesttocancer.png)

#### <a name="22-train-the-neural-entity-extractor"></a>2.2. Обучение нейронного средства для извлечения сущностей

См. раздел об [обучении нейронного средства для извлечения сущностей](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/02_model_creation/ReadMe.md).

В архитектуре нейронной сети прямого распространения существует проблема, при которой все входные и выходные данные определяются как независимые от других входных и выходных данных. Такая архитектура не позволяет моделировать задачи маркировки типа "последовательность-к-последовательности", такие как машинный перевод и извлечение сущностей. Эту проблему можно решить с помощью моделей рекуррентных нейронных сетей, так как они позволяют передавать на следующий узел данные, вычисляемые до текущего момента. Это свойство называется наличием памяти в сети из-за возможности использовать ранее вычисленные данные, как показано на следующем рисунке:

![Рекуррентная нейронная сеть](./media/scenario-tdsp-biomedical-recognition/rnn-expanded.png)

Базовые рекуррентные нейронные сети (RNN) сталкиваются с [проблемой исчезновения градиентов](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), из-за которой они не могут использовать все данные, полученные ранее. Эта проблема проявляется только в случаях, когда необходимо обработать большой объем контекста для создания прогноза. Но в моделях, подобных LSTM, такой проблемы нет. Они как раз предназначены для запоминания долгосрочных зависимостей. В отличие от базовых RNN, в которых имеется одна нейронная сеть, в моделях LSTM между собой взаимодействуют четыре нейронные сети для каждой ячейки. Подробное описание принципов работы LSTM см. в [этой записи блога](http://colah.github.io/posts/2015-08-Understanding-LSTMs/).

![Ячейка LSTM](./media/scenario-tdsp-biomedical-recognition/lstm-cell.png)

Давайте попробуем создать собственную рекуррентную нейронную сеть на основе LSTM и извлечь сущности таких типов, как упоминание лекарств, заболеваний и симптомов, из данных PubMed. Первым делом нужно получить большой объем данных с метками. И, как вы уже догадались, это не так просто! Большинство медицинских данных содержат много конфиденциальных сведений о пациентах и, следовательно, не являются общедоступными. Мы используем сочетание двух разных общедоступных наборов данных. Первый набор данных взят из задачи 9.1 по распознаванию названий лекарств, представленной на семинаре SemEval в 2013 г., а второй — из задачи, представленной на семинаре BioCreative V CDR. Эти два набора данных объединяются, и к ним автоматически добавляются метки, позволяя нам определить данные о лекарствах и заболеваниях в медицинских текстах и оценить наши векторные представления слов. Дополнительные сведения о реализации см. по [ссылке на код на сайте GitHub](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/02_model_creation).

Архитектура модели, которую мы использовали во всех кодах и для сравнения, представлена ниже. Параметр, который отличается в разных наборах данных, — это максимальная длина последовательности (здесь она равна 613).

![Модель LSTM](./media/scenario-tdsp-biomedical-recognition/d-a-d-model.png)

#### <a name="23-model-evaluation"></a>2.3. Оценка модели.
Ознакомьтесь с разделом [Оценка модели](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/02_modeling/03_model_evaluation/ReadMe.md).

Мы используем скрипт оценки из общедоступной [задачи по распознаванию биомедицинской сущности, представленной в 2004 г. на семинаре по обработке естественного языка и ее применению в биомедицине](http://www.nactem.ac.uk/tsujii/GENIA/ERtask/report.html), чтобы оценить точность, отзыв и F1-меру модели. 

#### <a name="in-domain-versus-generic-word-embedding-models"></a>Сравнение предметно-ориентированной модели векторного представления слов с обычной моделью векторного представления слов

Ниже представлено сравнение показателей точности двух типов признаков: (1) векторные представления, обученные на основе аннотаций PubMed, и (2) векторные представления, обученные на основе данных Google News. На изображении видно, что предметно-ориентированная модель превосходит обычную модель. Поэтому использовать предметно-ориентированную модель гораздо эффективнее, чем обычную. 

* Задача 1. Определение данных о лекарствах и заболеваниях

![Сравнение моделей 1](./media/scenario-tdsp-biomedical-recognition/mc1.png)

Мы проводим аналогичную оценку векторных представлений слов на основе разных наборов данных и видим, что показатели предметно-ориентированной модели всегда выше.

* Задача 2. Определение данных о белках, клеточных линиях, типах клеток, ДНК и РНК

![Сравнение моделей 2](./media/scenario-tdsp-biomedical-recognition/mc2.png)

* Задача 3. Определение данных о химических веществах и заболеваниях

![Сравнение моделей 3](./media/scenario-tdsp-biomedical-recognition/mc3.png)

* Задача 4. Определение данных о лекарствах

![Сравнение моделей 4](./media/scenario-tdsp-biomedical-recognition/mc4.png)

* Задача 5. Определение данных о генах

![Сравнение моделей 5](./media/scenario-tdsp-biomedical-recognition/mc5.png)

#### <a name="tensorflow-versus-cntk"></a>Сравнение TensorFlow и CNTK
Для обучения всех указанных моделей используется Keras с TensorFlow в качестве серверной части. На момент написания статьи в серверной части CNTK в Keras не поддерживался API reverse. Поэтому для сравнения мы обучили однонаправленную модель LSTM с серверной частью CNTK и сравнили ее с однонаправленной моделью LSTM с серверной частью TensorFlow. Установите CNTK 2.0 для Keras, следуя инструкциям из [этой статьи](https://docs.microsoft.com/cognitive-toolkit/using-cntk-with-keras). 

![Сравнение моделей 6](./media/scenario-tdsp-biomedical-recognition/mc6.png)

Мы пришли к выводу, что CNTK работает так же хорошо, как и TensorFlow, как с точки зрения времени обучения для каждой эпохи (60 с для CNTK и 75 с для TensorFlow), так и с точки зрения количества обнаруженных тестовых сущностей. Для оценки мы использовали однонаправленные слои.


### <a name="3-deployment"></a>3. Развертывание

См. раздел о [развертывании](https://github.com/Azure/MachineLearningSamples-BiomedicalEntityExtraction/tree/master/code/03_deployment).

Мы развернули кластерную веб-службу в [Службе контейнеров Azure (ACS)](https://azure.microsoft.com/services/container-service/). Среда ввода в эксплуатацию подготавливает в кластере Docker и Kubernetes для управления развертыванием веб службы. Дополнительные сведения о процессе реализации см. [здесь](model-management-service-deploy.md ).


## <a name="conclusion"></a>Заключение

Мы подробно рассмотрели, как обучать модели векторного представления с помощью алгоритма Word2Vec в Spark и использовать извлеченные векторные представления в качестве признаков для обучения глубинных нейронных сетей с целью извлечения сущностей. Мы применили конвейер обучения в области биомедицины. Но этот конвейер достаточно универсален, поэтому его можно применять для определения пользовательских типов сущностей в других предметных областях. Вам нужно только достаточное количество данных, и вы сможете легко адаптировать рабочий процесс, приведенный в этой статье, для другой предметной области.

## <a name="references"></a>Ссылки

* Томас Миколов (Tomas Mikolov), Кай Чэнь (Kai Chen), Грег С. Коррадо (Greg S Corrado) и Джеффри Дин (Jeffrey Dean). 2013a. Efficient estimation of word representations in vector space (Эффективная оценка представлений слов в векторном пространстве). Материалы международной конференции ICLR.
* Томас Миколов, Илья Суцкевер (Ilya Sutskever), Кай Чэнь, Грег С. Коррадо и Джефри Дин. 2013b. Distributed representations of words and phrases and their compositionality (Распределенные представления слов и фраз и их композиционность). Материалы конференции по нейросетевым системам обработки информации, стр. 3111–3119.
* Билли Цзю (Billy Chiu), Гамал Криктон (Gamal Crichton), Анна Корхонен (Anna Korhonen) и Сампо Пююсало (Sampo Pyysalo). 2016 г. [How to Train Good Word Embeddings for Biomedical NLP](http://aclweb.org/anthology/W/W16/W16-2922.pdf) (Как обучать эффективные векторные представления слов для обработки естественного языка в области биомедицины). Материалы пятнадцатого семинара по обработке естественного языка в области медицины, стр. 166–174.
* [Vector Representations of Words](https://www.tensorflow.org/tutorials/word2vec) (Векторные представления слов).
* [Recurrent Neural Networks](https://www.tensorflow.org/tutorials/recurrent) (Рекуррентные нейронные сети).
* [Problems encountered with Spark ml Word2Vec](https://intothedepthsofdataengineering.wordpress.com/2017/06/26/problems-encountered-with-spark-ml-word2vec/) (Проблемы, возникающие с моделью Word2Vec в Spark).
* [Spark Word2Vec: lessons learned](https://intothedepthsofdataengineering.wordpress.com/2017/06/26/spark-word2vec-lessons-learned/) (Опыт, полученный при работе с Word2Vec в Spark).

