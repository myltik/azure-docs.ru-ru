---
title: Выходные данные Data Lake Store в Azure Stream Analytics
description: Настройка проверки подлинности и авторизации хранилища озера данных в задании Stream Analytics
services: stream-analytics
author: jseb225
ms.author: jeanb
manager: kfile
ms.reviewer: jasonh
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 03/28/2017
ms.openlocfilehash: a0586b32fd12744c8bfce782583cdc4078979ef1
ms.sourcegitcommit: 3a4ebcb58192f5bf7969482393090cb356294399
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/12/2018
---
# <a name="stream-analytics-data-lake-store-output"></a>Выходные данные хранилища озера данных в Stream Analytics
Задания Stream Analytics поддерживают несколько методов вывода, одним из которых является [хранилище озера данных Azure](https://azure.microsoft.com/services/data-lake-store/). Хранилище озера данных Azure — это крупномасштабный репозиторий корпоративного уровня для рабочих нагрузок анализа больших данных. Озеро данных Azure позволяет сохранять данные с любым размером, типом и скоростью приема в одном месте для эксплуатационной и исследовательской аналитики.

## <a name="authorize-a-data-lake-store-account"></a>Авторизация учетной записи хранения озера данных Azure
1. Если на портале Azure для вывода данных выбран вариант Data Lake Store, вам будет предложено авторизовать существующую службу Data Lake Store или подать запрос на доступ к Data Lake Store.
   
   ![](media/stream-analytics-data-lake-output/stream-analytics-data-lake-output-authorization.png)  
   
2. Если у вас уже есть доступ к Data Lake Store, нажмите кнопку "Авторизовать сейчас", после чего на короткое время откроется страница с сообщением "Перенаправление для авторизации". Страница закроется автоматически, а затем появится страница для настройки выходных данных хранилища озера данных.

Если вы не зарегистрировались для использования Data Lake Store, перейдите по ссылке "Зарегистрируйтесь сейчас", чтобы отправить запрос, или следуйте [инструкциям по началу работы](../data-lake-store/data-lake-store-get-started-portal.md).

## <a name="configure-the-data-lake-store-output-properties"></a>Настройка свойств выходных данных хранилища озера данных
После проверки подлинности учетной записи хранилища озера данных можно настроить свойства для выходных данных хранилища озера данных. В таблице ниже приведены имена и описание свойств для настройки выходных данных хранилища озера данных.

<table>
<tbody>
<tr>
<td><B>Имя свойства</B></td>
<td><B>Описание</B></td>
</tr>
<tr>
<td>Псевдоним выходных данных</td>
<td>Это понятное имя, которое используется в запросах для направления выходных данных запроса в соответствующее хранилище озера данных.</td>
</tr>
<tr>
<td>Учетная запись хранилища озера данных</td>
<td>Имя учетной записи хранения, в которую отправляются выходные данные. Появится список учетных записей Data Lake Store, к которым у пользователя есть доступ.</td>
</tr>
<tr>
<td>Шаблон префикса пути [<I>необязательное свойство</I>]</td>
<td>Путь к файлу, используемый для записи файлов в указанной учетной записи хранилища озера данных. <BR>{date}, {time}<BR>Пример 1. folder1/logs/{дата}/{время}<BR>Пример 2. folder1/logs/{дата}</td>
</tr>
<tr>
<td>Формат даты [<I>необязательное свойство</I>]</td>
<td>Если в префиксе пути используется маркер даты, вы можете выбрать формат даты для упорядочивания своих файлов. Пример: ГГГГ/ММ/ДД</td>
</tr>
<tr>
<td>Формат времени [<I>необязательное свойство</I>]</td>
<td>Если в префиксе пути используется маркер времени, укажите формат времени для упорядочивания своих файлов. В настоящее время поддерживается только один формат — ЧЧ.</td>
</tr>
<tr>
<td>Формат сериализации событий</td>
<td>Формат сериализации для выходных данных. Поддерживаются форматы JSON, CSV и Avro.</td>
</tr>
<tr>
<td>Кодирование</td>
<td>Если используется формат CSV или JSON, необходимо указать формат кодирования. В настоящее время единственным поддерживаемым форматом кодировки является UTF-8.</td>
</tr>
<tr>
<td>Разделитель</td>
<td>Применяется только для сериализации CSV-файлов. Служба Stream Analytics позволяет использовать ряд распространенных разделителей для сериализации данных в формате CSV. Поддерживаются такие разделители: запятая, точка с запятой, пробел, табуляция и вертикальная черта.</td>
</tr>
<tr>
<td>Формат</td>
<td>Применяется только для сериализации JSON. Вариант «строки-разделители» предусматривает форматирование выходных данных таким образом, что каждый объект JSON будет отделен новой строкой. Вариант «массив» означает, что выходные данные будут отформатированы как массив объектов JSON.</td>
</tr>
</tbody>
</table>

## <a name="renew-data-lake-store-authorization"></a>Обновление авторизации хранилища озера данных
Сейчас существует ограничение, при котором маркер проверки подлинности необходимо обновлять вручную каждые 90 дней для всех заданий с выходными данными хранилища озера данных. Кроме того, необходимо будет повторно выполнить проверку подлинности учетной записи хранения озера данных, если с момента создания задания или последней проверки подлинности был изменен пароль. Признаком этой проблемы является отсутствие выходных данных задания и наличие ошибки в журналах операций, означающей необходимость повторной авторизации.

Чтобы устранить эту проблему, остановите выполнение задания и перейдите к выходным данным хранилища озера данных. Щелкните ссылку "Обновить авторизацию", после чего на непродолжительное время откроется страница с сообщением "Перенаправление для авторизации...". Страница автоматически закроется, и в случае успешного выполнения появится сообщение "Авторизация успешно возобновлена". В нижней части страницы нажмите кнопку "Сохранить", а затем перезапустите задание с момента последней остановки, чтобы избежать потери данных.

![](media/stream-analytics-data-lake-output/stream-analytics-data-lake-output-renew-authorization.png)

