---
title: Распространенные проблемы в Azure Stream Analytics
description: В этой статье описан ряд распространенных проблем в Azure Stream Analytics и инструкции по их устранению.
services: stream-analytics
author: jasonwhowell
manager: kfile
ms.author: jasonh
ms.reviewer: jasonh
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 04/12/2018
ms.openlocfilehash: e04d1072acee635235b0a5bd8465ca38c861017b
ms.sourcegitcommit: 1362e3d6961bdeaebed7fb342c7b0b34f6f6417a
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/18/2018
ms.locfileid: "31523529"
---
# <a name="common-issues-in-stream-analytics-and-steps-to-troubleshoot"></a>Распространенные проблемы в Stream Analytics и инструкции по их устранению

## <a name="troubleshoot-malformed-input-events"></a>Устранение неполадок в случае неправильного формата входных событий

 Если входной поток задания Stream Analytics содержит сообщения неправильного формата, возникают проблемы сериализации. Например, сообщение может иметь неправильный формат из-за отсутствия круглых или фигурных скобок в объекте JSON или неверного формата метки времени в соответствующем поле. 
 
 Когда задание Stream Analytics получает сообщение неправильного формата из входного набора данных, это сообщение отклоняется, а пользователь получает предупреждение. Символ предупреждения появляется на плитке **Входные данные** задания Stream Analytics (он отображается, пока задание находится в рабочем состоянии):

![Плитка "Входные данные"](media/stream-analytics-malformed-events/inputs_tile.png)

Чтобы просмотреть сведения предупреждения, включите журналы диагностики. Для входных событий неправильного формата в журналах выполнения создается запись о том, что не удалось выполнить десериализацию входных событий JSON из ресурса <blob URI>. 

### <a name="troubleshooting-steps"></a>Действия по устранению неполадок

1. Перейдите к плитке входных данных и щелкните ее, чтобы просмотреть предупреждения.

2. На плитке сведений о входных данных отображается набор предупреждений с подробными сведениями о проблеме. Ниже приведен пример предупреждающего сообщения, в котором отображаются раздел, смещение и порядковые номера с данными JSON неправильного формата. 

   ![Предупреждающее сообщение со смещением](media/stream-analytics-malformed-events/warning_message_with_offset.png)

3. Чтобы получить данные JSON, которые имеют неверный формат, запустите код CheckMalformedEvents.cs. Этот пример доступен в [репозитории примеров GitHub](https://github.com/Azure/azure-stream-analytics/tree/master/Samples/CheckMalformedEventsEH). При помощи этого кода считываются идентификатор раздела и смещение, а затем выводятся данные для этого смещения. 

4. После считывания данных можно проанализировать и исправить формат сериализации. 

## <a name="delayed-output"></a>Задержанные выходные данные

### <a name="first-output-is-delayed"></a>Первый фрагмент выходных данных задерживается
При запуске задания Stream Analytics считываются входные события, но при определенных обстоятельствах может произойти задержка формирования выходных данных.

Большие значения времени в элементах темпоральных запросов могут приводить к задержке выходных данных. Чтобы сформировать правильные выходные данные за большие периоды времени, задание потоковой передачи начинает считывать данные за самое последнее время (до семи дней назад) для охвата временного окна. В течение этого времени выходные данные не создаются, пока не будут считаны все необработанные входные события. Эта проблема может возникнуть, когда система обновляет задания потоковой передачи, тем самым перезапуская их. Такие обновления обычно происходят один раз каждые несколько месяцев. 

Таким образом, проявляйте осторожность при проектировании запроса Stream Analytics. Если вы используете большое временное окно (более чем несколько часов, до семи дней) для темпоральных элементов в синтаксисе запроса задания, то это может привести к задержке первого фрагмента выходных данных при запуске или перезапуске задания.  

В качестве способа устранения этой задержки можно использовать методы параллелизации запросов (секционирование данных) или добавить дополнительные единицы потоковой передачи, чтобы повысить пропускную способность, пока задание наверстывает упущенное.  Дополнительные сведения см. в статье [Концепции контрольных точек и воспроизведения в Azure Stream Analytics](stream-analytics-concepts-checkpoint-replay.md).

Эти факторы влияют на своевременность генерации первого фрагмента выходных данных:

1. Использование агрегатов данных на основе периодов (оператор группирования GROUP BY по "переворачивающимся", "прыгающим" и "скользящим" окнам).
   - Для агрегатов "переворачивающихся" или "прыгающих" окон результаты создаются в конце оконного временного интервала. 
   - Для "скользящего" окна результаты создаются, когда событие входит в это окно или выходит из него. 
   - Если вы планируете использовать большой размер окна (> 1 часа), то лучше выбрать "прыгающее" или "скользящее" окно, чтобы вы могли чаще видеть выходные данные.

2. Использование темпоральных соединений (JOIN с DATEDIFF).
   - Соответствия генерируются, как только поступают оба экземпляра сопоставляемых событий.
   - Данные без соответствия (LEFT OUTER JOIN) создаются в конце окна DATEDIFF относительно каждого события с левой стороны.

3. Использование темпоральных аналитических функции (ISFIRST, LAST и LAG с LIMIT DURATION).
   - Для аналитических функций выходные данные создаются для каждого события без задержки.

### <a name="output-falls-behind"></a>Выходные данные запаздывают
Если вы обнаружите, что во время обычной работы задания выходные данные задерживаются (и задержка становится больше и больше), то можно выявить первопричины, проанализировав такие факторы:
- регулируется ли подчиненный приемник:
- регулируется ли вышестоящий источник данных;
- потребляет ли логика обработки в запросе много вычислительных ресурсов.

Чтобы просмотреть эти сведения, на портале Azure выберите задание потоковой передачи и щелкните **Схема заданий**. Для каждого набора входных данных есть метрика событий невыполненной работы секции. Если метрика невыполненной работы увеличивается, это сигнализирует об ограниченности ресурсов системы. Это может быть связано с регулированием приемника выходных данных или высокой загрузкой ЦП. Дополнительные сведения об использовании схемы заданий см. в статье [Отладка на основе данных с помощью схемы заданий](stream-analytics-job-diagram-with-metrics.md).

## <a name="handle-duplicate-records-in-azure-sql-database-output"></a>Обработка повторяющихся записей в выходных данных базы данных SQL Azure

При настройке службы "База данных SQL Azure" для выходных данных задания Stream Analytics выполняется массовая вставка записей в целевую таблицу. Обычно Azure Stream Analytics гарантирует [по крайней мере однократную доставку]( https://msdn.microsoft.com/azure/stream-analytics/reference/event-delivery-guarantees-azure-stream-analytics) в приемник выходных данных. Но можно обеспечить и [исключительно однократную доставку]( https://blogs.msdn.microsoft.com/streamanalytics/2017/01/13/how-to-achieve-exactly-once-delivery-for-sql-output/) для выходных данных SQL. Для этого в таблице SQL нужно определить уникальное ограничение. 

Когда в таблицу SQL, в которой настроены уникальные ограничения ключей, вставляются повторяющиеся записи, Azure Stream Analytics удаляет такую запись. Данные разделяются на пакеты, которые рекурсивно вставляются, пока не будет обнаружена повторяющаяся запись. Если задание потоковой передачи имеет значительное число повторяющихся строк, процесс разбиения и вставки должен игнорировать дубликаты по одному, что менее эффективно и занимает много времени. Если в журнале действий в течение последнего часа отображается несколько предупреждающих сообщений о нарушении ключа, вполне вероятно, что обработка выходных данных SQL замедляет выполнение всего задания. 

Чтобы устранить эту проблему, нужно [настроить индекс]( https://docs.microsoft.com/sql/t-sql/statements/create-index-transact-sql), который вызывает нарушение ключа, включив параметр IGNORE_DUP_KEY. Этот параметр позволяет пропускать в SQL повторяющиеся значения при массовой вставке. В таком случае в SQL Azure вместо сообщения об ошибке отображается предупреждающее сообщение. Azure Stream Analytics больше не создают сообщения об ошибке при нарушении первичного ключа.

Если IGNORE_DUP_KEY настраивается для нескольких типов индексов, обратите внимание на следующее:

* IGNORE_DUP_KEY нельзя установить для первичного ключа или уникального ограничения, в котором используется ALTER INDEX. Индекс нужно удалить и создать повторно.  
* Вы можете задать параметр IGNORE_DUP_KEY для уникального индекса при помощи ALTER INDEX. Это ограничение отличается от PRIMARY KEY или UNIQUE и создается с использованием определения CREATE INDEX или INDEX.  
* IGNORE_DUP_KEY не применяется к индексам хранилища столбцов, так как нельзя обеспечить уникальность таких индексов.  

## <a name="next-steps"></a>Дополнительная информация
* [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)
