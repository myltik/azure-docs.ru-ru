---
title: Задания по масштабированию в Azure Stream Analytics для увеличения пропускной способности | Документация Майкрософт
description: Узнайте, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки определения запроса и определения единиц потоковой передачи.
keywords: потоковая передача данных, обработка потоковой передачи данных, настройка аналитики
services: stream-analytics
documentationcenter: ''
author: JSeb225
manager: ryanw
ms.assetid: 7e857ddb-71dd-4537-b7ab-4524335d7b35
ms.service: stream-analytics
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 06/22/2017
ms.author: jeanb
ms.openlocfilehash: 2e0487a9e4cd6346312c6817ef2768556cba72ba
ms.sourcegitcommit: 34e0b4a7427f9d2a74164a18c3063c8be967b194
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/30/2018
---
# <a name="scale-azure-stream-analytics-jobs-to-increase--throughput"></a>Задания по масштабированию в Azure Stream Analytics для увеличения пропускной способности
В этой статье описано, как настроить запрос Stream Analytics для увеличения пропускной способности заданий Streaming Analytics. Руководство ниже можно использовать для масштабирования заданий, чтобы обрабатывать большую нагрузку и использовать больше ресурсов системы (таких как пропускная способность, ресурсы ЦП, память).
Предварительно может потребоваться ознакомиться со следующими статьями:
-   [Обзор и настройка единиц потоковой передачи](stream-analytics-streaming-unit-consumption.md)
-   [Использование параллелизации запросов в Azure Stream Analytics](stream-analytics-parallelization.md)


## <a name="case-1--your-query-is-inherently-fully-parallelizable-across-input-partitions"></a>Вариант 1. Полностью параллелизуемый запрос в секциях ввода
Если запрос по своей природе полностью параллелизуемый в секциях ввода, можно выполнить такие действия:
1.  Создайте запрос с усложненным параллелизмом с помощью ключевого слова **PARTITION BY** (СЕКЦИОНИРОВАНИЕ ПО). Дополнительные сведения о заданиях с усложненным параллелизмом см. в [этой статье](stream-analytics-parallelization.md).
2.  В зависимости от типов выходных данных, используемых в запросе, некоторые выходные данные могут быть не параллелизуемыми или требовать дополнительной конфигурации при усложненном параллелизме. Например, выходные данные SQL, SQL DW и PowerBI не могут быть параллелизуемыми. Выходные данные всегда объединяются перед отправкой в приемник выходных данных. Большие двоичные объекты, таблицы, ADLS, служебные шины и служба "Функции Azure" автоматически параллелизуются. CosmosDB и концентратору событий необходим набор конфигурации PartitionKey, чтобы соответствовать полю **PARTITION BY** (СЕКЦИОНИРОВАНИЕ ПО) (обычно PartitionId). При использовании концентратора событий также обратите особое внимание на соответствие количества секций для всех входных и выходных данных, чтобы избежать пересечения секций. 
3.  Выполните запрос с **6 единицами потоковой передачи** (полная емкость одного узла вычислений) для измерения максимально достижимой пропускной способности, а при использовании **GROUP BY** (СГРУППИРОВАТЬ ПО) измерьте сколько групп (кратность) может обработать задание. Ниже перечислены общие признаки задания, достигшего ограничения по ресурсам.
    - Метрика процентного использования единиц потоковой передачи выше 80 %. Это указывает на высокий уровень использования памяти. Факторы, влияющие на увеличение этой метрики, описаны в [этой статье](stream-analytics-streaming-unit-consumption.md). 
    -   Метка времени выходных данных отстает от реального времени. В зависимости от логики запроса метка времени может иметь логическое смещение относительно реального времени. Тем не менее они будут выполняться примерно с такой же скоростью. Если метка времени выходных данных отстает все сильнее, это является индикатором того, что система перегружена. Это может быть результатом нисходящего регулирования приемника выходных данных или высокой загрузки ЦП. В настоящее время метрика использования процессора не предоставляется, поэтому их может быть трудно различить.
        - Если проблема не возникает из-за регулирования приемников, может потребоваться увеличить количество секций выходных данных (а также секций ввода, чтобы задание осталось полностью параллелизуемым) или увеличить объем ресурсов приемника (например, число единиц запроса для CosmosDB).
    - На схеме задания есть метрика событий невыполненной работы секции для каждого набора входных данных. Если метрика событий невыполненных работ продолжает увеличиваться, это означает, что системные ресурсы ограничены (из-за регулирования приемника выходных данных или высокой загрузки ЦП).
4.  После определения границ выполнения задания с 6 единицами потоковой передачи, можно линейно экстраполировать емкость обработки задания по мере добавления дополнительных единиц потоковой передачи при отсутствии неравномерного распределения данных, создающего секции с высокой нагрузкой.
>[!Note]
> Выберите правильное число единиц потоковой передачи, так как Stream Analytics создает узел обработки для каждой из добавленных 6 единиц потоковой передачи. Для равномерного распределения секций по узлам лучше всего сделать число секций делителем количества секций входных данных.
> Например, вы измерили, что задание с 6 единицами потоковой передачи может достигнуть скорости обработки 4 МБ/с, а количество секций выходных данных — 4. Можно запустить задание с 12 единицами потоковой передачи, чтобы достичь скорости обработки 8 МБ/с, или 24 единицами потоковой передачи, чтобы достичь скорости обработки 16 МБ/с. Затем можно решить, когда увеличивать количество единиц потоковой передачи для задания и до какого значения, в зависимости от скорости ввода.



## <a name="case-2---if-your-query-is-not-embarrassingly-parallel"></a>Вариант 2. Если запрос без усложненного параллелизма
Если в запросе нет усложненного параллелизма, можно выполнить такие действия.
1.  Сначала запустите запрос без **PARTITION BY** (СЕКЦИОНИРОВАНИЕ ПО), чтобы избежать сложности секционирования, и выполните запрос с 6 единицами потоковой передачи, чтобы измерить максимальную нагрузку, как в [варианте 1](#case-1--your-query-is-inherently-fully-parallelizable-across-input-partitions).
2.  При достижении ожидаемой нагрузки с точки зрения пропускной способности настройка завершена. Кроме того, можно измерить ту же задачу, выполняемую с 3 и 1 единицей потоковой передачи, чтобы узнать минимально необходимое для работы сценария число единиц хранения.
3.  Если необходимой пропускной способности достичь не удается, попробуйте (если это возможно) разбить запрос на несколько шагов, если этого еще не сделано, и выделите до 6 единиц потоковой передачи для каждого шага в запросе. Например, при наличии трех шагов выделите 18 единиц потоковой передачи в параметре "Масштаб".
4.  При выполнении такого задания Stream Analytics помещает каждый шаг на отдельный узел с выделенными ресурсами 6 единиц потоковой передачи. 
5.  Если необходимая нагрузка по прежнему не достигнута, можно использовать **PARTITION BY** (СЕКЦИОНИРОВАНИЕ ПО) начиная с шагов ближе к входным данным. Для оператора **GROUP BY** (СГРУППИРОВАТЬ ПО), который не может быть легко секционирован, можно использовать локальный или глобальный шаблон вычисления при выполнении секционированного оператора **GROUP BY** (СГРУППИРОВАТЬ ПО) после не секционированного **GROUP BY** (СГРУППИРОВАТЬ ПО). Например, если необходимо подсчитать, сколько автомобилей проходит через каждый пропускной пункт каждые 3 минуты, а объем данных выходит за рамки того, что может быть обработано в рамках 6 единиц потоковой передачи.

Запрос:

    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId, PartitionId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )
    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute, 3), TollBoothId

В вышеприведенном запросе подсчитывается количество автомобилей, прошедших через пункт пропуска каждой секции, а затем суммируются числа из всех секций.

После секционирования выделите до 6 единиц потоковой передачи для каждой секции шага. Так как это максимальное значение, каждую секцию можно разместить на собственном узле обработки.

> [!Note]
> Если запрос не может быть секционирован, добавление дополнительных единиц потоковой передачи в запрос с несколькими действиями не всегда может повысить пропускную способность. Один из способов повышения производительности — уменьшить объем начальных действий, используя локальный или глобальный шаблон вычисления, как описано выше в шаге 5.

## <a name="case-3---you-are-running-lots-of-independent-queries-in-a-job"></a>Вариант 3. Выполнение большого количества независимых запросов в задании
Для определенных вариантов использования ISV наиболее эффективным способом обработки данных нескольких клиентов является одно задание, использующее отдельные входные и выходные данные для каждого клиента. В одном задании можно запустить довольно много (например, 20) независимых запросов. Предполагается, что загрузка каждого из вложенных запросов относительно невелика. В этом случае можно выполнить следующие действия.
1.  В этом случае **PARTITION BY** (СЕКЦИОНИРОВАНИЕ ПО) не используется в запросе.
2.  Если используется концентратор событий, уменьшите количество секций входных данных до наименьшего возможного значения — 2.
3.  Выполните запрос с 6 единицами потоковой передачи. С ожидаемой нагрузкой каждого вложенного запроса добавьте столько вложенных запросов, сколько возможно, пока задание не достигнет ограничений по системным ресурсам. Дополнительные сведения об этом см. в разделе [Вариант 1. Запрос по своей природе полностью параллелизуемый в секциях ввода](#case-1--your-query-is-inherently-fully-parallelizable-across-input-partitions).
4.  При достижении измеренного выше ограничения вложенных запросов приступите к добавлению вложенных запросов в новую задачу. Количество задач, выполняемых в зависимости от количества независимых запросов, должно быть линейным при отсутствии среза нагрузки. Затем можно спрогнозировать, сколько задач с 6 единицами потоковой передачи необходимо выполнять в зависимости от количества клиентов, которых нужно обслужить.
5.  При использовании соединения ссылочных данных с такими запросами, необходимо объединить входные данные перед соединением с теми же ссылочными данными, а затем разделить события, если это необходимо. В противном случае каждое соединение ссылочных данных будет хранить ссылочные данные в памяти, что вызовет излишнее использование памяти.

> [!Note] 
> Сколько клиентов помещать в каждое задание?
> Этот шаблон запроса часто имеет большое количество вложенных запросов, что приводит к очень большой и сложной топологии. Контроллер задания может не справиться с обработкой такой большой топологии. Как правило, оставляйте до 40 клиентов для задания с 1 единицей потоковой передачи и 60 клиентов для заданий с 3 и 6 единицами потоковой передачи. Если емкость контроллера превышена, работа не начнется успешно.


## <a name="an-example-of-stream-analytics-throughput-at-scale"></a>Пример масштабируемой пропускной способности Stream Analytics
Чтобы понять, как масштабируется пропускная способность заданий Stream Analytics, выполним эксперимент с использованием входных данных с устройства Raspberry Pi. Этот эксперимент поможет увидеть влияние на пропускную способность нескольких единиц потоковой передачи и секций.

В этом случае устройство отправляет данные датчиков (клиентов) в концентратор событий. Служба Streaming Analytics обрабатывает эти данные и отправляет предупреждение или статистические сведения в качестве выходных данных на другой концентратор событий. 

Клиент отправляет данные датчиков в формате JSON. Выходные данные также находятся в формате JSON. Ниже приведен пример данных.

    {"devicetime":"2014-12-11T02:24:56.8850110Z","hmdt":42.7,"temp":72.6,"prss":98187.75,"lght":0.38,"dspl":"R-PI Olivier's Office"}

Следующий запрос используется для отправки предупреждения при выключении света:

    SELECT AVG(lght), "LightOff" as AlertText
    FROM input TIMESTAMP BY devicetime 
    PARTITION BY PartitionID
    WHERE lght< 0.05 GROUP BY TumblingWindow(second, 1)

### <a name="measure-throughput"></a>Измерения пропускной способности

Пропускная способность в этом контексте — это объем входных данных, обрабатываемых службой Stream Analytics в определенный промежуток времени. (Мы измеряли за 10 минут.) Чтобы обеспечить оптимальную пропускную способность для обработки входных данных, поток входных данных и запрос должны были секционированы. В запрос также включается **COUNT()**, что позволяет подсчитать число обработанных событий ввода. Чтобы убедиться, что задание не просто ожидает поступления событий ввода, в каждую секцию концентратора событий ввода были предварительно загружены входные данные в объеме 300 МБ.

В следующей таблице приведены результаты с увеличением количества единиц потоковой передачи и соответствующие данные о числе секций в концентраторах событий.  

<table border="1">
<tr><th>Секции ввода</th><th>Секции вывода</th><th>Единицы потоковой передачи</th><th>Поддерживаемая пропускная способность
</th></td>

<tr><td>12</td>
<td>12</td>
<td>6</td>
<td>4,06 МБ/с</td>
</tr>

<tr><td>12</td>
<td>12</td>
<td>12</td>
<td>8,06 МБ/с</td>
</tr>

<tr><td>48</td>
<td>48</td>
<td>48</td>
<td>38,32 МБ/с</td>
</tr>

<tr><td>192</td>
<td>192</td>
<td>192</td>
<td>172,67 МБ/с</td>
</tr>

<tr><td>480</td>
<td>480</td>
<td>480</td>
<td>454,27 МБ/с</td>
</tr>

<tr><td>720</td>
<td>720</td>
<td>720</td>
<td>609,69 МБ/с</td>
</tr>
</table>

На следующей диаграмме отображена визуализация связи между числом единиц пропускной способности и пропускной способностью.

![img.stream.analytics.perfgraph][img.stream.analytics.perfgraph]

## <a name="get-help"></a>Получение справки
За дополнительной помощью обращайтесь на наш [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics).

## <a name="next-steps"></a>Дальнейшие действия
* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

<!--Image references-->

[img.stream.analytics.monitor.job]: ./media/stream-analytics-scale-jobs/StreamAnalytics.job.monitor-NewPortal.png
[img.stream.analytics.configure.scale]: ./media/stream-analytics-scale-jobs/StreamAnalytics.configure.scale.png
[img.stream.analytics.perfgraph]: ./media/stream-analytics-scale-jobs/perf.png
[img.stream.analytics.streaming.units.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsStreamingUnitsExample.jpg
[img.stream.analytics.preview.portal.settings.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsPreviewPortalJobSettings-NewPortal.png   

<!--Link references-->

[microsoft.support]: http://support.microsoft.com
[azure.event.hubs.developer.guide]: http://msdn.microsoft.com/library/azure/dn789972.aspx

[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-real-time-fraud-detection.md
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301

