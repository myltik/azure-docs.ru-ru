---
title: "Задания по масштабированию в Azure Stream Analytics для увеличения пропускной способности | Документация Майкрософт"
description: "Узнайте, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки определения запроса и определения единиц потоковой передачи."
keywords: "потоковая передача данных, обработка потоковой передачи данных, настройка аналитики"
services: stream-analytics
documentationcenter: 
author: samacha
manager: jhubbard
editor: cgronlun
ms.assetid: 7e857ddb-71dd-4537-b7ab-4524335d7b35
ms.service: stream-analytics
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 06/22/2017
ms.author: samacha
ms.translationtype: HT
ms.sourcegitcommit: 8351217a29af20a10c64feba8ccd015702ff1b4e
ms.openlocfilehash: f1e5e11e82d344508aa4375c42d509f96aaa1d00
ms.contentlocale: ru-ru
ms.lasthandoff: 08/29/2017

---
# <a name="scale-azure-stream-analytics-jobs-to-increase-stream-data-processing-throughput"></a>Масштабирование заданий Azure Stream Analytics для повышения пропускной способности базы данных
В этой статье описано, как настроить запрос Stream Analytics для увеличения пропускной способности заданий Streaming Analytics. Узнайте, как масштабировать задания Stream Analytics путем настройки секций ввода, задания определения запроса аналитики, а также вычисления и определения *единиц потоковой передачи* задания. 

## <a name="what-are-the-parts-of-a-stream-analytics-job"></a>Из каких частей состоит задание службы Stream Analytics?
Определение задания Stream Analytics включает запрос, а также входные и выходные данные. Входные данные — это точки, откуда задания считывают данные из потока. Запрос используется для преобразования потока входных данных, а выходные данные являются точками, куда направляются результаты задания.  

Задание требует по крайней мере один источник входных данных для потока данных. Входной источник потока данных может храниться в концентраторе событий Azure или в хранилище BLOB-объектов Azure. Дополнительные сведения см. в статьях [Что такое Stream Analytics?](stream-analytics-introduction.md) и [Приступая к работе с Azure Stream Analytics: выявление мошенничества в режиме реального времени](stream-analytics-real-time-fraud-detection.md).

## <a name="partitions-in-event-hubs-and-azure-storage"></a>Секции в концентраторах событий и в хранилище Azure
Масштабирование задания Stream Analytics реализует преимущества использования секций во входных или выходных данных. Секционирование позволяет разделить данные на подмножества на основе ключа секции. Процесс, который использует данные (например, задание Streaming Analytics), может получать и записывать различные секции параллельно, тем самым повышая пропускную способность. При работе со Stream Analytics можно воспользоваться преимуществами секционирования в концентраторах событий и в хранилище BLOB-объектов. 

Дополнительные сведения об этих секциях см. в следующих статьях:

* [Обзор функций концентраторов событий](../event-hubs/event-hubs-features.md#partitions)
* [Секционирование данных](https://docs.microsoft.com/azure/architecture/best-practices/data-partitioning#partitioning-azure-blob-storage)


## <a name="streaming-units-sus"></a>Единицы потоковой передачи
Единицы потоковой передачи представляют ресурсы и вычислительную мощность, необходимые для выполнения задания Azure Stream Analytics. Единицы потоковой передачи предоставляют способ описания относительной мощности обработки события, основываясь на измерении загрузки ЦП, памяти и скорости чтения и записи. Каждая единица потоковой передачи соответствует пропускной способности около 1 МБ/с. 

Выбор необходимого количества единиц потоковой передачи для конкретного задания зависит от конфигурации секции для входных данных и запроса, определенного для задания. Вы можете выбрать для задания количество единиц потоковой передачи согласно указанной квоте. По умолчанию каждая подписка Azure включает в себя квоту до 50 единиц потоковой передачи для всех заданий аналитики в определенном регионе. Чтобы увеличить количество единиц потоковой передачи для своей подписки, свяжитесь со [службой технической поддержки Майкрософт](http://support.microsoft.com). Для задания допустимые значения количества начинаются с 1, 3, 6 и затем по возрастающей с шагом в 6.

## <a name="embarrassingly-parallel-jobs"></a>Задания с усложненным параллелизмом
Задание с *усложненным параллелизмом* — это самый масштабируемый сценарий в Azure Stream Analytics. Он соединяет один раздел входных данных с одним экземпляром запроса и одним разделом выходных данных. Такой параллелизм имеет следующие требования:

1. Если в логике запроса применяется ключ, который обрабатывается тем же экземпляром запроса, необходимо только проследить за тем, чтобы события попадали в ту же секцию входных данных. При использовании концентраторов событий это означает, что для данных событий должно быть задано значение **PartitionKey**. Кроме того, можно использовать секционированные отправители. Для хранилища BLOB-объектов это означает, что события отправляются в папку той же секции. Если логика запроса не требует обработки ключа тем же экземпляром запроса, это требование можно проигнорировать. В качестве примера такой логики можно привести простой запрос select, project или filter.  

2. После того как данные будут распределены в источнике данных, необходимо убедиться в том, что запрос разбит на секции. Для этого на каждом этапе используется параметр **Partition By**. Этапов может быть несколько, но на каждом из них должен использоваться один и тот же ключ. Сейчас для выполнения заданий с параллелизмом необходимо использовать значение **PartitionId** в качестве ключа секционирования.  

3. На данном этапе секционированные выходные данные поддерживаются только концентраторами событий и хранилищами BLOB-объектов. Для выходных данных концентраторов событий необходимо указать значение **PartitionId** в качестве ключа секции. Для выходных данных хранилища BLOB-объектов ничего делать не нужно.  

4. Число секций входных данных должно совпадать с числом секций выходных данных. В настоящее время выходные данные хранилища BLOB-объектов не поддерживают секционирование. В этом нет ничего страшного, так как они наследуют схему секционирования вышестоящего запроса. Примеры значений секций, позволяющие выполнять задания с полной параллельной обработкой:  

   * 8 секций входных данных концентраторов событий и 8 секций выходных данных концентраторов событий;
   * 8 секций входных данных концентраторов событий и выходные данные хранилища BLOB-объектов;  
   * 8 секций входных данных хранилища BLOB-объектов и выходные данные хранилища BLOB-объектов;  
   * 8 секций входных данных хранилища BLOB-объектов и 8 секций выходных данных концентраторов событий.  

Далее рассмотрим примеры сценариев с усложненным параллелизмом.

### <a name="simple-query"></a>Простой запрос

* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — концентратор событий с 8 секциями.

Запрос:

    SELECT TollBoothId
    FROM Input1 Partition By PartitionId
    WHERE TollBoothId > 100

Этот запрос является простым фильтром. Поэтому нам не нужно беспокоиться о секционировании входных данных, которые передаются в концентратор событий. Обратите внимание, что запрос содержит значение **Partition By PartitionId**, поэтому он удовлетворяет требованию 2, указанному выше. Выходные данные концентраторов событий необходимо настроить, указав значение **PartitionId** в качестве ключа секции. Последняя проверка: число секций входных данных должно быть равно числу секций выходных данных.

### <a name="query-with-a-grouping-key"></a>Запрос с ключом группирования

* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — хранилище BLOB-объектов.

Запрос:

    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Этот запрос содержит ключ группирования. Поэтому этот ключ должен обрабатываться тем же экземпляром запроса. Это означает, что события нужно отправлять в концентраторы событий с делением на секции. Какой ключ следует использовать? Ключ **PartitionId** определяет логику задания. Лучше обратить внимание на ключ **TollBoothId**. В качестве значения ключа **PartitionKey** данных события должен быть указан **TollBoothId**. В запросе задайте для параметра **Partition By** значение **PartitionId**. Так как выходными данными является хранилище BLOB-объектов, не нужно беспокоиться о настройке значения ключа секции, как описано в требовании 4.

### <a name="multi-step-query-with-a-grouping-key"></a>Многоэтапный запрос с ключом группирования
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — экземпляр концентратора событий с 8 секциями.

Запрос:

    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId, PartitionId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Этот запрос содержит ключ группирования, а значит, этот ключ должен обрабатываться тем же экземпляром запроса. Мы используем ту же стратегию, что и для предыдущего примера. В данном случае запрос состоит из нескольких этапов. Указан ли на каждом этапе параметр **Partition By PartitionId**? Да, поэтому этот запрос удовлетворяет требование 3. Для выходных данных нужно указать ключ секции **PartitionId**, как описано выше. Также можно увидеть, что они имеют то же количество секций, что и входные данные.

## <a name="example-scenarios-that-are-not-embarrassingly-parallel"></a>Примеры сценариев *без* усложненного параллелизма

В предыдущем разделе мы рассмотрели сценарии с усложненным параллелизмом. В этом разделе обсуждаются сценарии, которые не соответствуют всем показателям усложненного параллелизма. 

### <a name="mismatched-partition-count"></a>Несоответствие в числе секций
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — концентратор событий с 32 секциями.

В этом случае тип запроса не имеет значения. Если число секций входных данных не совпадает с числом секций выходных данных, топология не является топологией с усложненным параллелизмом.

### <a name="not-using-event-hubs-or-blob-storage-as-output"></a>Для выходных данных не используются концентраторы событий или хранилище BLOB-объектов
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — PowerBI.

В настоящее время выходные данные PowerBI не поддерживают секционирование. Таким образом этот сценарий не считается сценарием с усложненным параллелизмом.

### <a name="multi-step-query-with-different-partition-by-values"></a>Многоэтапный запрос с разными значениями параметра Partition By
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — концентратор событий с 8 секциями.

Запрос:

    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId, PartitionId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1 Partition By TollBoothId
    GROUP BY TumblingWindow(minute, 3), TollBoothId

Как видите, на втором этапе в качестве ключа секционирования используется **TollBoothId** . Он не совпадает с ключом в первом шаге, а значит, потребует перетасовки. 

Мы рассмотрели несколько примеров заданий Stream Analytics, соответствующих и не соответствующих критериям топологии с усложненным параллелизмом. При соответствии, задания будут иметь максимально возможное для них масштабирование. Для заданий, не соответствующих ни одному из этих профилей, в дальнейшем будут выпущены обновления в отношении масштабирования. А пока придерживайтесь описанных ниже рекомендаций.

## <a name="calculate-the-maximum-streaming-units-of-a-job"></a>Расчет максимального количества единиц потоковой передачи для задания
Общее число единиц потоковой передачи, которое можно использовать заданием Stream Analytics, зависит от числа шагов в запросе, определенных для задания, и количества разделов для каждого шага.

### <a name="steps-in-a-query"></a>Шаги в запросе
Запрос может иметь один или несколько шагов. Каждый шаг — это вложенный запрос, определенный с помощью ключевого слова **WITH**. Запрос за рамками ключевого слова **WITH** (только один запрос) также учитывается в качестве шага (например, инструкция **SELECT** в следующем запросе).

    WITH Step1 AS (
        SELECT COUNT(*) AS Count, TollBoothId
        FROM Input1 Partition By PartitionId
        GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute,3), TollBoothId

Этот запрос включает 2 шага.

> [!NOTE]
> Этот запрос будет описан далее в этой статье.
>  

### <a name="partition-a-step"></a>Разделы шага
Разделение шага требует наличия следующих условий.

* Источник входных данных должен быть секционирован. 
* Инструкция **SELECT** запроса должна читаться из разделенного источника входных данных.
* Запрос внутри шага должен включать ключевое слово **Partition By**.

Если запрос разделен, входные данные событий будут обработаны и объединены в отдельные группы секции, а выходные данные событий будут сгенерированы для каждой из групп. Если желательно иметь объединенный запрос, необходимо создать второй неразделенный шаг для объединения.

### <a name="calculate-the-max-streaming-units-for-a-job"></a>Рассчитайте максимальное количество единиц потоковой передачи для задания
Все несекционированные шаги можно масштабировать до шести единиц потоковой передачи для задания Stream Analytics. Для добавления дополнительных единиц потоковой передачи данных шаг должен быть секционирован. Каждая секция может включать шесть единиц потоковой передачи.

<table border="1">
<tr><th>Запрос</th><th>Максимальное количество единиц потоковой передачи для задания</th></td>

<tr><td>
<ul>
<li>Запрос содержит один шаг.</li>
<li>Шаг не секционирован.</li>
</ul>
</td>
<td>6</td></tr>

<tr><td>
<ul>
<li>Поток входных данных секционирован по 3.</li>
<li>Запрос содержит один шаг.</li>
<li>Шаг является секционированным.</li>
</ul>
</td>
<td>18</td></tr>

<tr><td>
<ul>
<li>Запрос состоит из двух шагов.</li>
<li>Ни один из шагов не секционирован.</li>
</ul>
</td>
<td>6</td></tr>

<tr><td>
<ul>
<li>Поток входных данных секционирован по 3.</li>
<li>Запрос состоит из двух шагов. Входной шаг секционирован, а второй шаг — нет.</li>
<li>Инструкция <strong>SELECT</strong> считывает из секционированных входных данных.</li>
</ul>
</td>
<td>24 (18 и 6 секционированных и несекционированных шагов соответственно)</td></tr>
</table>

### <a name="examples-of-scaling"></a>Примеры масштабирования

Следующий запрос вычисляет количество машин, проходящих через пропускной пункт с тремя пунктами для оплаты и пропускной способности три минуты для каждого пункта. Этот запрос можно масштабировать до шести единиц потоковой передачи.

    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Чтобы использовать дополнительные единицы потоковой передачи для запроса, входной поток данных и запрос должны быть секционированы. При наличии секции потока данных, равной 3, следующий измененный запрос можно масштабировать до 18 единиц потоковой передачи.

    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Если запрос секционирован, входные данные событий будут обработаны и объединены в отдельные группы секций. Кроме того, для каждой из групп будут сформированы выходные данные событий. Секционирование может вызвать некоторые непредвиденные результаты, если поле **GROUP BY** не является ключом секции во входном потоке данных. Например, поле **TollBoothId** в предыдущем запросе не является ключом секции **Input1**. В результате данные из пункта 1 можно распределить между несколькими секциями.

Каждая из секций **Input1** будет обрабатываться отдельно с помощью Stream Analytics. В результате будет создаваться несколько записей для автомобиля, проходящего через один и тот же пункт. Если нельзя изменить ключ секции ввода, эту проблему можно устранить, добавив несекционированные действия, например:

    WITH Step1 AS (
        SELECT COUNT(*) AS Count, TollBoothId
        FROM Input1 Partition By PartitionId
        GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute, 3), TollBoothId

Этот запрос можно увеличить до 24 единиц потоковой передачи.

> [!NOTE]
> При объединении двух потоков убедитесь, что потоки разделены с помощью ключа секции столбца, используемого для объединения. Также убедитесь, что количество секций в обоих потоках одинаковое.
> 
> 

## <a name="configure-stream-analytics-streaming-units"></a>Настройка единиц потоковой передачи Stream Analytics

1. Войдите на [портал Azure](https://portal.azure.com).
2. В списке ресурсов найдите задание Stream Analytics для масштабирования и откройте его.
3. В колонке задания в разделе **Параметры** щелкните **Масштаб**.

    ![Настройка задания Stream Analytics на портале Azure][img.stream.analytics.preview.portal.settings.scale]

4. Используйте ползунок, чтобы задать количество единиц потоковой передачи для задания. Обратите внимание, что существуют определенные ограничения параметров единиц потоковой передачи.


## <a name="monitor-job-performance"></a>Мониторинг производительности задания
На портале Azure можно отслеживать пропускную способность задания:

![Отслеживание заданий Azure Stream Analytics][img.stream.analytics.monitor.job]

Рассчитайте ожидаемую пропускную способность рабочей нагрузки. Если пропускная способность меньше, чем ожидалось, настройте входную секцию и запрос, а также добавьте в задание дополнительные единицы потоковой передачи.


## <a name="visualize-stream-analytics-throughput-at-scale-the-raspberry-pi-scenario"></a>Визуализация масштабирования пропускной способности службы Stream Analytics — сценарий для компьютера Raspberry Pi
Чтобы понять, как масштабируется пропускная способность заданий Stream Analytics, выполним эксперимент с использованием входных данных с устройства Raspberry Pi. Этот эксперимент поможет увидеть влияние на пропускную способность нескольких единиц потоковой передачи и секций.

В этом случае устройство отправляет данные датчиков (клиентов) в концентратор событий. Служба Streaming Analytics обрабатывает эти данные и отправляет предупреждение или статистические сведения в качестве выходных данных на другой концентратор событий. 

Клиент отправляет данные датчиков в формате JSON. Выходные данные также находятся в формате JSON. Ниже приведен пример данных.

    {"devicetime":"2014-12-11T02:24:56.8850110Z","hmdt":42.7,"temp":72.6,"prss":98187.75,"lght":0.38,"dspl":"R-PI Olivier's Office"}

Следующий запрос используется для отправки предупреждения при выключении света:

    SELECT AVG(lght),
     "LightOff" as AlertText
    FROM input TIMESTAMP
    BY devicetime
     WHERE
        lght< 0.05 GROUP BY TumblingWindow(second, 1)

### <a name="measure-throughput"></a>Измерения пропускной способности

Пропускная способность в этом контексте — это объем входных данных, обрабатываемых службой Stream Analytics в определенный промежуток времени. (Мы измеряли за 10 минут.) Чтобы обеспечить оптимальную пропускную способность для обработки входных данных, поток входных данных и запрос должны были секционированы. В запрос также включается **COUNT()**, что позволяет подсчитать число обработанных событий ввода. Чтобы убедиться, что задание не просто ожидает поступления событий ввода, в каждую секцию концентратора событий ввода были предварительно загружены входные данные в объеме 300 МБ.

В следующей таблице приведены результаты с увеличением количества единиц потоковой передачи и соответствующие данные о числе секций в концентраторах событий.  

<table border="1">
<tr><th>Секции ввода</th><th>Секции вывода</th><th>Единицы потоковой передачи</th><th>Поддерживаемая пропускная способность
</th></td>

<tr><td>12</td>
<td>12</td>
<td>6</td>
<td>4,06 МБ/с</td>
</tr>

<tr><td>12</td>
<td>12</td>
<td>12</td>
<td>8,06 МБ/с</td>
</tr>

<tr><td>48</td>
<td>48</td>
<td>48</td>
<td>38,32 МБ/с</td>
</tr>

<tr><td>192</td>
<td>192</td>
<td>192</td>
<td>172,67 МБ/с</td>
</tr>

<tr><td>480</td>
<td>480</td>
<td>480</td>
<td>454,27 МБ/с</td>
</tr>

<tr><td>720</td>
<td>720</td>
<td>720</td>
<td>609,69 МБ/с</td>
</tr>
</table>

На следующей диаграмме отображена визуализация связи между числом единиц пропускной способности и пропускной способностью.

![img.stream.analytics.perfgraph][img.stream.analytics.perfgraph]

## <a name="get-help"></a>Получение справки
За дополнительной помощью обращайтесь на наш [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/en-US/home?forum=AzureStreamAnalytics).

## <a name="next-steps"></a>Дальнейшие действия
* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

<!--Image references-->

[img.stream.analytics.monitor.job]: ./media/stream-analytics-scale-jobs/StreamAnalytics.job.monitor-NewPortal.png
[img.stream.analytics.configure.scale]: ./media/stream-analytics-scale-jobs/StreamAnalytics.configure.scale.png
[img.stream.analytics.perfgraph]: ./media/stream-analytics-scale-jobs/perf.png
[img.stream.analytics.streaming.units.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsStreamingUnitsExample.jpg
[img.stream.analytics.preview.portal.settings.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsPreviewPortalJobSettings-NewPortal.png   

<!--Link references-->

[microsoft.support]: http://support.microsoft.com
[azure.management.portal]: http://manage.windowsazure.com
[azure.event.hubs.developer.guide]: http://msdn.microsoft.com/library/azure/dn789972.aspx

[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-real-time-fraud-detection.md
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301


