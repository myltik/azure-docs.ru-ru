<properties
	pageTitle="Масштабирование заданий Stream Analytics с помощью функций машинного обучения Azure | Microsoft Azure"
	description="Узнайте, как правильно масштабировать задания Stream Analytics (секционирование, количество SU и т. д.) при использовании функций машинного обучения Azure."
	keywords=""
	documentationCenter=""
	services="stream-analytics"
	authors="jeffstokes72"
	manager="jhubbard"
	editor="cgronlun"
/>

<tags
	ms.service="stream-analytics"
	ms.devlang="na"
	ms.topic="article"
	ms.tgt_pltfrm="na"
	ms.workload="data-services"
	ms.date="07/27/2016"
	ms.author="jeffstok"
/>

# Масштабирование заданий Stream Analytics с помощью функций машинного обучения Azure

В большинстве случаев настроить задание Stream Analytics и запустить демонстрационные данные можно без особых усилий. А что делать, если необходимо выполнить то же задание с большим объемом данных? Мы должны разобраться, как настроить задание Stream Analytics таким образом, чтобы его можно было масштабировать. В этом документе основное внимание уделено специфическим аспектам масштабирования заданий Stream Analytics с помощью функций машинного обучения. Общие сведения о масштабировании заданий Stream Analytics см. в статье [Масштабирование заданий Azure Stream Analytics для повышения пропускной способности базы данных](stream-analytics-scale-jobs.md).

## Что такое функция машинного обучения Azure в Stream Analytics?

Функция машинного обучения в Stream Analytics может использоваться как обычный вызов функции в языке запросов Stream Analytics. На самом же деле вызовы функций являются запросами веб-службы машинного обучения Azure. Веб-службы машинного обучения поддерживают пакетную обработку нескольких строк (которые называются мини-пакетом) в одном вызове API веб-службы, что способствует повышению общей пропускной способности. Дополнительные сведения можно найти в следующих статьях: [Azure ML Now Available as a Function in Azure Stream Analytics](https://blogs.technet.microsoft.com/machinelearning/2015/12/10/azure-ml-now-available-as-a-function-in-azure-stream-analytics/) (Машинное обучение Azure теперь доступно как функция в Azure Stream Analytics) и [Azure Machine Learning Web Services](machine-learning/machine-learning-consume-web-services.md#request-response-service-rrs) (Как использовать веб-службу машинного обучения Azure, развернутую из эксперимента машинного обучения).

## Настройка задания Stream Analytics с помощью функций машинного обучения

При настройке функции машинного обучения для задания Stream Analytics необходимо учитывать два параметра: размер пакета, содержащего вызов функции машинного обучения, и количество единиц потоковой передачи (SU), подготовленных для задания Stream Analytics. Чтобы определить соответствующие значения для этих параметров, сначала нужно решить, что для вас приоритетнее — задержка или пропускная способность (задержка задания Stream Analytics или пропускная способность каждой единицы потоковой передачи). К заданию всегда можно добавить SU для увеличения пропускной способности оптимально секционированного запроса Stream Analytics, хотя дополнительные единицы SU увеличивают стоимость выполнения задания.

Поэтому важно определить *допустимую* задержку при выполнении задания Stream Analytics. Задержка выполнения запросов службы машинного обучения Azure естественным образом увеличивается вместе с размером пакета, что приводит к увеличению задержки задания Stream Analytics. С другой стороны, увеличение размера пакета позволяет заданиям Stream Analytics обрабатывать *больше событий с* одинаковым количеством* запросов веб-службы машинного обучения. Часто увеличение задержки веб-службы машинного обучения следует за увеличением размера пакета, поэтому важно определить наиболее экономичный размер пакета для веб-службы машинного обучения в той или иной ситуации. По умолчанию размер пакета для запросов веб-службы равен 1000. Это значение можно изменить с помощью [REST API Stream Analytics](https://msdn.microsoft.com/library/mt653706.aspx "REST API Stream Analytics") или [клиента PowerShell для Stream Analytics](stream-analytics-monitor-and-manage-jobs-use-powershell.md "Клиент PowerShell для Stream Analytics").

Определив размер пакета, можно определить количество единиц потоковой передачи в зависимости от количества событий, которые функция должна обрабатывать в секунду. Дополнительные сведения о единицах потоковой передачи см. в статье [о масштабировании заданий Stream Analytics](stream-analytics-scale-jobs.md#configuring-streaming-units).

Как правило, на каждые 6 SU приходится 20 одновременных подключений к веб-службе машинного обучения, за исключением того, что задания с 1 SU и 3 SU также получат 20 одновременных подключений. Например, если скорость передачи входных данных равна 200 000 событий в секунду и используется размер пакета по умолчанию (1000), в результате задержка веб-службы с мини-пакетом на 1000 событий будет составлять 200 мс. Это означает, что каждое подключение может отправлять в веб-службу машинного обучения 5 запросов в секунду. С 20 соединениями задание Stream Analytics может обрабатывать 20 000 событий за 200 мс и, соответственно, 100 000 событий в секунду. Таким образом, чтобы обрабатывать 200 000 событий в секунду, заданию Stream Analytics требуется 40 одновременных подключений, что соответствует 12 SU. На следующей схеме показан запрос из задания Stream Analytics к конечной точке веб-службы машинного обучения. На каждые 6 SU приходится максимум 20 одновременных подключений к веб-службе машинного обучения.

![Пример: масштабирование 2 заданий Stream Analytics с помощью функций машинного обучения](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-00.png "Пример: масштабирование 2 заданий Stream Analytics с помощью функций машинного обучения")

В общем случае, если ***B*** — размер пакета, а ***L*** — задержка веб-службы при размере пакета B в миллисекундах, пропускная способность задания Stream Analytics с ***N*** SU будет составлять:

![Формула масштабирования Stream Analytics с помощью функций машинного обучения](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-02.png "Формула масштабирования Stream Analytics с помощью функций машинного обучения")

Дополнительный параметр, который следует учитывать, — максимальное количество одновременных вызовов на стороне веб-службы машинного обучения. Для него рекомендуется задать максимальное значение (в настоящее время 200).

Дополнительные сведения об этом параметре см. в статье [Масштабирование веб-службы](../machine-learning/machine-learning-scaling-webservice.md).

## Пример: анализ мнений

В следующем примере показано задание Stream Analytics с функцией машинного обучения для анализа мнений, как описано в руководстве [Общие сведения о Stream Analytics и интеграции машинного обучения](stream-analytics-machine-learning-integration-tutorial.md).

Запрос представляет собой простой полностью секционированный запрос, за которым следует функция **sentiment**, как показано ниже.

    WITH subquery AS (
        SELECT text, sentiment(text) as result from input
    )
    
    Select text, result.[Score]
    Into output
    From subquery

Рассмотрим следующий сценарий: необходимо создать задание Stream Analytics для анализа мнений в твитах (событиях) с пропускной способностью 10 000 твитов в секунду. Достаточно ли 1 SU, чтобы это задание Stream Analytics могло обрабатывать нужный объем трафика? Если использовать размер пакета по умолчанию (1000), задание должно справиться с входными данными. Дополнительно добавленная функция машинного обучения будет создавать задержку не более одной секунды — это обычная задержка по умолчанию для веб-службы машинного обучения по анализу мнений (при размере пакета по умолчанию 1000). **Общая** (сквозная) задержка задания Stream Analytics обычно составляет несколько секунд. Изучите это задание Stream Analytics более подробно, *особенно* вызовы функций машинного обучения. При размере пакета 1000 и пропускной способности 10 000 событий количество запросов к веб-службе будет составлять примерно 10. Даже при 1 SU количество одновременных подключений будет достаточным для обработки этого входящего трафика.

Но что делать, если частота входящих событий увеличится в 100 раз и задание Stream Analytics должно будет обрабатывать 1 000 000 твитов в секунду? Существуют два варианта:

1.  Увеличить размер пакета.
2.  Секционировать входной поток для обработки событий в параллельном режиме.

Если выбрать первый вариант, увеличится **задержка** задания.

Для второго варианта потребуется подготовить дополнительные единицы SU, которые, в свою очередь, будут создавать дополнительные параллельные запросы к веб-службе машинного обучения. Это означает, что **стоимость** задания увеличится.


Предположим, что задержка веб-службы машинного обучения по анализу мнений составляет 200 мс для пакетов размером до 1000 событий, 250 мс для пакетов на 5000 событий, 300 мс для пакетов на 10 000 событий и 500 мс для пакетов на 25 000 событий.

1. Используя первый вариант (**без** подготовки дополнительных единиц SU), можно увеличить размер пакета до **25 000**. Это, в свою очередь, позволит заданию обрабатывать 1 000 000 событий при 20 одновременных подключениях к веб-службе машинного обучения (с задержкой 500 мс на один вызов). Поэтому дополнительная задержка задания Stream Analytics из-за запросов функции анализа мнений к запросам веб-службы машинного обучения увеличится с **200 мс** до **500 мс**. Однако обратите внимание, что размер пакета **не может** увеличиваться бесконечно: в веб-службах машинного обучения допускается размер полезных данных запроса не более 4 МБ, так как веб-службе запросов требуется время ожидания после 100 секунд работы.
2. Если используется второй вариант, размер пакета остается неизменным (1000), и при задержке веб-службы в 200 мс каждые 20 одновременных подключений к веб-службе смогут обрабатывать 1000 * *20* * 5 событий, то есть 100 000 событий в секунду. Таким образом, для обработки 1 000 000 событий в секунду заданию потребуется 60 SU. По сравнению с первым вариантом задание Stream Analytics будет создавать больше пакетных запросов к веб-службе, что приведет к увеличению затрат.

Ниже приведена таблица пропускной способности (количества событий в секунду) задания Stream Analytics для разного количества SU и размеров пакета.

| Количество SU | | | | Размер пакета (задержка службы машинного обучения) | |
|--------|-------------------------|---------------|---------------|----------------|----------------|
| | | | | | |
| | 500 (200 мс) | 1000 (200 мс) | 5000 (250 мс) | 10 000 (300 мс) | 25 000 (500 мс) |
| 1 ЕП | 2500 | 5 000 | 20 000 | 30 000 | 50 000 |
| 3 SU | 2500 | 5 000 | 20 000 | 30 000 | 50 000 |
| 6 SU | 2500 | 5 000 | 20 000 | 30 000 | 50 000 |
| 12 SU | 5 000 | 10 000 | 40 000 | 60 000 | 100 000 |
| 18 SU | 7500 | 15 000 | 60 000 | 90 000 | 150 000 |
| 24 SU | 10 000 | 20 000 | 80 000 | 120 000 | 200 000 |
| … | … | … | … | … | … |
| 60 SU | 25 000 | 50 000 | 200 000 | 300 000 | 500 000 |

Теперь у вас есть четкое представление о том, как работают функции машинного обучения в Stream Analytics. Скорее всего, вы также знаете, что задания Stream Analytics извлекают данные из источников данных и каждая операция извлечения возвращает пакет событий, которые должно обработать задание Stream Analytics. Каким образом эта модель извлечения данных влияет на запросы к веб-службе машинного обучения?

Как правило, размер пакета, заданный для функций машинного обучения, не делится точно на количество событий, возвращаемых каждой операцией извлечения, которую выполняет задание Stream Analytics. Когда это происходит, веб-служба машинного обучения вызывается с помощью "частичных" пакетов. Это делается во избежание дополнительных затрат на задержку задания при объединении событий из разных операций извлечения.

## Новые метрики мониторинга, связанные с функциями

В области мониторинга задания Stream Analytics добавлены три дополнительные метрики, связанные с функциями. Это "Запросы функций", "События функций" и "Запросы функций со сбоем", как показано на следующем рисунке.

![Метрики масштабирования Stream Analytics с помощью функций машинного обучения](./media/stream-analytics-scale-with-ml-functions/stream-analytics-scale-with-ml-functions-01.png "Метрики масштабирования Stream Analytics с помощью функций машинного обучения")

Вот их определения:

**Запросы функций** — количество запросов функций.

**События функций** — количество событий в запросах функций.

**Запросы функций со сбоем** — количество запросов функций, завершившихся сбоем.

## Общие выводы  

Подытожим основные тезисы. Итак, чтобы масштабировать задания Stream Analytics с помощью функций машинного обучения, необходимо учитывать следующие аспекты.

1.  Частота входящих событий.
2.  Допустимая задержка для выполняющегося задания Stream Analytics (и, соответственно, размер пакета для запросов веб-службы машинного обучения).
3.  Количество подготовленных единиц SU Stream Analytics и количество запросов веб-службы машинного обучения (дополнительные расходы, связанные с использованием функций).

В качестве примера был использован полностью секционированный запрос Stream Analytics. Если требуется более сложный запрос, посетите [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/ru-RU/home?forum=AzureStreamAnalytics). Это превосходный ресурс, на котором можно получить дополнительные сведения от команды Stream Analytics.

## Дальнейшие действия

Дополнительные сведения о службе Stream Analytics см. в следующих статьях:

- [Приступая к работе с Azure Stream Analytics](stream-analytics-get-started.md)
- [Масштабирование заданий в службе Azure Stream Analytics](stream-analytics-scale-jobs.md)
- [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
- [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

<!---HONumber=AcomDC_0921_2016-->