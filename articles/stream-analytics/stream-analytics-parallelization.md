---
title: Использование параллелизации запросов и масштабирования в Azure Stream Analytics
description: В этой статье объясняется, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки определения запроса и определения единиц потоковой передачи.
services: stream-analytics
author: JSeb225
ms.author: jeanb
manager: kfile
ms.reviewer: jasonh
ms.service: stream-analytics
ms.topic: conceptual
ms.date: 05/07/2018
ms.openlocfilehash: 44a7c0721d8a0683162d2219bff0e4a4ecb117e6
ms.sourcegitcommit: e221d1a2e0fb245610a6dd886e7e74c362f06467
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/07/2018
ms.locfileid: "33777633"
---
# <a name="leverage-query-parallelization-in-azure-stream-analytics"></a>Использование параллелизации запросов в Azure Stream Analytics
В этой статье показано, как воспользоваться преимуществами параллелизма в Azure Stream Analytics. Узнайте, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки аналитики определения запроса.
Предварительно может потребоваться ознакомиться с концепцией потоковой единицы, которая описана в статье [Оптимизация задания для эффективного использования единиц потоковой передачи](stream-analytics-streaming-unit-consumption.md).

## <a name="what-are-the-parts-of-a-stream-analytics-job"></a>Из каких частей состоит задание службы Stream Analytics?
Определение задания Stream Analytics включает запрос, а также входные и выходные данные. Входные данные — это точки, откуда задания считывают данные из потока. Запрос используется для преобразования потока входных данных, а выходные данные являются точками, куда направляются результаты задания.  

Задание требует по крайней мере один источник входных данных для потока данных. Входной источник потока данных может храниться в концентраторе событий Azure или в хранилище BLOB-объектов Azure. Дополнительные сведения см. в статьях [Что такое Stream Analytics?](stream-analytics-introduction.md) и [Приступая к работе с Azure Stream Analytics: выявление мошенничества в режиме реального времени](stream-analytics-real-time-fraud-detection.md).

## <a name="partitions-in-sources-and-sinks"></a>Секции в источниках и приемниках
Масштабирование задания Stream Analytics реализует преимущества использования секций во входных или выходных данных. Секционирование позволяет разделить данные на подмножества на основе ключа секции. Процесс, который использует данные (например, задание Streaming Analytics), может получать и записывать различные секции параллельно, тем самым повышая пропускную способность. 

### <a name="inputs"></a>Входные данные
Все входные данные в Azure Stream Analytics могут использовать преимущества секционирования:
-   Концентратор событий (требуется явно задать ключ раздела с помощью ключевого слова PARTITION BY).
-   Концентратор событий (требуется явно задать ключ раздела с помощью ключевого слова PARTITION BY).
-   Хранилище BLOB-объектов

### <a name="outputs"></a>outputs

При работе со Stream Analytics можно воспользоваться преимуществами секционирования в концентраторах событий и выходных данных:
-   Хранилище Azure Data Lake.
-   Функции Azure
-   таблице Azure
-   Хранилище BLOB-объектов (требуется явно задать ключ раздела).
-   CosmosDB (требуется явно задать ключ раздела).
-   Концентратор событий (требуется явно задать ключ раздела).
-   Центр Интернета вещей (требуется явно задать ключ раздела).
-   Служебная шина Azure

Выходные данные PowerBI, SQL и хранилища данных SQL не поддерживают секционирование. Однако можно по-прежнему секционировать входные данные как описано в [этом разделе](#multi-step-query-with-different-partition-by-values). 

Дополнительные сведения об этих секциях см. в следующих статьях:

* [Обзор функций концентраторов событий](../event-hubs/event-hubs-features.md#partitions)
* [Секционирование данных](https://docs.microsoft.com/azure/architecture/best-practices/data-partitioning#partitioning-azure-blob-storage)


## <a name="embarrassingly-parallel-jobs"></a>Задания с усложненным параллелизмом
Задание с *усложненным параллелизмом* — это самый масштабируемый сценарий в Azure Stream Analytics. Он соединяет один раздел входных данных с одним экземпляром запроса и одним разделом выходных данных. Такой параллелизм имеет следующие требования:

1. Если в логике запроса применяется ключ, который обрабатывается тем же экземпляром запроса, необходимо только проследить за тем, чтобы события попадали в ту же секцию входных данных. При использовании концентраторов событий или Центра Интернета вещей это означает, что для данных событий должно быть задано значение **PartitionKey**. Кроме того, можно использовать секционированные отправители. Для хранилища BLOB-объектов это означает, что события отправляются в папку той же секции. Если логика запроса не требует обработки ключа тем же экземпляром запроса, это требование можно проигнорировать. В качестве примера такой логики можно привести простой запрос select, project или filter.  

2. После того как данные будут распределены в источнике данных, необходимо убедиться в том, что запрос разбит на секции. Для этого на каждом этапе используется параметр **PARTITION BY**. Этапов может быть несколько, но на каждом из них должен использоваться один и тот же ключ. Сейчас для выполнения заданий с параллелизмом необходимо использовать значение **PartitionId** в качестве ключа секционирования.  

3. Большая часть выходных данных может воспользоваться преимуществами секционирования, однако при использовании типа выходных данных, не поддерживающих секционирование, задание не будет полностью параллельным. Дополнительные сведения см. в [этом разделе](#outputs).

4. Число секций входных данных должно совпадать с числом секций выходных данных. Выходные данные хранилища BLOB-объектов могут поддерживать секции и наследуют схему секционирования вышестоящего запроса. Если для хранилища BLOB-объектов указан ключ секции, то данные секционируются по входным секциям, поэтому результат по-прежнему вычисляется параллельно. Примеры значений секций, позволяющие выполнять задания с полной параллельной обработкой:

   * 8 секций входных данных концентраторов событий и 8 секций выходных данных концентраторов событий;
   * 8 секций входных данных концентраторов событий и выходные данные хранилища BLOB-объектов;
   * 8 входных секций концентраторов событий и выходные данные хранилища BLOB-объектов, секционированные по пользовательскому полю с произвольной кратностью;
   * 8 секций входных данных хранилища BLOB-объектов и выходные данные хранилища BLOB-объектов;
   * 8 секций входных данных хранилища BLOB-объектов и 8 секций выходных данных концентраторов событий.

Далее рассмотрим примеры сценариев с усложненным параллелизмом.

### <a name="simple-query"></a>Простой запрос

* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — концентратор событий с 8 секциями.

Запрос:

    SELECT TollBoothId
    FROM Input1 Partition By PartitionId
    WHERE TollBoothId > 100

Этот запрос является простым фильтром. Поэтому нам не нужно беспокоиться о секционировании входных данных, которые передаются в концентратор событий. Обратите внимание, что запрос содержит значение **PARTITION BY PartitionId**, поэтому он удовлетворяет требованию 2, указанному выше. Выходные данные концентраторов событий необходимо настроить, указав значение **PartitionId** в качестве ключа секции. Последняя проверка: число секций входных данных должно быть равно числу секций выходных данных.

### <a name="query-with-a-grouping-key"></a>Запрос с ключом группирования

* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — хранилище BLOB-объектов.

Запрос:

    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Этот запрос содержит ключ группирования. Поэтому события, сгруппированные вместе, должны быть отправлены в одну секцию концентратора событий. Так как в этом примере выполняется группирование по TollBoothID, необходимо убедиться, что TollBoothID используется в качестве ключа секции при отправке событий в концентратор событий. Затем в ASA, можно использовать **PARTITION BY PartitionId** для наследования этой схемы разделов и обеспечения полной паралеллизации. Так как выходными данными является хранилище BLOB-объектов, не нужно беспокоиться о настройке значения ключа секции, как описано в требовании 4.

## <a name="example-of-scenarios-that-are-not-embarrassingly-parallel"></a>Примеры сценариев *без* усложненного параллелизма

В предыдущем разделе мы рассмотрели сценарии с усложненным параллелизмом. В этом разделе обсуждаются сценарии, которые не соответствуют всем показателям усложненного параллелизма. 

### <a name="mismatched-partition-count"></a>Несоответствие в числе секций
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — концентратор событий с 32 секциями.

В этом случае тип запроса не имеет значения. Если число секций входных данных не совпадает с числом секций выходных данных, топология не является топологией с усложненным параллелизмом. Однако все равно можно получить некоторый уровень или паралеллизацию.

### <a name="query-using-non-partitioned-output"></a>Запрос с использованием несекционированных выходных данных
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — PowerBI.

В настоящее время выходные данные PowerBI не поддерживают секционирование. Таким образом этот сценарий не считается сценарием с усложненным параллелизмом.

### <a name="multi-step-query-with-different-partition-by-values"></a>Многоэтапный запрос с разными значениями параметра PARTITION BY
* Входные данные — концентратор событий с 8 секциями.
* Выходные данные — концентратор событий с 8 секциями.

Запрос:

    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId, PartitionId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1 Partition By TollBoothId
    GROUP BY TumblingWindow(minute, 3), TollBoothId

Как видите, на втором этапе в качестве ключа секционирования используется **TollBoothId** . Он не совпадает с ключом в первом шаге, а значит, потребует перетасовки. 

Мы рассмотрели несколько примеров заданий Stream Analytics, соответствующих и не соответствующих критериям топологии с усложненным параллелизмом. При соответствии, задания будут иметь максимально возможное для них масштабирование. Для заданий, не соответствующих ни одному из этих профилей, в дальнейшем будут выпущены обновления в отношении масштабирования. А пока придерживайтесь описанных ниже рекомендаций.

## <a name="calculate-the-maximum-streaming-units-of-a-job"></a>Расчет максимального количества единиц потоковой передачи для задания
Общее число единиц потоковой передачи, которое можно использовать заданием Stream Analytics, зависит от числа шагов в запросе, определенных для задания, и количества разделов для каждого шага.

### <a name="steps-in-a-query"></a>Шаги в запросе
Запрос может иметь один или несколько шагов. Каждый шаг — это вложенный запрос, определенный с помощью ключевого слова **WITH**. Запрос за рамками ключевого слова **WITH** (только один запрос) также учитывается в качестве шага (например, инструкция **SELECT** в следующем запросе).

Запрос:

    WITH Step1 AS (
        SELECT COUNT(*) AS Count, TollBoothId
        FROM Input1 Partition By PartitionId
        GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )
    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute,3), TollBoothId

Этот запрос включает 2 шага.

> [!NOTE]
> Этот запрос будет описан далее в этой статье.
>  

### <a name="partition-a-step"></a>Разделы шага
Разделение шага требует наличия следующих условий.

* Источник входных данных должен быть секционирован. 
* Инструкция **SELECT** запроса должна читаться из разделенного источника входных данных.
* Запрос внутри шага должен включать ключевое слово **PARTITION BY**.

Если запрос разделен, входные данные событий будут обработаны и объединены в отдельные группы секции, а выходные данные событий будут сгенерированы для каждой из групп. Если желательно иметь объединенный запрос, необходимо создать второй неразделенный шаг для объединения.

### <a name="calculate-the-max-streaming-units-for-a-job"></a>Рассчитайте максимальное количество единиц потоковой передачи для задания
Все несекционированные шаги можно масштабировать до шести единиц потоковой передачи для задания Stream Analytics. Помимо этого можно добавить 6 единиц потоковой передачи для каждой секции на шаге секционирования.
Дополнительные **примеры** можно просмотреть в таблице ниже.

| Запрос                                               | Максимальное количество единиц потоковой передачи для задания |
| --------------------------------------------------- | ------------------- |
| <ul><li>Запрос содержит один шаг.</li><li>Шаг не секционирован.</li></ul> | 6 |
| <ul><li>Поток входных данных секционирован по 16.</li><li>Запрос содержит один шаг.</li><li>Шаг является секционированным.</li></ul> | 96 (6 * 16 секций) |
| <ul><li>Запрос состоит из двух шагов.</li><li>Ни один из шагов не секционирован.</li></ul> | 6 |
| <ul><li>Поток входных данных секционирован по 3.</li><li>Запрос состоит из двух шагов. Входной шаг секционирован, а второй шаг — нет.</li><li>Инструкция <strong>SELECT</strong> считывает из секционированных входных данных.</li></ul> | 24 (18 и 6 секционированных и несекционированных шагов соответственно) |

### <a name="examples-of-scaling"></a>Примеры масштабирования

Следующий запрос вычисляет количество машин, проходящих через пропускной пункт с тремя пунктами для оплаты и пропускной способности три минуты для каждого пункта. Этот запрос можно масштабировать до шести единиц потоковой передачи.

    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Чтобы использовать дополнительные единицы потоковой передачи для запроса, входной поток данных и запрос должны быть секционированы. При наличии секции потока данных, равной 3, следующий измененный запрос можно масштабировать до 18 единиц потоковой передачи.

    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Если запрос секционирован, входные данные событий будут обработаны и объединены в отдельные группы секций. Кроме того, для каждой из групп будут сформированы выходные данные событий. Секционирование может вызвать некоторые непредвиденные результаты, если поле **GROUP BY** не является ключом секции во входном потоке данных. Например, поле **TollBoothId** в предыдущем запросе не является ключом секции **Input1**. В результате данные из пункта 1 можно распределить между несколькими секциями.

Каждая из секций **Input1** будет обрабатываться отдельно с помощью Stream Analytics. В результате будет создаваться несколько записей для автомобиля, проходящего через один и тот же пункт. Если нельзя изменить ключ секции ввода, эту проблему можно устранить, добавив несекционированные действия для вычисления значений по секциям, например:

    WITH Step1 AS (
        SELECT COUNT(*) AS Count, TollBoothId
        FROM Input1 Partition By PartitionId
        GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )

    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1
    GROUP BY TumblingWindow(minute, 3), TollBoothId

Этот запрос можно увеличить до 24 единиц потоковой передачи.

> [!NOTE]
> При объединении двух потоков убедитесь, что потоки разделены с помощью ключа секции столбца, используемого для объединения. Также убедитесь, что количество секций в обоих потоках одинаковое.
> 
> 





## <a name="get-help"></a>Получение справки
За дополнительной помощью обращайтесь на наш [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/azure/home?forum=AzureStreamAnalytics).

## <a name="next-steps"></a>Дальнейшие действия
* [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
* [Приступая к работе с Azure Stream Analytics](stream-analytics-real-time-fraud-detection.md)
* [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
* [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)

<!--Image references-->

[img.stream.analytics.monitor.job]: ./media/stream-analytics-scale-jobs/StreamAnalytics.job.monitor-NewPortal.png
[img.stream.analytics.configure.scale]: ./media/stream-analytics-scale-jobs/StreamAnalytics.configure.scale.png
[img.stream.analytics.perfgraph]: ./media/stream-analytics-scale-jobs/perf.png
[img.stream.analytics.streaming.units.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsStreamingUnitsExample.jpg
[img.stream.analytics.preview.portal.settings.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsPreviewPortalJobSettings-NewPortal.png   

<!--Link references-->

[microsoft.support]: http://support.microsoft.com
[azure.event.hubs.developer.guide]: http://msdn.microsoft.com/library/azure/dn789972.aspx

[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-real-time-fraud-detection.md
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301

