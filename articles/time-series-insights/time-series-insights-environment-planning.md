---
title: Подготовка к масштабированию среды Аналитики временных рядов Azure | Документация Майкрософт
description: В этой статье описано, как при планировании среды Аналитики временных рядов Azure учесть все рекомендации в отношении емкости хранилища, времени хранения, объема входящих данных и мониторинга.
services: time-series-insights
ms.service: time-series-insights
author: jasonwhowell
ms.author: jasonh
manager: jhubbard
ms.reviewer: v-mamcge, jasonh, kfile, anshan
ms.devlang: csharp
ms.workload: big-data
ms.topic: conceptual
ms.date: 11/15/2017
ms.openlocfilehash: 45f081c4e1dbd32b46c8a69f32b0b205b948f9b5
ms.sourcegitcommit: 266fe4c2216c0420e415d733cd3abbf94994533d
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/01/2018
ms.locfileid: "34652327"
---
# <a name="plan-your-azure-time-series-insights-environment"></a>Планирование среды Аналитики временных рядов Azure

В этой статье описано, как спланировать среду для Аналитики временных рядов Azure с учетом ожидаемого объема входящих данных и требуемого срока хранения данных.

## <a name="best-practices"></a>Рекомендации

Чтобы приступить к работе с Аналитикой временных рядов, желательно знать ожидаемый объем передаваемых данных в минуту и срок хранения этих данных.  

Дополнительные сведения о емкости и сроках хранения для двух предложений Аналитики временных рядов см. в описании [цен на Аналитику временных рядов](https://azure.microsoft.com/pricing/details/time-series-insights/).

Чтобы планирование привело к долгосрочному успеху, учтите следующие важные характеристики: 
- Емкость хранилища
- Срок хранения данных
- Объем входящих данных 
- Формирование событий
- Обеспечение наличия эталонных данных

## <a name="understand-storage-capacity"></a>Концепция емкости хранилища
По умолчанию Аналитика временных рядов определяет срок хранения данных, исходя из предоставленного объема хранилища (произведение количества единиц и объема хранилища для одной единицы) и объема входящих данных.

## <a name="understand-data-retention"></a>Концепция срока хранения данных
В среде Аналитики временных рядов можно настроить параметр **Время хранения данных** с максимальным значением 400 дней хранения.  Аналитика временных рядов поддерживает два режима. В одном из них (который используется по умолчанию) среда обеспечивает наличие самых свежих данных, а во втором — соблюдение требований по срокам хранения. Во втором режиме прием входящих данных приостанавливается, когда достигается предел предоставленной емкости хранилища.  Время хранения и режим работы можно настроить на странице конфигурации среды на портале Azure.

В среде Аналитики временных рядов вы можете указать время хранения не более 400 дней.

## <a name="configure-data-retention"></a>Настройка времени хранения данных

1. Выберите нужную среду Аналитики временных рядов на [портале Azure](https://portal.azure.com).

2. На **странице среды Аналитики временных рядов** в разделе **Параметры** выберите действие **Настройка**. 

3. В поле **Время хранения данных (в днях)** введите значение от 1 до 400.

   ![Настройка времени хранения](media/environment-mitigate-latency/configure-retention.png)

## <a name="understand-ingress-capacity"></a>Концепция объема входящих данных

Также при планировании важно учесть объем входящих данных, который вычисляется на основе поминутного распределения. 

С точки зрения регулирования входящий пакет данных размером 32 КБ рассматривается как 32 события размером по 1 КБ каждое. Максимальный допустимый размер события составляет 32 КБ. Пакеты данных, размер которых превышает 32 КБ, усекаются.

В следующей таблице указан объем входящих данных для каждого номера SKU.

|SKU  |Число событий за месяц на каждую единицу  |Размер событий за месяц на каждую единицу  |Число событий в минуту на каждую единицу  | Размер событий в минуту на каждую единицу   |
|---------|---------|---------|---------|---------|
|S1     |   30 млн     |  30 ГБ     |  700    |  700 КБ   |
|S2     |   300 млн    |   300 ГБ   | 7000   | 7000 КБ  |

В одной среде допускается до 10 единиц SKU S1 и S2. Миграция среды с SKU S1 на S2 или с SKU S2 на S1 не поддерживается. 

Чтобы оценить объем входящих данных, сначала следует вычислить общий объем данных за весь месяц. Далее определите требуемую скорость в минуту, так как задержки и регулирование применяются именно с такими показателями.

Если вплески скорости поступления данных продолжаются не более 24 часов, Аналитика временных рядов позволяет "догнать" такой поток, временно вдвое увеличивая указанную выше скорость входящих данных. 

Например, если вы используете один номер SKU S1, а объем входящих данных составляет 700 событий в минуту с отдельными всплесками длительностью 1 час и объемом не более 1400 событий в минуту, то вы не заметите никаких задержек в такой среде. Но если скорость превысит 1400 событий на период более одного часа, вы столкнетесь с задержками в получении данных для визуализации и запросов в такой среде. 

Возможно, вы заранее не знаете точный объем передаваемых данных. В этом случае вы можете применить телеметрию данных для [Центра Интернета вещей Azure](https://docs.microsoft.com/azure/iot-hub/iot-hub-metrics) и [Концентраторов событий Azure](https://blogs.msdn.microsoft.com/cloud_solution_architect/2016/05/25/using-the-azure-rest-apis-to-retrieve-event-hub-metrics/) на портале Azure. Данные телеметрии помогут вам определить параметры для подготовки среды. На портале Azure откройте страницу **Метрики** для соответствующего источника, чтобы просмотреть данные телеметрии для него. Изучив метрики для источника событий вы сможете более эффективно спланировать и подготовить среду Аналитики временных рядов.

### <a name="calculate-ingress-requirements"></a>Расчет требований к объему входящих данных

- Убедитесь, что среда имеет объем входящих данных, превышающий вашу среднюю скорость поступления данных, и способна выдержать пиковые значения скорости, вдвое превышающие этот объем на период не более одного часа.

- Если пиковые значения скорости сохраняются на период более одного часа, используйте при расчетах пиковое значение в качестве среднего, чтобы среда имела достаточную производительность для этих пиковых периодов.
 
### <a name="mitigate-throttling-and-latency"></a>Устранение регулирования и задержек

Сведения о том, как предотвратить задержки и регулирование, вы найдете в [этой статье](time-series-insights-environment-mitigate-latency.md). 

## <a name="shaping-your-events"></a>Формирование событий
Важно, чтобы способ отправки событий в TSI поддерживал размер подготавливаемой среды (и наоборот, можно сопоставить размер среды с количеством событий, считываемых TSI, и размером каждого события).  Также важно думать об атрибутах, по которым необходимо выполнять срез и фильтрацию во время отправки запросов данных.  Учитывая эти факторы, мы предлагаем проверить раздел о формировании JSON в [документации] (https://docs.microsoft.com/azure/time-series-insights/time-series-insights-send-events) по *отправке событий*.  Он находится в нижней части страницы.  

## <a name="ensuring-you-have-reference-data-in-place"></a>Обеспечение наличия эталонных данных
Эталонный набор данных — это коллекция элементов, которые дополняют события из вашего источника событий. Обработчик входящего трафика аналитики временных рядов соединяет каждое событие из вашего источника событий с соответствующей строкой данных в вашем эталонном наборе данных. Это дополненное событие становится доступным для запроса. Это соединение основано на столбцах первичного ключа, определенных в эталонном наборе данных.

Обратите внимание, что ретроактивное объединение с эталонными данными не поддерживается. Это означает, что сопоставляются и присоединяются к эталонному набору данных после его настройки и загрузки только текущие и будущие входящие данные.  Если вы планируете отправлять большой объем исторических данных в TSI, но не будете сначала создавать или передать эталонные данные в TSI, вам может потребоваться переделывать всю работу (не очень забавно).  

Дополнительные сведения о создании, передаче эталонных данных и управлении ими в TSI можно узнать в [документации] (https://docs.microsoft.com/azure/time-series-insights/time-series-insights-add-reference-data-set) по *эталонным данным*.


## <a name="next-steps"></a>Дополнительная информация
- [Как создать источник событий концентратора событий](time-series-insights-how-to-add-an-event-source-eventhub.md)
- [Как создать источник событий Центра Интернета вещей](time-series-insights-how-to-add-an-event-source-iothub.md)
