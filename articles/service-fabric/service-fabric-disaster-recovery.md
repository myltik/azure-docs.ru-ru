---
title: Аварийное восстановление в Azure Service Fabric | Документация Майкрософт
description: Azure Service Fabric предлагает возможности, необходимые для устранения всех типов сбоев. В этой статье описаны типы сбоев, которые могут возникать, и приведены способы их устранения.
services: service-fabric
documentationcenter: .net
author: masnider
manager: timlt
editor: ''
ms.assetid: ab49c4b9-74a8-4907-b75b-8d2ee84c6d90
ms.service: service-fabric
ms.devlang: dotNet
ms.topic: conceptual
ms.tgt_pltfrm: NA
ms.workload: NA
ms.date: 08/18/2017
ms.author: masnider
ms.openlocfilehash: 295772b70529f79c7a4c135d8ea7c12a1c661fe6
ms.sourcegitcommit: eb75f177fc59d90b1b667afcfe64ac51936e2638
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/16/2018
ms.locfileid: "34206442"
---
# <a name="disaster-recovery-in-azure-service-fabric"></a>Аварийное восстановление в Azure Service Fabric
Для обеспечения высокого уровня доступности крайне важно гарантировать продолжение работы всех типов служб при любых сбоях. Это особенно важно в ситуациях незапланированных сбоев, которые находятся вне вашего контроля. В этой статье описываются некоторые часто встречающиеся виды сбоев, которые могут привести к авариям, если их не смоделировать и не взять под контроль должным образом. Также рассматриваются способы устранения рисков и действия при аварии, если она все таки произошла. Цель этого руководства — помочь ограничить или избежать простоя и потери данных, при которых возникают сбои, запланированные или случайные.

## <a name="avoiding-disaster"></a>Предотвращение аварий
Основная цель Service Fabric — помочь в моделировании среды и служб таким образом, чтобы общие типы сбоев не приводили к авариям. 

В основном существует два типа сценариев аварий и сбоев:

1. Сбои оборудования или программного обеспечения.
2. Проблемы с работоспособностью.

### <a name="hardware-and-software-faults"></a>Сбои оборудования или программного обеспечения
Сбои оборудования и программного обеспечения — непредсказуемы. Самый простой способ предотвратить сбой — запускать несколько копий службы, распределенных на границах сбоя оборудования или программного обеспечения. Например, если служба выполняется только на одном конкретном компьютере, тогда сбой на таком компьютере приведет к аварии этой службы. Простой способ предотвратить этот сбой — убедиться, что служба действительно работает на нескольких компьютерах. Тестирование также необходимо, чтобы гарантировать, что сбой одного компьютера не нарушит работу выполняемой службы. Планирование ресурсов гарантирует, что можно создать экземпляр для замены в другом расположении и что снижение производительности не приведет к перегрузке оставшихся служб. Этот шаблон работает независимо от того, какой сбой вы пытаетесь предотвратить. Например, если выбран диапазон 10.0.0.0/20 для виртуальной сети, для пространства клиентских адресов можно выбрать 10.1.0.0/24. Если вы хотите избежать сбоев сети хранения данных, храните данные в нескольких сетях SAN. Если вы хотите избежать выхода из строя серверов и серверных стоек, используйте несколько серверов и серверных стоек. Если вы хотите предотвратить потерю центров обработки данных, службу следует запускать в нескольких регионах или центрах обработки данных Azure. 

При работе в таком режиме вы по-прежнему подвержены некоторым видам одновременных отказов, но при этом единичные и даже множественные сбои определенного типа (например, сбой одной виртуальной машины или сетевого соединения) обрабатываются автоматически, не приводя к аварии. Service Fabric предоставляет много механизмов развертывания кластера и управляет восстановлением работоспособности узлов и служб. Service Fabric также позволяет запускать несколько экземпляров служб во избежание аварий вследствие такого рода незапланированных сбоев.

Возможны ситуации, когда запуск развертывания, охватывающего все сбои, не представляется возможным. Например, может потребоваться больше аппаратных ресурсов, чем вы готовы оплатить, чтобы предотвратить сбои. При работе с распределенными приложениями дополнительные прыжки или репликация состояний между географическими регионами могут привести к неприемлемому уровню задержек. Этот уровень отличается для каждого приложения. В частности при сбоях программного обеспечения ошибка может возникнуть в службе, которую вы пытаетесь масштабировать. В этом случае дополнительные копии не предотвращают аварию, так как условие сбоя касается всех экземпляров.

### <a name="operational-faults"></a>Проблемы с работоспособностью
Даже если служба располагается во множестве географических регионов с большим количеством избыточных данных, она по-прежнему может столкнуться с катастрофическими событиями. Например, если кто-то случайно перенастроит DNS-имя службы или удалит его. Например, предположим, что имеется служба Service Fabric с отслеживанием состояния и кто-то случайно ее удалил. При отсутствии других планов по устранению рисков эта служба и все сведения о ее состоянии исчезнут. Для этих типов функциональных аварий (ошибок) требуются другие методы устранения рисков и шаги для восстановления, отличные от обычных незапланированных сбоев. 

Лучшие способы предотвращения подобных функциональных ошибок:
1. Ограничение оперативного доступа к среде.
2. Строгий аудит небезопасных операций.
3. Внедрение автоматизации, запрет изменений вручную или внештатных изменений и проверка определенных изменений в фактической среде перед их применением.
4. Гарантирование, что разрушительные операции будут "мягкими". "Мягкие операции" не вступают в силу немедленно и могут быть отменены в рамках определенного временного окна.

Service Fabric предоставляет некоторые механизмы для предотвращения функциональных сбоев, например обеспечение управления доступом на основе [ролей](service-fabric-cluster-security-roles.md) для операций с кластером. Однако для предотвращения большинства таких функциональных сбоев требуются организационные усилия и другие методы. Service Fabric предоставляет ряд механизмов для преодоления функциональных ошибок, в частности резервное копирование и восстановление служб с отслеживанием состояния.

## <a name="managing-failures"></a>Обработка сбоев
Целью Service Fabric почти всегда является автоматическая обработка сбоев. Тем не менее для обработки некоторых типов сбоев службам потребуется дополнительный код. Другие типы сбоев _не_ должны обрабатываться автоматически по причинам обеспечения непрерывности бизнес-процессов и безопасности. 

### <a name="handling-single-failures"></a>Обработка единичных сбоев
Единичные компьютеры могут выйти из строя по множеству причин. В некоторых случаях — это сбои оборудования, как например сбои источников питания или сетевого оборудования, а в других — сбои программного обеспечения. К последним относятся сбои операционной системы и самих служб. Service Fabric автоматически обнаруживает эти типы сбоев, включая ситуации, когда компьютер становится изолирован от других компьютеров из-за проблем с сетью.

Независимо от типа службы выполнение одного экземпляра приводит к простою службы, если по какой-либо причине происходит сбой этой копии. 

Для обработки любого единичного отказа следует обеспечить выполнение служб на нескольких узлах по умолчанию. Для служб без отслеживания состояния это можно сделать, задав для параметра `InstanceCount` значение больше 1. Для служб с отслеживанием состояния минимальное рекомендуемое значение всегда должно быть `TargetReplicaSetSize`, а значение `MinReplicaSetSize` — по крайней мере 3. Запуск нескольких копий кода службы гарантирует, что служба может автоматически обработать любой единичный отказ. 

### <a name="handling-coordinated-failures"></a>Обработка координированных сбоев
Скоординированные сбои могут происходить в кластере вследствие любых запланированных или незапланированных сбоев инфраструктуры и изменений или запланированных изменений программного обеспечения. Service Fabric моделирует зоны инфраструктуры, в которых возникают скоординированные сбои, как домены сбоя. Области, в которых будут возникать координируемые изменения программного обеспечения, моделируются как домены обновления. Дополнительные сведения о доменах сбоя и обновления см. [в этом документе](service-fabric-cluster-resource-manager-cluster-description.md), в котором описываются определение и топология кластера.

По умолчанию Service Fabric учитывает домены сбоя и обновления при планировании места запуска служб. По умолчанию Service Fabric пытается обеспечить выполнение служб в нескольких доменах сбоя и обновления, чтобы в случае запланированных или незапланированных изменений службы оставались доступными. 

Например, предположим, что сбой источника питания вызывает одновременный сбой стойки компьютеров. При выполнении нескольких копий службы потеря нескольких компьютеров в домене сбоя будет являться примером единичного сбоя для данной службы. Именно поэтому управление доменами сбоя крайне важно для обеспечения высокого уровня доступности служб. При запуске Service Fabric в Azure домены сбоя обрабатываются автоматически. В других средах процедура может быть отличной. При создании кластеров в локальной среде обеспечьте соответствующее сопоставление и планирование структуры домена сбоя.

Домены обновления можно использовать для моделирования областей, в которых программное обеспечение будет обновляться в одно время. По этой причине домены обновления также часто определяют границы, где программное обеспечение прекращает работу во время запланированного обновления. Обновления Service Fabric и ваших служб следуют той же модели. Дополнительные сведения о последовательном обновлении, доменах обновления и модели работоспособности Service Fabric, которая помогает предотвратить непредвиденные изменения, влияющие на кластер и службы, см. в следующих статьях:

 - [Обновление приложения](service-fabric-application-upgrade.md)
 - [Руководство по обновлению приложений Service Fabric с помощью Visual Studio](service-fabric-application-upgrade-tutorial.md)
 - [Общие сведения о наблюдении за работоспособностью системы в Service Fabric](service-fabric-health-introduction.md)

Для визуализации структуры кластера можно использовать схему кластера в [Service Fabric Explorer](service-fabric-visualizing-your-cluster.md):

<center>
![Узлы, распределенные между доменами сбоев в Service Fabric Explorer][sfx-cluster-map]
</center>

> [!NOTE]
> Моделирование областей сбоя, последовательных обновлений, выполнение множества экземпляров кода и состояния службы, правила размещения для обеспечения выполнения служб на доменах сбоя и обновления, а также встроенный мониторинг работоспособности — только **некоторые** функции, которые Service Fabric предоставляет для предотвращения аварий вследствие обычных функциональных проблем и ошибок. 
>

### <a name="handling-simultaneous-hardware-or-software-failures"></a>Обработка одновременных сбоев оборудования или программного обеспечения
Выше речь шла о единичных сбоях. Как видите, можно легко обрабатывать сбои служб с отслеживанием состояния и без отслеживания за счет выполнения нескольких копий кода (и состояния) на доменах сбоя и обновления. Также возможно возникновение нескольких одновременных случайных сбоев. Такие сбои с большей вероятностью могут привести к фактической аварии.


### <a name="random-failures-leading-to-service-failures"></a>Случайные сбои, вызывающие сбои службы
Предположим, что эта служба имеет значение 5 для параметра `InstanceCount` и несколько узлов, на которых были запущены экземпляры службы, вышли из строя одновременно. Service Fabric отвечает путем автоматического создания экземпляров для замены на других узлах. Экземпляры для замены будут создаваться, пока для службы не будет восстановлено нужное количество экземпляров. Например, предположим, что имеется служба без отслеживания состояния и параметр `InstanceCount` имеет значение -1, то есть она работает на всех допустимых узлах в кластере. Предположим, что некоторые из этих экземпляров завершили работу по причине сбоя. В таком случае Service Fabric замечает, что служба не находится в должном состоянии, и пытается создать экземпляры на узлах, где они отсутствуют. 

Для служб с отслеживанием состояния ситуация зависит от того, имеет ли служба сохраненное состояние. Она также зависит от того, как много реплик имела эта служба и сколько из них вышли из строя. Определение, случился ли сбой службы с отслеживанием состояния, и его обработка состоят из трех этапов:

1. Определение, произошла ли потеря кворума.
 - Потеря кворума происходит каждый раз, когда большая часть реплик службы с отслеживанием состояния выходят из строя одновременно, включая первичную.
2. Определение, является ли потеря кворума постоянной.
 - В большинстве случаев сбои являются временными. Перезапускаются процессы, узлы и виртуальные машины, а также выполняется автоматическое восстановление секций сети. Однако иногда сбои являются постоянными. 
    - Для служб без сохраненного состояния потеря кворума или нескольких реплик _немедленно_ приводит к постоянной потере кворума. Когда Service Fabric обнаруживает потерю кворума в непостоянной службе с отслеживанием состояния, она немедленно переходит к шагу 3, объявляя (возможную) потерю данных. Это происходит потому, что Service Fabric знает, что нет смысла ждать восстановления реплик, так как даже если они будут восстановлены, они окажутся пустыми.
    - Для постоянных служб с отслеживанием состояния сбой кворума или нескольких реплик приводит к тому, что Service Fabric ожидает возобновления работы реплик и восстановления кворума. Это приводит к сбою любых операций _записи_ в затронутые секции (или наборы реплик) службы. Тем не менее операции чтения по-прежнему могут выполняться с пониженным уровнем обеспечения согласованности. Период времени по умолчанию, на протяжении которого Service Fabric ожидает восстановления кворума, является бесконечным, так как в противном случае может возникнуть вероятность потери данных и другие риски. Переопределить значение по умолчанию параметра `QuorumLossWaitDuration` можно, но не рекомендуется. Вместо этого в данный момент необходимо предпринять все возможное для восстановления вышедших из строя реплик. Требуется восстановить неработающие узлы и повторно подключить диски, где хранится постоянное локальное состояние. Если причиной потери кворума стал сбой процесса, Service Fabric автоматически попытается воссоздать процессы и перезапустить реплики внутри них. В случае сбоя Service Fabric сообщит об ошибках работоспособности. Если это возможно, реплики обычно восстанавливаются. В некоторых случаях реплики не удается подключить обратно. Например, могут выйти из строя все диски или каким-то образом быть разрушены физически компьютеры. В таких случаях потеря кворума будет постоянной. Чтобы дать указание Service Fabric прекратить ожидание восстановления неработающих реплик, администратор кластера должен определить, какие секции служб повреждены, и вызвать API `Repair-ServiceFabricPartition -PartitionId` или ` System.Fabric.FabricClient.ClusterManagementClient.RecoverPartitionAsync(Guid partitionId)`.  Этот API позволяет указать идентификатор секции для перемещения из состояния потери кворума в состояние потенциальной потери данных.

> [!NOTE]
> Этот API _всегда_ небезопасно использовать, кроме как для целевого применения для конкретных секций. 
>

3. Определение наличия фактической потери данных и восстановление из резервных копий
  - Когда Service Fabric вызывает метод `OnDataLossAsync`, это всегда происходит по причине _возможной_ потери данных. Service Fabric всегда направляет этот вызов к _лучшей_ оставшейся реплике. Это любая реплика с лучшим показателем состояния. Данные считаются _потенциально_ утерянными, поскольку возможно, что оставшаяся реплика фактически имеет состояние, аналогичное состоянию первичной реплики перед ее выходом из строя. Однако возможность сравнить состояние для Service Fabric или операторов отсутствует. На этом этапе Service Fabric также определяет, что реплики не будут восстановлены. Это решение принимается в момент прекращения ожидания восстановления потери кворума. Лучше всего заморозить службу и дождаться помощи администратора. Что же дает типичная реализация метода `OnDataLossAsync`?
  - Во-первых, запись о запуске `OnDataLossAsync` и запуск необходимых административных оповещений.
   - Обычно на этом этапе следует ожидать дальнейших решений и выполнения действий вручную. Ведь даже если резервные копии доступны, их нужно подготовить. Например, если две разные службы обмениваются данными, их резервные копии может потребоваться изменить, чтобы обеспечить согласованность этих данных после выполнения восстановления. 
  - Часто также существует другая телеметрия или данные, получаемые от службы. Эти метаданные могут содержаться в других службах или в журналах. Эти сведения можно использовать для определения того, были ли получены и обработаны в первичной реплике вызовы, которые отсутствовали в резервной копии либо были реплицированы в эту конкретную реплику. Может потребоваться воспроизвести или добавить эти данные к резервной копии, прежде чем восстановление станет возможным.  
   - Сравнения состояния оставшейся реплики с состоянием в доступных резервных копиях. При использовании надежных коллекций Service Fabric для этого можно использовать средства и процедуры, описанные в [этой статье](service-fabric-reliable-services-backup-restore.md). Это необходимо, чтобы определить, является ли состояние в реплике достаточным, а также какие данные могут отсутствовать в резервной копии.
  - После завершения сравнения и при необходимости выполнения восстановления код службы должен вернуть значение true, если были внесены изменения состояния. Если реплика определяется как лучшая доступная копия состояния и изменения не вносятся, возвращается значение false. Значение true указывает, что все _остальные_ оставшиеся реплики теперь не согласованы с этой репликой. Они будут удалены и пересозданы из этой реплики. Значение false указывает, что не было внесено никаких изменений состояния, поэтому другие реплики можно оставить. 

Очень важно, чтобы разработчики службы смоделировали потенциальную потерю данных и сценарии сбоев, прежде чем развертывать службы в рабочей среде. Чтобы избежать возможной потери данных, важно периодически выполнять [резервное копирование состояния](service-fabric-reliable-services-backup-restore.md) служб с отслеживанием состояния в любое геоизбыточное хранилище. Также необходимо убедиться, что имеется возможность его восстановить. Поскольку резервные копии различных служб создаются в разное время, необходимо убедиться, что после восстановления службы имеют согласованное представление друг о друге. Например, рассмотрим ситуацию, где одна служба создает число и сохраняет его, а затем отправляет его в другую службу, которая также его сохраняет. После восстановления может выясниться, что вторая служба сохранила номер, а первая нет, так как ее резервное копирование не предусматривает этой операции.

Если оставшихся реплик недостаточно для восстановления в случае сценария потери данных и невозможно восстановить состояние службы из телеметрии или выходных данных, частота резервного копирования определяет лучшую целевую точку восстановления (RPO). Service Fabric предоставляет множество средств для тестирования различных сценариев сбоя, включая постоянный кворум и потерю данных, для которой требуется восстановление из резервной копии. Эти сценарии включены как часть средств тестирования Service Fabric, управляемых службой анализа сбоев. Дополнительные сведения об этих средствах и шаблонах см. [здесь](service-fabric-testability-overview.md). 

> [!NOTE]
> Системные службы также могут испытывать потерю кворума, причем серьезность влияния зависит от конкретной службы. Например, потеря кворума в службе именования влияет на разрешение имен, тогда как потеря кворума в службе диспетчера отработки отказа блокирует создание службы и переход на другой ресурс. Хотя системные службы Service Fabric следуют тому же шаблону, что и службы для управления состоянием, не рекомендуется пытаться переместить их за пределы потери кворума в состояние потенциальной потери данных. Вместо этого рекомендуется [обратиться за помощью](service-fabric-support.md) в поиске решения, применимого конкретно к вашей ситуации.  Обычно достаточно дождаться возврата реплик в работоспособное состояние.
>

## <a name="availability-of-the-service-fabric-cluster"></a>Доступность кластера Service Fabric
Как правило, сам по себе кластер Service Fabric является высоко распределенной средой без единичных точек отказа. Сбой одного из узлов не приведет к проблемам доступности или надежности кластера, в основном в связи с тем, что системные службы Service Fabric следуют тем же правилам: всегда выполняется не менее трех реплик по умолчанию и эти системные службы без отслеживания состояния выполняются на всех узлах. Базовые сетевые подключения Service Fabric и уровни определения сбоев являются полностью распределенными. Большинство системных служб могут быть перестроены на основе метаданных в кластере или повторно синхронизировать свое состояние из других мест. Доступность кластера может быть нарушена, если системные службы окажутся в ситуации потери кворума, как описано выше. В таких случаях вы не сможете выполнять определенные операции в кластере, такие как запуск обновлений или развертывание новых служб, но сам кластер по-прежнему будет работать. В этих условиях уже запущенные службы продолжают работу, если только им не требуется выполнять операции записи в системные службы, чтобы продолжать работу. Например, если диспетчер отработки отказов теряет кворум, все службы продолжат работу, но те службы, работа которых завершилась сбоем, не смогут автоматически перезапуститься, поскольку для этого требуется участие диспетчера отработки отказов. 

### <a name="failures-of-a-datacenter-or-azure-region"></a>Сбои в центре обработки данных или регионе Azure
В редких случаях физические центры обработки данных могут стать временно недоступными из-за отключения питания или потери сетевого подключения. В этих случаях кластеры Service Fabric, а также службы в таких центрах обработки данных или в регионе Azure будут недоступны. Тем не менее _данные сохраняются_. Просмотреть обновления сбоев для кластеров, запущенных в Azure, можно на [странице состояния Azure][azure-status-dashboard]. В крайне маловероятном случае полного или частичного разрушения физического центра обработки данных будут потеряны все размещенные в нем кластеры Service Fabric вместе со службами. Сюда входят все состояния, для которых не были созданы резервные копии за пределами этого центра обработки данных или региона.

Есть две разные стратегии предотвращения постоянного или неустранимого сбоя в одном центре обработки данных или регионе. 

1. Запустите отдельные кластеры Service Fabric в нескольких регионах и используйте механизм для отработки отказа и восстановления размещения между этими средами. Для такой мультикластерной модели типа "активный — активный" или "активный — пассивный" требуется дополнительный код для управления и операций. Также требуется координация резервных копий служб в одном центре обработки данных или регионе, чтобы они были доступны в других центрах обработки данных или регионах в случае сбоя. 
2. Запустите кластер Service Fabric, охватывающий несколько центров обработки данных или регионов. Минимальные требования для такой конфигурации — три центра обработки данных или региона. Но рекомендуется пять. Это предполагает более сложную топологию кластера. Однако преимуществом такой модели является тот факт, что сбой в одном центре обработки данных или регионе преобразуется из аварии в обычный сбой. Эти ошибки можно обрабатывать с помощью механизмов, которые применимы для кластеров в одном регионе. Домены сбоя, домены обновления и правила размещения Service Fabric гарантируют, что нагрузки распределяются таким образом, чтобы выдерживать обычные сбои. Дополнительные сведения о политиках, которые помогают работать службам в таком типе кластеров, см. в статье [Политики размещения для служб Service Fabric](service-fabric-cluster-resource-manager-advanced-placement-rules-placement-policies.md)

### <a name="random-failures-leading-to-cluster-failures"></a>Случайные сбои, вызывающие сбои кластеров
Service Fabric реализует концепцию начальных узлов. Это узлы, которые поддерживают доступность базового кластера. Эти узлы гарантируют работу кластера, арендуя другие узлы и выступая в роли прерывателя связи во время определенных сбоев сети. Если случайные сбои выводят из строя большинство начальных узлов в кластере и они не возобновляют работу, кластер автоматически завершает работу. В Azure начальные узлы управляются автоматически: они распределяются по доступным доменам сбоя и обновления, и если один начальный узел удаляется из кластера, вместо него будет создан новый. 

В автономных кластерах Service Fabric и в Azure первичный узел управляет начальными узлами. При определении типа первичного узла Service Fabric автоматически использует преимущество количества предоставленных узлов и создает до 9 начальных узлов и 9 реплик каждой системной службы. Если большинство этих реплик системных служб одновременно выйдут из строя в результате ряда случайных сбоев, системные службы потеряют кворум, как описано выше. Если большинство начальных узлов выйдут из строя, работа кластера будет прекращена.

## <a name="next-steps"></a>Дополнительная информация
- Узнайте, как моделировать различные сбои с помощью [платформы тестирования](service-fabric-testability-overview.md)
- Ознакомьтесь с другими материалами по аварийному восстановлению и обеспечению высокой доступности. Корпорация Майкрософт опубликовала множество руководств по этим темам. Несмотря на то, что некоторые из этих документов посвящены конкретным методам для других продуктов, они содержат целый ряд общих практических рекомендаций, которые можно применять в контексте Service Fabric.
  - [Контрольный список для обеспечения доступности](../best-practices-availability-checklist.md)
  - [Отработка аварийного восстановления](../sql-database/sql-database-disaster-recovery-drills.md)
  - [Аварийное восстановление и высокий уровень доступности для приложений Azure][dr-ha-guide]
- Узнайте о [вариантах поддержки Service Fabric](service-fabric-support.md).

<!-- External links -->

[repair-partition-ps]: https://msdn.microsoft.com/library/mt163522.aspx
[azure-status-dashboard]:https://azure.microsoft.com/status/
[azure-regions]: https://azure.microsoft.com/regions/
[dr-ha-guide]: https://msdn.microsoft.com/library/azure/dn251004.aspx


<!-- Images -->

[sfx-cluster-map]: ./media/service-fabric-disaster-recovery/sfx-clustermap.png
