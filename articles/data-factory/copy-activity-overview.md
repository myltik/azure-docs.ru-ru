---
title: Действие копирования в фабрике данных Azure | Документация Майкрософт
description: Узнайте о действии копирования в фабрике данных Azure, которое можно использовать для копирования данных из поддерживаемых источников в поддерживаемые приемники.
services: data-factory
documentationcenter: ''
author: linda33wj
manager: craigg
ms.reviewer: douglasl
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/01/2018
ms.author: jingwang
ms.openlocfilehash: 8ae1402b6821d1b42fa8f2bf9c2f6453a5ce7109
ms.sourcegitcommit: ca05dd10784c0651da12c4d58fb9ad40fdcd9b10
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 05/03/2018
---
# <a name="copy-activity-in-azure-data-factory"></a>Действие копирования в фабрике данных Azure

## <a name="overview"></a>Обзор

> [!div class="op_single_selector" title1="Select the version of Data Factory service you are using:"]
> * [Версия 1 — общедоступная](v1/data-factory-data-movement-activities.md)
> * [Версия 2 — предварительная](copy-activity-overview.md)

В фабрике данных Azure с помощью действия копирования можно копировать данные между локальными и облачными хранилищами данных. После копирования данные можно подвергнуть дальнейшему преобразованию и анализу. С помощью действия копирования можно также публиковать результаты преобразования и анализа для бизнес-аналитики и использования приложения.

![Роль действия копирования](media/copy-activity-overview/copy-activity.png)

> [!NOTE]
> Эта статья относится к версии 2 фабрики данных, которая в настоящее время доступна в предварительной версии. Если используется служба фабрики данных версии 1, которая является общедоступной версией, ознакомьтесь со статьей [Move data by using Copy Activity](v1/data-factory-data-movement-activities.md) (Перемещение данных с помощью действия копирования).

Действие копирования выполняется в [интегрированной среде выполнения](concepts-integration-runtime.md). В различных сценариях копирования данных могут использоваться разные версии интегрированной среды выполнения:

* При копировании данных между общедоступными хранилищами данных действие копирования может выполняться **интегрированной средой выполнения Azure**, которая является безопасной, надежной, масштабируемой и [глобально доступной](concepts-integration-runtime.md#integration-runtime-location).
* При копировании данных в хранилища данных, расположенные локально или в сети с управлением доступом (например, виртуальная сеть Azure), и из них необходимо настроить **локальную интегрированную среду выполнения** для расширения возможностей копирования данных.

Интегрированную среду выполнения следует связать с каждым источником и приемником данных. Дополнительные сведения о том, как действие копирования определяет, какую IR использовать, см. в [этом разделе](concepts-integration-runtime.md#determining-which-ir-to-use).

При копировании данных из источника в приемник действие копирования выполняет такие действия: Служба, на основе которой реализовано действие копирования, выполняет следующее:

1. Считывает данные из источника данных.
2. Выполняет сериализацию или десериализацию, сжатие или распаковку, сопоставление столбцов и т. д. Она выполняет эти операции в соответствии с конфигурациями наборов входных данных, наборов выходных данных и действия копирования.
3. Записывает данные в приемник или целевое хранилище данных.

![Общие сведения о действии копирования](media/copy-activity-overview/copy-activity-overview.png)

## <a name="supported-data-stores-and-formats"></a>Поддерживаемые хранилища данных и форматы

[!INCLUDE [data-factory-v2-supported-data-stores](../../includes/data-factory-v2-supported-data-stores.md)]

### <a name="supported-file-formats"></a>Поддерживаемые форматы файлов

Действие копирования можно использовать для **копирования файлов "как есть"** между двумя хранилищами данных на основе файлов. При этом данные эффективно копируются без какой-либо сериализации или десериализации.

Кроме того, действие копирования поддерживает считывание и запись файлов в таких форматах: **текстовый формат, JSON, Avro, ORC и Parquet**. Поддерживаются кодеки сжатия **GZip, Deflate, BZip2 и ZipDeflate**. Дополнительные сведения см. в разделе [Форматы файлов и сжатия данных, поддерживаемые фабрикой данных Azure](supported-file-formats-and-compression-codecs.md).

Например, можно выполнять следующие действия копирования:

* копирование данных с локального сервера SQL Server и запись в Azure Data Lake Store в формате ORC;
* копирование файлов в текстовом формате (CSV) из локальной файловой системы и запись в большой двоичный объект Azure в формате AVRO;
* копирование ZIP-файлов из локальной файловой системы, их распаковка и размещение в Azure Data Lake Store.
* копирование данных в сжатом с помощью GZip текстовом формате (CSV) из большого двоичного объекта Azure и запись в базу данных SQL Azure;

## <a name="supported-regions"></a>Поддерживаемые регионы

Служба, управляющая действием копирования, является общедоступной в регионах и географических областях, перечисленных в разделе [Расположение среды выполнения интеграции](concepts-integration-runtime.md#integration-runtime-location). Глобально доступная топология обеспечивает эффективное перемещение данных, обычно позволяя избежать "прыжков" по разным регионам. Дополнительные сведения о доступности фабрики данных и перемещения данных в регионе см. на [этой странице](https://azure.microsoft.com/regions/#services).

## <a name="configuration"></a>Параметр Configuration

Чтобы использовать действие копирования в фабрике данных Azure, необходимо:

1. **Создать связанные службы для источника и приемника данных.** Дополнительные сведения о настройке и поддерживаемых свойствах см. в разделе "Свойства связанных служб" статьи о соединителях. Список поддерживаемых соединителей приведен в разделе [Поддерживаемые хранилища данных и форматы](#supported-data-stores-and-formats).
2. **Создать наборы данных для источника и приемника.** Дополнительные сведения о настройке и поддерживаемых свойствах см. в разделе "Свойства наборов данных" статьи о соединителях источника и приемника.
3. **Создать конвейер с действием копирования.** В следующем разделе приведен пример.  

### <a name="syntax"></a>Синтаксис

Следующий шаблон действия копирования содержит исчерпывающий список поддерживаемых свойств. Выберите свойства для своего сценария.

```json
"activities":[
    {
        "name": "CopyActivityTemplate",
        "type": "Copy",
        "inputs": [
            {
                "referenceName": "<source dataset name>",
                "type": "DatasetReference"
            }
        ],
        "outputs": [
            {
                "referenceName": "<sink dataset name>",
                "type": "DatasetReference"
            }
        ],
        "typeProperties": {
            "source": {
                "type": "<source type>",
                <properties>
            },
            "sink": {
                "type": "<sink type>"
                <properties>
            },
            "translator":
            {
                "type": "TabularTranslator",
                "columnMappings": "<column mapping>"
            },
            "cloudDataMovementUnits": <number>,
            "parallelCopies": <number>,
            "enableStaging": true/false,
            "stagingSettings": {
                <properties>
            },
            "enableSkipIncompatibleRow": true/false,
            "redirectIncompatibleRowSettings": {
                <properties>
            }
        }
    }
]
```

### <a name="syntax-details"></a>Сведения о синтаксисе

| Свойство | ОПИСАНИЕ | Обязательно |
|:--- |:--- |:--- |
| Тип | Свойство type действия копирования должно иметь значение **Copy**. | Yes |
| inputs | Укажите созданный набор данных, который указывает на исходные данные. Действие копирования поддерживает один экземпляр входных данных. | Yes |
| outputs | Укажите созданный набор данных, который указывает на данные приемника. Действие копирования поддерживает один экземпляр выходных данных. | Yes |
| typeProperties | Группа свойств для настройки действия копирования. | Yes |
| источник | Укажите тип источника копирования и соответствующие свойства, определяющие конкретный сценарий извлечения данных.<br/><br/>Дополнительные сведения см. в разделе "Свойства действия копирования" в статье о соединителях, приведенных в разделе [Поддерживаемые хранилища данных и форматы](#supported-data-stores-and-formats). | Yes |
| sink | Укажите тип приемника копирования и соответствующие свойства, определяющие конкретный сценарий записи данных.<br/><br/>Дополнительные сведения см. в разделе "Свойства действия копирования" в статье о соединителях, приведенных в разделе [Поддерживаемые хранилища данных и форматы](#supported-data-stores-and-formats). | Yes |
| translator | Укажите явные сопоставления столбцов от источника к приемнику. Применяется, когда действие копирования по умолчанию не может удовлетворить ваши потребности.<br/><br/>Дополнительные сведения см. в статье [Schema mapping in copy activity](copy-activity-schema-and-type-mapping.md) (Сопоставление диаграммы в действии копирования). | Нет  |
| CloudDataMovementUnits | Укажите число единиц перемещения для [интегрированной среды выполнения Azure](concepts-integration-runtime.md), обеспечивающей копирование данных.<br/><br/>Дополнительные сведения см. в статье [Copy Activity performance and tuning guide](copy-activity-performance.md) (Производительность действия копирования и руководство по настройке). | Нет  |
| parallelCopies | Укажите показатель параллелизма, который должно использовать действие копирования при считывании данных из источника и записи данных в приемник.<br/><br/>Дополнительные сведения см. в разделе [Parallel copy](copy-activity-performance.md#parallel-copy) (Параллельное копирование). | Нет  |
| enableStaging<br/>stagingSettings | Позволяет разместить временные данные в хранилище BLOB-объектов вместо копирования данных из источника в приемник напрямую.<br/><br/>Дополнительные сведения о полезных сценариях и конфигурации см. в разделе [Staged copy](copy-activity-performance.md#staged-copy) (Промежуточное копирование). | Нет  |
| enableSkipIncompatibleRow<br/>redirectIncompatibleRowSettings| Позволяет выбрать способ обработки несовместимых строк при копировании данных из источника в приемник.<br/><br/>Дополнительные сведения см. в статье [Fault tolerance of copy activity in Azure Data Factory](copy-activity-fault-tolerance.md) (Отказоустойчивость действия копирования в фабрике данных Azure). | Нет  |

## <a name="monitoring"></a>Мониторинг

Вы можете отслеживать выполнение действия копирования в пользовательском интерфейсе "Создание и мониторинг" службы "Фабрика данных Azure" или при помощи программных средств. Затем можно сравнить производительность и конфигурацию вашего сценария с [базовыми показателями производительности](copy-activity-performance.md#performance-reference) для действия копирования, полученными в результате внутреннего тестирования.

### <a name="monitor-visually"></a>Визуальный мониторинг

Чтобы визуально отслеживать выполнение действия копирования, в фабрике данных последовательно выберите **Создание и мониторинг** -> **Вкладка монитора**. Здесь отображается список запусков конвейера, для каждого из которых в столбце **Действия** предоставлена ссылка View Activity Runs (Просмотр выполнений действий). 

![Мониторинг выполнений конвейера](./media/load-data-into-azure-data-lake-store/monitor-pipeline-runs.png)

Щелкните ее, чтобы отобразился список действий для конкретного запуска конвейера. В столбце **Действия** есть ссылки на входные и выходные данные, ошибки (если действие копирования завершилось сбоем) и подробные сведения о действии копирования.

![Мониторинг выполнений действий](./media/load-data-into-azure-data-lake-store/monitor-activity-runs.png)

Щелкните ссылку **Сведения** в столбце **Действия**, чтобы просмотреть сведения о выполнении и о производительности действия копирования. Для каждого сценария копирования отображаются такие сведения, как объем данных, количество строк и (или) файлов, скопированных из источника в приемник, пропускная способность, полный список процессов с указанием времени выполнения, а также выбранная конфигурация.

**Пример: копирование из Amazon S3 в Azure Data Lake Store**
![Сведения о выполнении действия](./media/copy-activity-overview/monitor-activity-run-details-adls.png)

**Пример: копирование из службы "База данных SQL Azure" в хранилище данных SQL Azure с применением промежуточного копирования**
![Сведения о выполнении действия](./media/copy-activity-overview/monitor-activity-run-details-sql-dw.png)

### <a name="monitor-programmatically"></a>Мониторинг при помощи программных средств

Сведения о выполнении действия копирования и характеристики производительности можно получить в разделе "Выходные данные" из результата выполнения действия копирования. Ниже приведен полный список параметров, из которых будут отображаться только применимые к вашему сценарию копирования. Дополнительные сведения о мониторинге выполняемого действия см. в [этом разделе](quickstart-create-data-factory-dot-net.md#monitor-a-pipeline-run).

| Имя свойства  | ОПИСАНИЕ | Единица измерения |
|:--- |:--- |:--- |
| dataRead | Размер данных, считанных из источника. | Значение Int64 в **байтах** |
| dataWritten | Размер данных, записанных в приемник. | Значение Int64 в **байтах** |
| filesRead | Число файлов, скопированных из хранилища файлов. | Значение Int64 (не единица измерения) |
| filesWritten | Число файлов, скопированных в хранилище файлов. | Значение Int64 (не единица измерения) |
| rowsCopied | Число скопированных строк (неприменимо для двоичного копирования). | Значение Int64 (не единица измерения) |
| rowsSkipped | Число пропущенных несовместимых строк. Эту возможность можно включить, задав свойству enableSkipIncompatibleRow значение true. | Значение Int64 (не единица измерения) |
| throughput | Отношение, с которым передаются данные. | Число с плавающей запятой (**КБ/с**) |
| copyDuration | Длительность копирования. | Значение Int32 в секундах |
| sqlDwPolyBase | Если при копировании данных в хранилище данных SQL используется PolyBase. | Логическое |
| redshiftUnload | Если при копировании данных из Redshift используется команда UNLOAD. | Логическое |
| hdfsDistcp | Если при копировании данных из HDFS используется DistCp. | Логическое |
| effectiveIntegrationRuntime | Показывает, какие среды Integration Runtime используются для выполнения действия, в формате `<IR name> (<region if it's Azure IR>)`. | Текст (string) |
| usedCloudDataMovementUnits | Эффективные единицы перемещения облачных данных во время копирования. | Значение Int32 |
| usedParallelCopies | Использованное количество параллельных процессов копирования. | Значение Int32|
| redirectRowPath | Путь к журналу пропущенных несовместимых строк в хранилище BLOB-объектов, который настраивается в разделе redirectIncompatibleRowSettings. См. пример ниже. | Текст (string) |
| executionDetails | Дополнительные сведения о стадиях, которые проходит действие копирования, с указанием всех шагов, длительности, конфигураций и т. п. Не рекомендуем применять синтаксический анализ для этого раздела, поскольку его формат может изменяться. | Массив, |

```json
"output": {
    "dataRead": 107280845500,
    "dataWritten": 107280845500,
    "filesRead": 10,
    "filesWritten": 10,
    "copyDuration": 224,
    "throughput": 467707.344,
    "errors": [],
    "effectiveIntegrationRuntime": "DefaultIntegrationRuntime (East US 2)",
    "usedCloudDataMovementUnits": 32,
    "usedParallelCopies": 8,
    "executionDetails": [
        {
            "source": {
                "type": "AmazonS3"
            },
            "sink": {
                "type": "AzureDataLakeStore"
            },
            "status": "Succeeded",
            "start": "2018-01-17T15:13:00.3515165Z",
            "duration": 221,
            "usedCloudDataMovementUnits": 32,
            "usedParallelCopies": 8,
            "detailedDurations": {
                "queuingDuration": 2,
                "transferDuration": 219
            }
        }
    ]
}
```

## <a name="schema-and-data-type-mapping"></a>Сопоставление типов данных и схемы

Дополнительные сведения о том, как действие копирования сопоставляет данные источника в приемнике, см. в статье [Schema mapping in copy activity](copy-activity-schema-and-type-mapping.md) (Сопоставление схемы в действии копирования).

## <a name="fault-tolerance"></a>Отказоустойчивость

По умолчанию действие копирования останавливает копирование данных и сообщает о сбое, когда встречает несовместимые данные между источником и приемником. Для успешного копирования данных можно явно настроить пропуск и запись несовместимых строк и копировать только совместимые данные. Дополнительные сведения см. в разделе [Отказоустойчивость действий копирования](copy-activity-fault-tolerance.md).

## <a name="performance-and-tuning"></a>Производительность и настройка

Сведения о ключевых факторах, влияющих на производительность перемещения данных (действие копирования) в фабрике данных Azure см. в [руководстве по настройке производительности действия копирования](copy-activity-performance.md). В ней также приведены сведения о производительности, наблюдаемой во время внутреннего тестирования, и рассматриваются различные способы оптимизировать производительность действия копирования.

## <a name="incremental-copy"></a>Добавочное копирование 
Фабрика данных версии 2 поддерживает режимы добавочного копирования изменившихся данных из исходного хранилища данных в целевое. Дополнительные сведения см. в [руководстве по добавочному копированию данных](tutorial-incremental-copy-overview.md). 

## <a name="read-and-write-partitioned-data"></a>Чтение и запись секционированных данных
В версии 1 фабрика данных Azure поддерживала чтение или запись секционированных данных с использованием системных переменных SliceStart/SliceEnd/WindowStart/WindowEnd. В версии 2 это достигается с помощью параметра конвейера и времени начала или запланированного времени запуска триггера в качестве значения параметра. Дополнительные сведения см. в статье о [чтении и записи секционированных данных](how-to-read-write-partitioned-data.md).

## <a name="next-steps"></a>Дополнительная информация
Ознакомьтесь со следующими руководствами и примерами:

- [Create a data factory and pipeline using .NET SDK](quickstart-create-data-factory-dot-net.md) (Создание фабрики данных и конвейера с помощью пакета SDK для .NET)
- [Copy data from Azure Blob to Azure SQL Database using Azure Data Factory](tutorial-copy-data-dot-net.md) (Копирование данных из большого двоичного объекта Azure в Базу данных SQL Azure с помощью фабрики данных Azure)
- [Copy data between on-premises and cloud](tutorial-hybrid-copy-powershell.md) (Копирование данных между локальным расположением и облаком)
