---
title: Планирование и исполнение с использованием фабрики данных | Документация Майкрософт
description: Сведения об аспектах планирования и исполнения в модели приложений фабрики данных Azure.
services: data-factory
documentationcenter: ''
author: sharonlo101
manager: craigg
ms.assetid: 088a83df-4d1b-4ac1-afb3-0787a9bd1ca5
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: conceptual
ms.date: 01/10/2018
ms.author: shlo
robots: noindex
ms.openlocfilehash: f18d6817d3a04ad787888ba058e1251303e575a7
ms.sourcegitcommit: 266fe4c2216c0420e415d733cd3abbf94994533d
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/01/2018
ms.locfileid: "34622413"
---
# <a name="data-factory-scheduling-and-execution"></a>Планирование и исполнение с использованием фабрики данных
> [!NOTE]
> Статья относится к версии 1 фабрики данных, которая является общедоступной версией. Если вы используете версию 2 службы фабрики данных, которая находится на этапе предварительной версии, ознакомьтесь со статьей о [выполнении конвейеров и триггерах](../concepts-pipeline-execution-triggers.md).

Здесь объясняются аспекты планирования и исполнения в модели приложений фабрики данных Azure. В этой статье предполагается, что вам известны основные понятия модели приложений фабрики данных: действия, конвейеры, связанные службы и наборы данных. С основными понятиями фабрики данных Azure можно ознакомиться в следующих статьях:

* [Введение в службу фабрики данных](data-factory-introduction.md)
* [Конвейеры](data-factory-create-pipelines.md)
* [Наборы данных](data-factory-create-datasets.md) 

## <a name="start-and-end-times-of-pipeline"></a>Время начала и окончания конвейера
Конвейер работает только в период активности, то есть между временем **начала** и **окончания**. Он не работает до времени начала и после времени окончания. Если конвейер приостановлен, он не будет работать независимо от значений времени начала и окончания. Запустить конвейер можно только в том случае, если он не находится в приостановленном состоянии. Эти параметры (начало, окончание, остановка) можно найти в определении конвейера: 

```json
"start": "2017-04-01T08:00:00Z",
"end": "2017-04-01T11:00:00Z"
"isPaused": false
```

Дополнительные сведения об этих свойствах см. в статье [Конвейеры и действия в фабрике данных Azure](data-factory-create-pipelines.md). 


## <a name="specify-schedule-for-an-activity"></a>Указание расписания для действия
Выполняется не сам конвейер, а действия в нем. Однако это происходит в общем контексте конвейера. С помощью раздела **scheduler** в файле действия JSON можно указать регулярное расписание данного действия. Например, можно запланировать выполнение действия каждый час следующим образом:  

```json
"scheduler": {
    "frequency": "Hour",
    "interval": 1
},
```

Как показано на схеме, при задании расписания для действия создается последовательность "переворачивающихся" окон в пределах времени начала и окончания конвейера. "Переворачивающиеся" окна — это ряд не перекрывающихся и не соприкасающихся интервалов фиксированного размера. Эти логические стыкующиеся окна для действия называются **окнами действия**.

![Пример планировщика действий](media/data-factory-scheduling-and-execution/scheduler-example.png)

Свойство **scheduler** для действия является необязательным. Если это свойство указывается, оно должно соответствовать периодичности, заданной в определении выходного набора данных для действия. Сейчас на основе этого набора настраивается расписание. Поэтому вы должны создать выходной набор данных, даже если действие не выдает выходные данные. 

## <a name="specify-schedule-for-a-dataset"></a>Указание расписания для набора данных
У каждого действия в конвейере фабрики данных может быть несколько входных **наборов данных** или же ни одного, и каждое действие может производить один или несколько выходных наборов данных. Для действия можно указать периодичность, с которой поступают входные данные или выводятся выходные данные, используя раздел **availability** в определении набора данных. 

**frequency** в разделе **availability** указывает единицу времени. Допустимы следующие значения частоты: Minute, Hour, Day, Week и Month. Свойство **interval** в разделе availability задает множитель для частоты. Например, если для параметра frequency задано значение Day, а для interval — 1 для выходного набора данных, выходные данные будут создаваться ежедневно. Если вы выбрали значение Minute для параметра frequency, мы рекомендуем задать для параметра interval значение не менее 15. 

В следующем примере входные и выходные данные поступают каждый час (`"frequency": "Hour", "interval": 1`). 

**Входной набор данных:** 

```json
{
    "name": "AzureSqlInput",
    "properties": {
        "published": false,
        "type": "AzureSqlTable",
        "linkedServiceName": "AzureSqlLinkedService",
        "typeProperties": {
            "tableName": "MyTable"
        },
        "availability": {
            "frequency": "Hour",
            "interval": 1
        },
        "external": true,
        "policy": {}
    }
}
```


**Выходной набор данных**

```json
{
    "name": "AzureBlobOutput",
    "properties": {
        "published": false,
        "type": "AzureBlob",
        "linkedServiceName": "StorageLinkedService",
        "typeProperties": {
            "folderPath": "mypath/{Year}/{Month}/{Day}/{Hour}",
            "format": {
                "type": "TextFormat"
            },
            "partitionedBy": [
                { "name": "Year", "value": { "type": "DateTime", "date": "SliceStart", "format": "yyyy" } },
                { "name": "Month", "value": { "type": "DateTime", "date": "SliceStart", "format": "MM" } },
                { "name": "Day", "value": { "type": "DateTime", "date": "SliceStart", "format": "dd" } },
                { "name": "Hour", "value": { "type": "DateTime", "date": "SliceStart", "format": "HH" }}
            ]
        },
        "availability": {
            "frequency": "Hour",
            "interval": 1
        }
    }
}
```

Сейчас **на основе этого набора настраивается расписание.** Другими словами, расписание, указанное для выходного набора данных, используется для запуска действия во время выполнения. Поэтому вы должны создать выходной набор данных, даже если действие не выдает выходные данные. Если действие не принимает никаких входных данных, входной набор данных можно не создавать. 

В следующем определении конвейера свойство **scheduler** используется, чтобы задать расписание для действия. Это необязательное свойство. Сейчас расписание для действия должно соответствовать расписанию, указанному для выходного набора данных.
 
```json
{
    "name": "SamplePipeline",
    "properties": {
        "description": "copy activity",
        "activities": [
            {
                "type": "Copy",
                "name": "AzureSQLtoBlob",
                "description": "copy activity",
                "typeProperties": {
                    "source": {
                        "type": "SqlSource",
                        "sqlReaderQuery": "$$Text.Format('select * from MyTable where timestampcolumn >= \\'{0:yyyy-MM-dd HH:mm}\\' AND timestampcolumn < \\'{1:yyyy-MM-dd HH:mm}\\'', WindowStart, WindowEnd)"
                    },
                    "sink": {
                        "type": "BlobSink",
                        "writeBatchSize": 100000,
                        "writeBatchTimeout": "00:05:00"
                    }
                },
                "inputs": [
                    {
                        "name": "AzureSQLInput"
                    }
                ],
                "outputs": [
                    {
                        "name": "AzureBlobOutput"
                    }
                ],
                "scheduler": {
                    "frequency": "Hour",
                    "interval": 1
                }
            }
        ],
        "start": "2017-04-01T08:00:00Z",
        "end": "2017-04-01T11:00:00Z"
    }
}
```

В этом примере действие выполняется каждый час между временем начала и окончания конвейера. Выходные данные создаются ежечасно в рамках трех часовых окон (с 8:00 до 9:00, с 9:00 до 10:00 и с 10:00 до 11:00). 

Каждая единица данных, потребляемых или создаваемых запуском действия, называется **срезом данных**. На следующей схеме показан пример действия с входным и выходным наборами данных. 

![Планировщик доступности](./media/data-factory-scheduling-and-execution/availability-scheduler.png)

На схеме показаны почасовые срезы данных для входного и выходного наборов данных. На схеме показаны три входных среза, готовых к обработке. Выполняемое действие 11–10 AM выдает выходной срез 10–11 AM. 

К интервалу времени, связанному с текущим срезом, можно получить доступ в наборе данных JSON с помощью переменных [SliceStart](data-factory-functions-variables.md#data-factory-system-variables) и [SliceEnd](data-factory-functions-variables.md#data-factory-system-variables). Аналогичным образом можно получить доступ к интервалу времени, связанному с окном действий, с помощью переменных WindowStart и WindowEnd. Расписание действия должно соответствовать расписанию выходного набора данных для действия. Таким образом значения SliceStart, SliceEnd, WindowStart и WindowEnd совпадают соответственно. Дополнительные сведения об этих переменных см. в статье [Фабрика данных Azure — функции и системные переменные](data-factory-functions-variables.md#data-factory-system-variables).  

Эти переменные можно использовать для различных целей в действии JSON. Например, для выбора данных из входных и выходных наборов данных, соответствующих временным рядам (к примеру, с 8:00 до 9:00). В примере значения **WindowStart** и **WindowEnd** используются, чтобы выбрать соответствующие данные для выполнения действия и скопировать их в большой двоичный объект с соответствующим значением **folderPath**. Значение **folderPath** параметризовано таким образом, чтобы каждый час использовалась отдельная папка.  

В предыдущем примере используется то же расписание (ежечасно), указанное для входных и выходных наборов данных. Если входной набор данных для действия выводится с другой частотой, скажем, каждые 15 минут, действие, создающее этот выходной набор данных, по-прежнему выполняется раз в час, так как на основе этого набора настраивается расписание действия. Дополнительные сведения см. в разделе [Моделирование наборов данных с разной частотой](#model-datasets-with-different-frequencies).

## <a name="dataset-availability-and-policies"></a>Доступность набора данных и политики
Вы узнали об использовании свойств frequency и interval в разделе availability определения набора данных. Есть и другие свойства, влияющие на планирование и выполнение действия. 

### <a name="dataset-availability"></a>Доступность набора данных 
В таблице ниже перечислены свойства, которые можно использовать в разделе **availability**.

| Свойство | ОПИСАНИЕ | Обязательно | значение по умолчанию |
| --- | --- | --- | --- |
| frequency |Указывает единицу времени, которая определяет частоту создания среза данных.<br/><br/><b>Поддерживаемые значения</b>: Minute, Hour, Day, Week, Month. |Yes |Нет данных |
| interval |Задает множитель для частоты.<br/><br/>"Интервал х частоты" определяет частоту создания срезов.<br/><br/>Если нужно, чтобы срез в наборе данных создавался каждый час, задайте для параметра <b>frequency</b> значение <b>Hour</b>, а для параметра <b>interval</b> — значение <b>1</b>.<br/><br/><b>Примечание.</b> Если вы выбрали значение Minute для параметра Frequency, рекомендуем, чтобы интервал длился не менее 15 минут. |Yes |Нет данных |
| style |Указывает, когда выполняется срез: в начале или в конце интервала.<ul><li>StartOfInterval</li><li>EndOfInterval</li></ul><br/><br/>Если для Frequency задано значение Month, а для Style — EndOfInterval, срез данных будет создаваться в последний день месяца. Если для Style задано значение StartOfInterval, срез создается в первый день месяца.<br/><br/>Если для frequency задано значение Day, а для style — EndOfInterval, срез данных будет создаваться в последний час дня.<br/><br/>Если для Frequency задано значение Hour, а для Style — EndOfInterval, срез создается в конце часа. Например, для периода с 13:00 до 14:00 срез создается в 14:00. |Нет  |EndOfInterval |
| anchorDateTime |Определяет момент времени, на основе которого планировщик вычисляет границы среза набора данных. <br/><br/><b>Примечание</b>. Если параметр AnchorDateTime содержит элементы с большей степенью детализации, чем значение параметра frequency, эти элементы игнорируются. <br/><br/>Например, если для <b>интервала</b> задано значение <b>ежечасно</b> (frequency = Hour, interval = 1), а <b>AnchorDateTime</b> содержит <b>минуты и секунды</b>, то <b>минуты и секунды</b> из параметра AnchorDateTime не учитываются. |Нет  |01/01/0001 |
| offset |Интервал времени, на который сдвигаются начало и конец всех срезов данных. <br/><br/><b>Примечание</b>. Если указаны значения для обоих параметров (anchorDateTime и offset), сдвиг вычисляется с учетом обоих значений. |Нет  |Нет данных |

### <a name="offset-example"></a>Пример смещения
По умолчанию создание ежедневных срезов (`"frequency": "Day", "interval": 1`) начинается в 00:00 (UTC). Если требуется начинать их создание 06:00 (UTC), задайте смещение, как показано в следующем фрагменте. 

```json
"availability":
{
    "frequency": "Day",
    "interval": 1,
    "offset": "06:00:00"
}
```
### <a name="anchordatetime-example"></a>Пример для anchorDateTime
В следующем примере набор данных создается каждые 23 часа. Создание первого среза начинается в момент, определяемый параметром anchorDateTime, для которого задано значение `2017-04-19T08:00:00` (время в формате UTC).

```json
"availability":    
{    
    "frequency": "Hour",        
    "interval": 23,    
    "anchorDateTime":"2017-04-19T08:00:00"    
}
```

### <a name="offsetstyle-example"></a>Пример для Offset и Style
Следующий набор данных создается ежемесячно в 3-й день каждого месяца в 08:00 (`3.08:00:00`).

```json
"availability": {
    "frequency": "Month",
    "interval": 1,
    "offset": "3.08:00:00", 
    "style": "StartOfInterval"
}
```

### <a name="dataset-policy"></a>Политика набора данных
Для набора данных можно определить политику проверки, указывающую, как данные, созданные выполнением среза, могут быть проверены на готовность к потреблению. В таких случаях после завершения выполнения среза состояние выходного среза меняется на **Ожидание** с подсостоянием **Проверка**. После проверки срезов их статус меняется на **Готово**. Если срез данных был сформирован, но не прошел проверку, запуски действий для нижестоящих срезов, зависимых от данного среза, не будут обрабатываться. [Мониторинг конвейеров фабрики данных Azure и управление ими](data-factory-monitor-manage-pipelines.md) .

Раздел **policy** в определении набора данных содержит условия, которым должен соответствовать срез данных. В таблице ниже перечислены свойства, которые можно использовать в разделе **policy**:

| Имя политики | ОПИСАНИЕ | Применяется к | Обязательно | значение по умолчанию |
| --- | --- | --- | --- | --- |
| minimumSizeMB | Проверяет, удовлетворяют ли данные в **большом двоичном объекте Azure** требованиям к минимальному размеру (в мегабайтах). |большом двоичном объекте Azure |Нет  |Нет данных |
| minimumRows | Проверяет, содержат ли данные в **базе данных SQL Azure** или **таблице Azure** минимально необходимое количество строк. |<ul><li>Базы данных SQL Azure</li><li>таблице Azure</li></ul> |Нет  |Нет данных |

#### <a name="examples"></a>Примеры
**minimumSizeMB:**

```json
"policy":

{
    "validation":
    {
        "minimumSizeMB": 10.0
    }
}
```

**minimumRows:**

```json
"policy":
{
    "validation":
    {
        "minimumRows": 100
    }
}
```

Дополнительные сведения о наборах данных см. в статье [Наборы данных в фабрике данных Azure](data-factory-create-datasets.md). 

## <a name="activity-policies"></a>Политики действий
Политики влияют на поведение во время выполнения действия, особенно при обработке среза таблицы. В следующей таблице приведено несколько примеров.

| Свойство | Допустимые значения | По умолчанию | ОПИСАНИЕ |
| --- | --- | --- | --- |
| concurrency |Целое число  <br/><br/>Максимальное значение — 10 |1 |Число одновременных выполнений действия.<br/><br/>Определяет количество параллельных выполнений одного действия для обработки разных срезов. Например, высокое значение этого свойства ускорит обработку большого набора доступных данных. |
| executionPriorityOrder |NewestFirst<br/><br/>OldestFirst |OldestFirst |Определяет порядок обработки срезов данных.<br/><br/>Предположим, есть два ожидающих обработки среза (от 16:00 и от 17:00). Если для свойства executionPriorityOrder задано значение NewestFirst, срез от 17:00 будет обработан первым. Точно так же, если для executionPriorityORder задано значение OldestFIrst, первым будет обработан срез от 16:00. |
| retry |Целое число <br/><br/>Максимальное значение — 10 |0 |Число повторных попыток обработки данных до того, как срез перейдет в состояние Failure (сбой). Выполнение действия со срезом данных повторяется указанное количество раз. Повторная попытка выполняется сразу после неудачной. |
| timeout |Интервал времени |00:00:00 |Время ожидания для действия. Пример: 00:10:00 (время ожидания — 10 минут).<br/><br/>Если значение не указано или равно 0, то время ожидания не ограничено.<br/><br/>Если время обработки среза превышает время ожидания, система отменяет текущую обработку и начинает новую. Количество повторов зависит от значения свойства retry. Когда время ожидания истекает, состояние среза меняется на TimedOut. |
| delay |Интервал времени |00:00:00 |Задайте задержку перед обработкой данных после начала выполнения среза.<br/><br/>Действие для среза данных запускается в ожидаемое время выполнения с указанной задержкой.<br/><br/>Пример: 00:10:00 (означает задержку в 10 минут). |
| longRetry |Целое число <br/><br/>Максимальное значение — 10 |1 |Количество длительных повторных попыток перед завершением сбоем выполнения среза.<br/><br/>Интервал между этими попытками задается свойством longRetryInterval. Используйте свойство longRetry, если повторные попытки необходимо выполнять с паузами. Если указаны свойства Retry и longRetry, то каждая попытка longRetry включает в себя попытки Retry, и максимальное число попыток равно Retry * longRetry.<br/><br/>Например, в политике действия указаны следующие параметры:<br/>Retry: 3<br/>longRetry: 2<br/>longRetryInterval: 01:00:00<br/><br/>Предположим, что существует только один выполняемый срез (в состоянии Waiting), и каждый раз при выполнении действия происходит сбой. Первые три попытки будут выполнены подряд. После каждой повторной попытки срез будет находиться в состоянии Retry. После выполнения первых трех попыток состоянием среза станет LongRetry.<br/><br/>Через час (значение свойства longRetryInterval) будут выполнены еще три попытки подряд. После этого состояние среза изменится на Failed и дальнейшие попытки предприниматься не будут. Поэтому всего было предпринято 6 попыток.<br/><br/>Если какое-либо выполнение завершится успешно, то состоянием среза станет Ready и дальнейшие попытки выполняться не будут.<br/><br/>Свойство longRetry можно использовать в ситуациях, когда зависимые данные поступают в неопределенное время или вся среда, в которой происходит обработка данных, непредсказуема. В таких случаях последовательные повторные попытки могут оказаться бесполезными, а выполненные через некоторое время, напротив, могут привести к желаемому результату.<br/><br/>Предупреждение. Не задавайте высокие значения для свойств longRetry и longRetryInterval. Как правило, более высокие значения приводят к появлению других системных проблем. |
| longRetryInterval |Интервал времени |00:00:00 |Период времени между длительными повторными попытками. |

Дополнительные сведения см. в статье [Конвейеры и действия в фабрике данных Azure](data-factory-create-pipelines.md). 

## <a name="parallel-processing-of-data-slices"></a>Параллельная обработка срезов данных
Для конвейера можно задать прошедшую дату начала. При этом фабрика данных автоматически вычисляет все срезы данных из прошлого (выполняет обратное заполнение) и начинает их обработку. Например, если вы создадите конвейер с датой начала 2017-04-01, а текущая дата — 2017-04-10. Если для выходного набора данных задана ежедневная периодичность, фабрика данных начнет обработку всех срезов с 2017-04-01 по 2017-04-09 сразу, так как дата начала находится в прошлом. Сейчас срез за 2017-04-10 не будет обрабатываться, так как в качестве значения свойства style в разделе availability задано EndOfInterval по умолчанию. Сначала обрабатывается самый старый срез, так как значение executionPriorityOrder по умолчанию — OldestFirst. Описание свойства style см. в разделе о [доступности набора данных](#dataset-availability). Описание раздела executionPriorityOrder см. в разделе о [политиках действий](#activity-policies). 

Вы можете настроить параллельную обработку срезов данных с обратным заполнением, задав свойство **concurrency** в разделе **policy** определения JSON действия. Это свойство определяет количество параллельных выполнений одного действия для обработки разных срезов. По умолчанию для свойства concurrency используется значение 1. Таким образом, по умолчанию одновременно обрабатывается один срез. Максимальное значение — 10. Высокое значение этого свойства ускорит обработку большого набора доступных данных в конвейере. 

## <a name="rerun-a-failed-data-slice"></a>Повторное выполнение невыполненного среза данных
При возникновении ошибки во время обработки среза данных можно выяснить причину сбоя, просмотрев колонки портала Azure или воспользовавшись приложением для мониторинга и управления. Дополнительные сведения см. в статьях [Мониторинг конвейеров фабрики данных Azure и управление ими](data-factory-monitor-manage-pipelines.md) и [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью нового приложения по мониторингу и управлению](data-factory-monitor-manage-app.md).

Рассмотрим следующий пример, в котором показаны два действия. Activity1 и Activity2. Activity1 использует срез Dataset1 и создает срез Dataset2, который используется в качестве входных данных в Activity2 для создания среза конечного набора данных.

![Срез, в котором произошла ошибка](./media/data-factory-scheduling-and-execution/failed-slice.png)

На схеме показано, что среди трех последних срезов произошла ошибка создания среза 9–10 AM для набора данных Dataset2. Фабрика данных автоматически отслеживает зависимости для набора данных временного ряда. Это задерживает запуск действия для нижестоящего среза 9-10 AM.

Средства мониторинга и управления фабриками данных позволяют детально просмотреть журналы диагностики на предмет неудачного среза, легко найти причину неполадки и устранить ее. После устранения неполадки вы можете легко инициировать запуск действия для создания среза, в котором произошла ошибка. Дополнительные сведения о повторных запусках, а также о переходах от одного состояния срезов данных к другому см. в статьях [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью портала Azure и PowerShell](data-factory-monitor-manage-pipelines.md) и [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью приложения для мониторинга и управления](data-factory-monitor-manage-app.md).

После повторного запуска среза 9–10 AM для **Dataset2**фабрика данных инициирует запуск для зависимого среза 9–10 AM в конечном наборе данных.

![Повторный запуск среза, в котором произошла ошибка](./media/data-factory-scheduling-and-execution/rerun-failed-slice.png)

## <a name="multiple-activities-in-a-pipeline"></a>Несколько действий в конвейере
Конвейер может содержать сразу несколько действий. Если в конвейере несколько действий и выходные данные одного действия не являются входными данными другого, такие действия могут выполняться параллельно, при условии, что срезы входных данных для действий готовы.

Можно объединить в цепочку два действия (выполнить одно действие вслед за другим), настроив выходной набор данных одного действия как входной набор данных другого действия. Действия могут находиться в одном конвейере или разных конвейерах. Второе действие выполняется только после успешного завершения первого.

Например, рассмотрим следующий случай, где конвейер содержит два действия:

1. Действие A1, для которого требуется внешний входной набор данных D1. Оно создает выходной набор данных D2.
2. Действие A2, для которого требуется ввод из набора данных D2. Оно создает выходной набор данных D3.

В этом сценарии действия A1 и A2 находятся в одном конвейере. Действие A1 выполняется, когда доступны внешние данные и достигнута запланированная частота доступности. Действие A2 выполняется, когда доступны запланированные срезы из D2 и достигнута запланированная частота доступности. В случае ошибки в одном из срезов в наборе данных D2 действие A2 не запустится для этого среза, пока он не станет доступным.

Представление схемы с обоими действиями в одном конвейере будет выглядеть, как на следующей схеме:

![Построение цепочки действий в одном конвейере](./media/data-factory-scheduling-and-execution/chaining-one-pipeline.png)

Как упоминалось ранее, действия могут находиться в разных конвейерах. В таком сценарии представление схемы будет выглядеть следующим образом:

![Построение цепочки действий в двух конвейерах](./media/data-factory-scheduling-and-execution/chaining-two-pipelines.png)

Пример см. в разделе о [последовательном копировании](#copy-sequentially) в приложении.

## <a name="model-datasets-with-different-frequencies"></a>Моделирование наборов данных с разной частотой
В примерах частота входных и выходных наборов данных и окон расписания действий была одинаковой. В некоторых сценариях требуется возможность создавать выходные данные с частотой, отличной от частоты одного или нескольких наборов входных данных. Фабрика данных поддерживает моделирование таких сценариев.

### <a name="sample-1-produce-a-daily-output-report-for-input-data-that-is-available-every-hour"></a>Пример 1. Создание ежедневного выходного отчета по входным данным, которые доступны каждый час
Рассмотрим сценарий, где имеются входные данные измерений датчиков, доступные каждый час в хранилище BLOB-объектов Azure. Нам требуется формировать ежедневный совокупный отчет со статистикой средних, максимальных и минимальных показателей за день с помощью [действия Hive фабрики данных](data-factory-hive-activity.md).

Смоделировать этот сценарий с помощью фабрики данных можно приведенным ниже способом.

**Входной набор данных**

Почасовые входные файлы за заданный день удаляются из папки. Для входных данных устанавливается **почасовая** доступность (frequency: Hour, interval: 1).

```json
{
  "name": "AzureBlobInput",
  "properties": {
    "type": "AzureBlob",
    "linkedServiceName": "StorageLinkedService",
    "typeProperties": {
      "folderPath": "mycontainer/myfolder/{Year}/{Month}/{Day}/",
      "partitionedBy": [
        { "name": "Year", "value": {"type": "DateTime","date": "SliceStart","format": "yyyy"}},
        { "name": "Month","value": {"type": "DateTime","date": "SliceStart","format": "MM"}},
        { "name": "Day","value": {"type": "DateTime","date": "SliceStart","format": "dd"}}
      ],
      "format": {
        "type": "TextFormat"
      }
    },
    "external": true,
    "availability": {
      "frequency": "Hour",
      "interval": 1
    }
  }
}
```
**Выходной набор данных**

Каждый день в папке создается один выходной файл за целый день. Для выходных данных устанавливается **ежедневная** доступность (frequency: Day, interval: 1).

```json
{
  "name": "AzureBlobOutput",
  "properties": {
    "type": "AzureBlob",
    "linkedServiceName": "StorageLinkedService",
    "typeProperties": {
      "folderPath": "mycontainer/myfolder/{Year}/{Month}/{Day}/",
      "partitionedBy": [
        { "name": "Year", "value": {"type": "DateTime","date": "SliceStart","format": "yyyy"}},
        { "name": "Month","value": {"type": "DateTime","date": "SliceStart","format": "MM"}},
        { "name": "Day","value": {"type": "DateTime","date": "SliceStart","format": "dd"}}
      ],
      "format": {
        "type": "TextFormat"
      }
    },
    "availability": {
      "frequency": "Day",
      "interval": 1
    }
  }
}
```

**Действие: действие Hive в конвейере**

Скрипт hive получает соответствующие сведения о *дате и времени* в качестве параметров, используя переменную **WindowStart** , как показано во фрагменте кода ниже. Эту переменную скрипт hive использует для загрузки данных за день из нужной папки и для создания выходных данных путем агрегирования.

```json
{  
    "name":"SamplePipeline",
    "properties":{  
    "start":"2015-01-01T08:00:00",
    "end":"2015-01-01T11:00:00",
    "description":"hive activity",
    "activities": [
        {
            "name": "SampleHiveActivity",
            "inputs": [
                {
                    "name": "AzureBlobInput"
                }
            ],
            "outputs": [
                {
                    "name": "AzureBlobOutput"
                }
            ],
            "linkedServiceName": "HDInsightLinkedService",
            "type": "HDInsightHive",
            "typeProperties": {
                "scriptPath": "adftutorial\\hivequery.hql",
                "scriptLinkedService": "StorageLinkedService",
                "defines": {
                    "Year": "$$Text.Format('{0:yyyy}',WindowStart)",
                    "Month": "$$Text.Format('{0:MM}',WindowStart)",
                    "Day": "$$Text.Format('{0:dd}',WindowStart)"
                }
            },
            "scheduler": {
                "frequency": "Day",
                "interval": 1
            },            
            "policy": {
                "concurrency": 1,
                "executionPriorityOrder": "OldestFirst",
                "retry": 2,
                "timeout": "01:00:00"
            }
         }
     ]
   }
}
```

На схеме ниже показан сценарий с точки зрения зависимостей данных.

![Зависимость данных](./media/data-factory-scheduling-and-execution/data-dependency.png)

Выходной срез за каждый день зависит от 24 почасовых срезов из входного набора данных. Фабрика данных автоматически вычисляет эти зависимости, определяя срезы, которые попадают в тот же период времени, что и создаваемый выходной срез. Если какой-либо из 24 входных срезов недоступен, фабрика данных дожидается готовности входного среза перед запуском ежедневного действия.

### <a name="sample-2-specify-dependency-with-expressions-and-data-factory-functions"></a>Пример 2. Указание зависимости с использованием выражений и функций фабрики данных
Рассмотрим другой сценарий. Предположим, есть действие Hive, которое обрабатывает два входных набора данных. В одном из этих наборов новые данные появляются ежедневно, а в другом — раз в неделю. Предположим, что требуется выполнить соединение двух входных наборов и выдать ежедневный выходной набор данных.

Простой подход заключается в том, чтобы фабрика данных автоматически определяла нужные входные срезы для обработки путем согласования с периодом времени выходного среза данных. Сейчас этот подход уже не работает.

Необходимо указать фабрике данных, что для каждого действия следует использовать срез данных за последнюю неделю из еженедельного входного набора данных. Чтобы реализовать это поведение, вы используете функции фабрики данных Azure, как показано в следующем фрагменте кода.

**Входной набор 1: большой двоичный объект Azure**

Первый входной набор данных представляет собой большой двоичный объект Azure, обновляемый ежедневно.

```json
{
  "name": "AzureBlobInputDaily",
  "properties": {
    "type": "AzureBlob",
    "linkedServiceName": "StorageLinkedService",
    "typeProperties": {
      "folderPath": "mycontainer/myfolder/{Year}/{Month}/{Day}/",
      "partitionedBy": [
        { "name": "Year", "value": {"type": "DateTime","date": "SliceStart","format": "yyyy"}},
        { "name": "Month","value": {"type": "DateTime","date": "SliceStart","format": "MM"}},
        { "name": "Day","value": {"type": "DateTime","date": "SliceStart","format": "dd"}}
      ],
      "format": {
        "type": "TextFormat"
      }
    },
    "external": true,
    "availability": {
      "frequency": "Day",
      "interval": 1
    }
  }
}
```

**Входной набор 2: большой двоичный объект Azure**

Второй входной набор — большой двоичный объект Azure, обновляемый еженедельно.

```json
{
  "name": "AzureBlobInputWeekly",
  "properties": {
    "type": "AzureBlob",
    "linkedServiceName": "StorageLinkedService",
    "typeProperties": {
      "folderPath": "mycontainer/myfolder/{Year}/{Month}/{Day}/",
      "partitionedBy": [
        { "name": "Year", "value": {"type": "DateTime","date": "SliceStart","format": "yyyy"}},
        { "name": "Month","value": {"type": "DateTime","date": "SliceStart","format": "MM"}},
        { "name": "Day","value": {"type": "DateTime","date": "SliceStart","format": "dd"}}
      ],
      "format": {
        "type": "TextFormat"
      }
    },
    "external": true,
    "availability": {
      "frequency": "Day",
      "interval": 7
    }
  }
}
```

**Выходной набор данных: большой двоичный объект Azure**

Каждый день в папке создается один выходной файл за целый день. Для выходных данных задается **ежедневная** доступность (frequency: Day, interval: 1).

```json
{
  "name": "AzureBlobOutputDaily",
  "properties": {
    "type": "AzureBlob",
    "linkedServiceName": "StorageLinkedService",
    "typeProperties": {
      "folderPath": "mycontainer/myfolder/{Year}/{Month}/{Day}/",
      "partitionedBy": [
        { "name": "Year", "value": {"type": "DateTime","date": "SliceStart","format": "yyyy"}},
        { "name": "Month","value": {"type": "DateTime","date": "SliceStart","format": "MM"}},
        { "name": "Day","value": {"type": "DateTime","date": "SliceStart","format": "dd"}}
      ],
      "format": {
        "type": "TextFormat"
      }
    },
    "availability": {
      "frequency": "Day",
      "interval": 1
    }
  }
}
```

**Действие: действие Hive в конвейере**

Действие hive принимает два входных набора данных и создает выходной срез данных каждый день. Зависимость ежедневного выходного среза от входного среза предыдущей недели можно задать для еженедельных входных данных приведенным ниже образом.

```json
{  
    "name":"SamplePipeline",
    "properties":{  
    "start":"2015-01-01T08:00:00",
    "end":"2015-01-01T11:00:00",
    "description":"hive activity",
    "activities": [
      {
        "name": "SampleHiveActivity",
        "inputs": [
          {
            "name": "AzureBlobInputDaily"
          },
          {
            "name": "AzureBlobInputWeekly",
            "startTime": "Date.AddDays(SliceStart, - Date.DayOfWeek(SliceStart))",
            "endTime": "Date.AddDays(SliceEnd,  -Date.DayOfWeek(SliceEnd))"  
          }
        ],
        "outputs": [
          {
            "name": "AzureBlobOutputDaily"
          }
        ],
        "linkedServiceName": "HDInsightLinkedService",
        "type": "HDInsightHive",
        "typeProperties": {
          "scriptPath": "adftutorial\\hivequery.hql",
          "scriptLinkedService": "StorageLinkedService",
          "defines": {
            "Year": "$$Text.Format('{0:yyyy}',WindowStart)",
            "Month": "$$Text.Format('{0:MM}',WindowStart)",
            "Day": "$$Text.Format('{0:dd}',WindowStart)"
          }
        },
        "scheduler": {
          "frequency": "Day",
          "interval": 1
        },            
        "policy": {
          "concurrency": 1,
          "executionPriorityOrder": "OldestFirst",
          "retry": 2,  
          "timeout": "01:00:00"
        }
       }
     ]
   }
}
```

В статье [Фабрика данных Azure — функции и системные переменные](data-factory-functions-variables.md) приведен список функций и системных переменных, поддерживаемых фабрикой данных.

## <a name="appendix"></a>Приложение

### <a name="example-copy-sequentially"></a>Пример: последовательное копирование
Несколько операций копирования можно выполнить друг за другом последовательно или упорядоченно. Допустим, в конвейере есть два действия копирования (CopyActivity1 и CopyActivity2) со следующими входным и выходным наборами данных.   

CopyActivity1

Входные данные: Dataset. Выходные данные: Dataset2.

CopyActivity2

Входные данные: Dataset2.  Выходные данные: Dataset3.

Действие копирования CopyActivity2 будет выполнено только в том случае, если действие копирования CopyActivity1 прошло успешно и набор данных Dataset2 доступен.

Ниже приведен пример файла JSON конвейера.

```json
{
    "name": "ChainActivities",
    "properties": {
        "description": "Run activities in sequence",
        "activities": [
            {
                "type": "Copy",
                "typeProperties": {
                    "source": {
                        "type": "BlobSource"
                    },
                    "sink": {
                        "type": "BlobSink",
                        "copyBehavior": "PreserveHierarchy",
                        "writeBatchSize": 0,
                        "writeBatchTimeout": "00:00:00"
                    }
                },
                "inputs": [
                    {
                        "name": "Dataset1"
                    }
                ],
                "outputs": [
                    {
                        "name": "Dataset2"
                    }
                ],
                "policy": {
                    "timeout": "01:00:00"
                },
                "scheduler": {
                    "frequency": "Hour",
                    "interval": 1
                },
                "name": "CopyFromBlob1ToBlob2",
                "description": "Copy data from a blob to another"
            },
            {
                "type": "Copy",
                "typeProperties": {
                    "source": {
                        "type": "BlobSource"
                    },
                    "sink": {
                        "type": "BlobSink",
                        "writeBatchSize": 0,
                        "writeBatchTimeout": "00:00:00"
                    }
                },
                "inputs": [
                    {
                        "name": "Dataset2"
                    }
                ],
                "outputs": [
                    {
                        "name": "Dataset3"
                    }
                ],
                "policy": {
                    "timeout": "01:00:00"
                },
                "scheduler": {
                    "frequency": "Hour",
                    "interval": 1
                },
                "name": "CopyFromBlob2ToBlob3",
                "description": "Copy data from a blob to another"
            }
        ],
        "start": "2016-08-25T01:00:00Z",
        "end": "2016-08-25T01:00:00Z",
        "isPaused": false
    }
}
```

Обратите внимание, что в примере выходной набор данных первого действия копирования (Dataset2) указан как входной набор данных второго действия. Таким образом, второе действие выполняется только после того, как готов выходной набор данных первого действия.  

В примере действие копирования CopyActivity2 может иметь другие входные данные, например набор данных Dataset3, но необходимо указать набор Dataset2 в качестве входных данных, чтобы действие копирования CopyActivity2 не запускалось, пока не завершится действие копирования CopyActivity1. Например: 

CopyActivity1

Входные данные: Dataset1. Выходные данные: Dataset2.

CopyActivity2

Входные данные: Dataset3, Dataset2. Выходные данные: Dataset4.

```json
{
    "name": "ChainActivities",
    "properties": {
        "description": "Run activities in sequence",
        "activities": [
            {
                "type": "Copy",
                "typeProperties": {
                    "source": {
                        "type": "BlobSource"
                    },
                    "sink": {
                        "type": "BlobSink",
                        "copyBehavior": "PreserveHierarchy",
                        "writeBatchSize": 0,
                        "writeBatchTimeout": "00:00:00"
                    }
                },
                "inputs": [
                    {
                        "name": "Dataset1"
                    }
                ],
                "outputs": [
                    {
                        "name": "Dataset2"
                    }
                ],
                "policy": {
                    "timeout": "01:00:00"
                },
                "scheduler": {
                    "frequency": "Hour",
                    "interval": 1
                },
                "name": "CopyFromBlobToBlob",
                "description": "Copy data from a blob to another"
            },
            {
                "type": "Copy",
                "typeProperties": {
                    "source": {
                        "type": "BlobSource"
                    },
                    "sink": {
                        "type": "BlobSink",
                        "writeBatchSize": 0,
                        "writeBatchTimeout": "00:00:00"
                    }
                },
                "inputs": [
                    {
                        "name": "Dataset3"
                    },
                    {
                        "name": "Dataset2"
                    }
                ],
                "outputs": [
                    {
                        "name": "Dataset4"
                    }
                ],
                "policy": {
                    "timeout": "01:00:00"
                },
                "scheduler": {
                    "frequency": "Hour",
                    "interval": 1
                },
                "name": "CopyFromBlob3ToBlob4",
                "description": "Copy data from a blob to another"
            }
        ],
        "start": "2017-04-25T01:00:00Z",
        "end": "2017-04-25T01:00:00Z",
        "isPaused": false
    }
}
```

Обратите внимание, что в примере для второго действия копирования задано два входных набора данных. Если указано несколько наборов входных данных, то для копирования используется только первый набор, а другие наборы используются в качестве зависимостей. Действие CopyActivity2 запустится только при соблюдении следующих условий:

* Действие CopyActivity1 успешно завершено, и набор данных Dataset2 доступен. Этот набор данных не используется при копировании данных в Dataset4. Он используется только как зависимость для планирования CopyActivity2.   
* Набор данных Dataset3 доступен. Этот данные, которые копируются в место назначения. 
