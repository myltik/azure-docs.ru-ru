---
title: Создание наборов данных в фабрике данных Azure | Документация Майкрософт
description: Узнайте, как создавать наборы данных в фабрике данных Azure, на основе примеров с использованием свойств offset и anchorDateTime.
services: data-factory
documentationcenter: ''
author: sharonlo101
manager: craigg
ms.assetid: 0614cd24-2ff0-49d3-9301-06052fd4f92a
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: conceptual
ms.date: 01/10/2018
ms.author: shlo
robots: noindex
ms.openlocfilehash: 6a3401f620f7dfe8b42bad9ed1a3981325b2ce1e
ms.sourcegitcommit: 266fe4c2216c0420e415d733cd3abbf94994533d
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 06/01/2018
ms.locfileid: "34620485"
---
# <a name="datasets-in-azure-data-factory"></a>Наборы данных в фабрике данных Azure
> [!div class="op_single_selector" title1="Select the version of Data Factory service you are using:"]
> * [Версия 1 — общедоступная](data-factory-create-datasets.md)
> * [Версия 2 — предварительная](../concepts-datasets-linked-services.md)

> [!NOTE]
> Статья относится к версии 1 фабрики данных, которая является общедоступной версией. Если вы используете версию 2 службы фабрики данных, которая находится на этапе предварительной версии, см. статью [Наборы данных и связанные службы в фабрике данных Azure](../concepts-datasets-linked-services.md).

В этой статье описывается, какие бывают наборы данных, каким образом они определяются в формате JSON, а также как они используются в конвейерах фабрики данных Azure. В этой статье подробно рассматривается каждый раздел (например, структура, доступность и политика) в определении JSON набора данных. Здесь также приведены примеры использования свойств **offset**, **anchorDateTime** и **style** в определении JSON набора данных.

> [!NOTE]
> Чтобы получить общие представления о фабрике данных, ознакомьтесь со статьей [Общие сведения о службе фабрики данных Azure, службе интеграции данных в облаке](data-factory-introduction.md). Если у вас нет практического опыта создания фабрик данных, рекомендуем для лучшего понимания этого вопроса ознакомиться с [руководством по преобразованию данных](data-factory-build-your-first-pipeline.md) и [руководством по перемещению данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md). 

## <a name="overview"></a>Обзор
Фабрика данных может иметь один или несколько конвейеров. **Конвейер** — это логическая группа **действий**, которые вместе выполняют задачу. Действия в конвейере определяют операции с данными. Например, вы можете использовать действие копирования, чтобы скопировать данные из локального сервера SQL Server в хранилище BLOB-объектов Azure. Затем можно использовать действие Hive для запуска сценария Hive в кластере HDInsight Azure, чтобы обработать данные из хранилища BLOB-объектов для получения выходных данных. Наконец, можно использовать второе действие копирования, чтобы скопировать выходные данные в хранилище данных SQL Azure, на основе которого созданы решения для создания отчетов бизнес-аналитики. Дополнительные сведения о конвейерах и действиях см. в статье [Конвейеры и действия в фабрике данных Azure](data-factory-create-pipelines.md).

У каждого действия может быть несколько входных **наборов данных** или же ни одного, и каждое действие может производить один или несколько выходных наборов данных. Входной набор данных представляет входные данные для действия в конвейере, а выходной набор данных — выходные данные для действия. Наборы данных представляют данные в разных хранилищах, например в таблицах, файлах, папках и документах. Например, набор данных больших двоичных объектов Azure указывает контейнер больших двоичных объектов и папку в хранилище BLOB-объектов, из которой конвейер должен считывать данные. 

Перед созданием набора данных создайте **связанную службу**, чтобы связать хранилище данных с фабрикой данных. Связанные службы напоминают строки подключения, определяющие сведения о подключении, необходимые для подключения фабрики данных к внешним ресурсам. Наборы данных представляют данные в связанных хранилищах данных, например в таблицах SQL, файлах, папках и документах. Например, связанная служба хранилища Azure связывает учетную запись хранения с фабрикой данных. Набор данных больших двоичных объектов Azure представляет контейнер больших двоичных объектов и папку, содержащую входные большие двоичные объекты для обработки. 

Ниже приведен пример сценария. Чтобы скопировать данные из хранилища BLOB-объектов в базу данных SQL, создайте две связанные службы: службу хранилища Azure и базу данных SQL Azure. Затем создайте два набора данных: набор данных больших двоичных объектов Azure (для связанной службы хранилища Azure) и набор данных таблицы SQL Azure (для связанной службы базы данных SQL Azure). Связанные службы хранилища Azure и базы данных SQL Azure содержат строки подключения, которые фабрика данных использует во время выполнения для подключения к службе хранилища Azure и базе данных Azure SQL соответственно. Набор данных больших двоичных объектов Azure указывает контейнер и папку больших двоичных объектов, содержащие входные большие двоичные объекты в хранилище BLOB-объектов. Набор данных таблицы SQL Azure указывает таблицу SQL в базе данных SQL, в которую будут копироваться данные.

На следующей схеме показана связь между конвейером, действием, набором данных и связанной службой в фабрике данных. 

![Связь между конвейером, действием, набором данных и связанными службами](media/data-factory-create-datasets/relationship-between-data-factory-entities.png)

## <a name="dataset-json"></a>JSON набора данных
Набор данных в фабрике данных определяется в формате JSON, как показано ниже.

```json
{
    "name": "<name of dataset>",
    "properties": {
        "type": "<type of dataset: AzureBlob, AzureSql etc...>",
        "external": <boolean flag to indicate external data. only for input datasets>,
        "linkedServiceName": "<Name of the linked service that refers to a data store.>",
        "structure": [
            {
                "name": "<Name of the column>",
                "type": "<Name of the type>"
            }
        ],
        "typeProperties": {
            "<type specific property>": "<value>",
            "<type specific property 2>": "<value 2>",
        },
        "availability": {
            "frequency": "<Specifies the time unit for data slice production. Supported frequency: Minute, Hour, Day, Week, Month>",
            "interval": "<Specifies the interval within the defined frequency. For example, frequency set to 'Hour' and interval set to 1 indicates that new data slices should be produced hourly>"
        },
       "policy":
        {      
        }
    }
}
```

В следующей таблице описаны свойства приведенного выше объекта JSON.   

| Свойство | ОПИСАНИЕ | Обязательно | значение по умолчанию |
| --- | --- | --- | --- |
| name |Имя набора данных. Правила именования для фабрики данных Azure описаны [здесь](data-factory-naming-rules.md) . |Yes |Нет данных |
| Тип |Тип набора данных. Укажите один из типов, которые поддерживает фабрика данных (например: AzureBlob, AzureSqlTable). <br/><br/>Дополнительные сведения см. в разделе [Тип набора данных](#Type). |Yes |Нет данных |
| structure |Схема набора данных.<br/><br/>Дополнительные сведения см. в разделе [Структура набора данных](#Structure). |Нет  |Нет данных |
| typeProperties | Свойства каждого типа отличаются (например, свойства большого двоичного объекта Azure и таблицы SQL Azure). Сведения о поддерживаемых типах и их свойствах см. в разделе [Тип набора данных](#Type). |Yes |Нет данных |
| external | Этот логический флаг указывает, создается ли набор данных конвейером фабрики данных явным образом. Если входной набор данных для действия не создается текущим конвейером, присвойте этому флагу значение true. Присвойте этому флагу значение true для входного набора данных первого действия в конвейере.  |Нет  |false |
| availability | Определяет окно обработки (например, каждый час или ежедневно) или модель среза для создания набора данных. Каждая единица данных, потребляемых и создаваемых запуском действия, называется срезом данных. Если для выходного набора данных задана ежедневная доступность (параметр frequency имеет значение Day, а параметр interval имеет значение 1), то срез создается каждый день. <br/><br/>Дополнительные сведения см. в разделе [Доступность набора данных](#Availability). <br/><br/>Дополнительные сведения о модели срезов набора данных см. в статье [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md). |Yes |Нет данных |
| policy |Определяет условия, которым должен соответствовать срез данных. <br/><br/>Дополнительные сведения см. в разделе [Политика наборов данных](#Policy). |Нет  |Нет данных |

## <a name="dataset-example"></a>Пример набора данных
В следующем примере набор данных представляет таблицу с именем **MyTable** в базе данных SQL.

```json
{
    "name": "DatasetSample",
    "properties": {
        "type": "AzureSqlTable",
        "linkedServiceName": "AzureSqlLinkedService",
        "typeProperties":
        {
            "tableName": "MyTable"
        },
        "availability":
        {
            "frequency": "Day",
            "interval": 1
        }
    }
}
```

Обратите внимание на следующие моменты.

* Для параметра **type** задано значение AzureSqlTable.
* Свойство типа **tableName** (используется только для типа AzureSqlTable) имеет значение MyTable.
* Параметр **linkedServiceName** ссылается на связанную службу типа AzureSqlDatabase, определение которой указано во фрагменте кода JSON ниже. 
* Параметру **availability frequency** задано значение Day, а для параметра **interval** установлено значение 1. Это означает, что срез набора данных создается ежедневно.  

**AzureSqlLinkedService** определяется следующим образом:

```json
{
    "name": "AzureSqlLinkedService",
    "properties": {
        "type": "AzureSqlDatabase",
        "description": "",
        "typeProperties": {
            "connectionString": "Data Source=tcp:<servername>.database.windows.net,1433;Initial Catalog=<databasename>;User ID=<username>@<servername>;Password=<password>;Integrated Security=False;Encrypt=True;Connect Timeout=30"
        }
    }
}
```

В предыдущем фрагменте кода JSON представлены следующие значения:

* для параметра **type** задано значение AzureSqlDatabase;
* свойство типа **connectionString** указывает сведения для подключения к базе данных SQL.  

Как видите, связанная служба определяет способ подключения к базе данных SQL. Набор данных определяет, какие таблицы используются в качестве входных и выходных данных для действия в конвейере.   

> [!IMPORTANT]
> Если набор данных не создается конвейером, он должен быть помечен как **external**. Этот параметр обычно относится к входным данным для первого действия в конвейере.   


## <a name="Type"></a>Тип набора данных
Тип набора данных зависит от хранилища данных, которые вы используете. В таблице ниже перечислены хранилища данных, поддерживаемые фабрикой данных. Щелкните хранилище данных, чтобы узнать, как для него создать связанную службу и набор данных.

[!INCLUDE [data-factory-supported-data-stores](../../../includes/data-factory-supported-data-stores.md)]

> [!NOTE]
> Хранилища данных с * могут быть локальными или в IaaS Azure. Для этих хранилищ данных необходимо установить [шлюз управления данными](data-factory-data-management-gateway.md).

В примере в предыдущем разделе задан тип набора данных **AzureSqlTable**. Аналогично для набора данных больших двоичных объектов Azure задается тип **AzureBlob**, как показано в следующем фрагменте JSON.

```json
{
    "name": "AzureBlobInput",
    "properties": {
        "type": "AzureBlob",
        "linkedServiceName": "AzureStorageLinkedService",
        "typeProperties": {
            "fileName": "input.log",
            "folderPath": "adfgetstarted/inputdata",
            "format": {
                "type": "TextFormat",
                "columnDelimiter": ","
            }
        },
        "availability": {
            "frequency": "Month",
            "interval": 1
        },
        "external": true,
        "policy": {}
    }
}
```

## <a name="Structure"></a>Структура набора данных
Раздел **structure** необязателен. Он определяет схему набора данных. В нем содержится коллекция имен и типов данных столбцов. Используйте этот раздел, чтобы указать сведения о типах, которые используются для преобразования типов и сопоставления столбцов из источника в приемник. В следующем примере набор данных имеет три столбца: `slicetimestamp`, `projectname` и `pageviews`. Они имеют типы String, String и Decimal соответственно.

```json
structure:  
[
    { "name": "slicetimestamp", "type": "String"},
    { "name": "projectname", "type": "String"},
    { "name": "pageviews", "type": "Decimal"}
]
```

В каждом столбце раздела structure содержатся следующие свойства.

| Свойство | ОПИСАНИЕ | Обязательно |
| --- | --- | --- |
| name |Имя столбца. |Yes |
| Тип |Тип данных столбца.  |Нет  |
| culture |Язык и региональные параметры на основе .NET, используемые, если указан тип .NET `Datetime` или `Datetimeoffset`. Значение по умолчанию — `en-us`. |Нет  |
| свойства |Строка формата будет использоваться, если указан тип .NET `Datetime` или `Datetimeoffset`. |Нет  |

Используйте приведенные ниже рекомендации и узнайте, когда следует включать сведения о структуре, а также что включать в раздел **structure**.

* **Для структурированных источников данных** укажите раздел structure только в том случае, если вы хотите сопоставить столбцы источника со столбцами приемника и если их имена отличаются. Этот тип структурированного источника данных хранит схему данных и сведения о типе, а также сами данные. Примерами структурированных источников данных являются SQL Server, Oracle и таблица Azure. 
  
    Для структурированных источников данных информация о типах уже доступна, поэтому ее не следует включать при добавлении раздела structure.
* **Для схемы на основе считываемых источников данных (особенно хранилища BLOB-объектов)** вы можете выбрать хранение данных без сохранения какой-либо схемы или сведений о типах вместе с данными. Для этих типов источников данных вы можете добавить раздел structure, если хотите сопоставить столбцы источника со столбцами приемника. Вы также можете добавить этот раздел в случае, когда набор данных представляет собой входные данные для действия копирования и типы данных исходного набора данных должны быть преобразованы в собственные типы для приемника. 
    
    Фабрика данных поддерживает следующие значения для указания в разделе structure сведений о типах: **Int16, Int32, Int64, Single, Double, Decimal, Byte[], Boolean, String, Guid, Datetime, Datetimeoffset и Timespan**. Это значения типов на основе .NET, совместимые со спецификацией CLS.

Фабрика данных автоматически преобразует типы при переносе данных из источника в приемник. 
  

## <a name="dataset-availability"></a>Доступность набора данных
Раздел **availability** в наборе данных определяет окно обработки для этого набора (например, каждый час, ежедневно или еженедельно). Дополнительные сведения об окнах действий см. в статье [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md).

В следующем примере раздел availability определяет, что набор выходных данных создается ежечасно или доступен ежечасно.

```json
"availability":    
{    
    "frequency": "Hour",        
    "interval": 1    
}
```

Предположим, для конвейера задано следующее время начала и окончания:  

```json
    "start": "2016-08-25T00:00:00Z",
    "end": "2016-08-25T05:00:00Z",
```

Выходной набор данных создается каждый час в пределах времени начала и времени окончания для конвейера. Таким образом, в этом конвейере создаются пять срезов набора данных — по одному для каждого окна действий (с 12:00 до 01:00, с 01:00 до 02:00, с 02:00 до 03:00, с 03:00 до 04:00, с 04:00 до 05:00). 

Ниже перечислены свойства, которые можно использовать в разделе availability.

| Свойство | ОПИСАНИЕ | Обязательно | значение по умолчанию |
| --- | --- | --- | --- |
| frequency |Указывает единицу времени, которая определяет частоту создания среза данных.<br/><br/><b>Поддерживаемые значения</b>: Minute, Hour, Day, Week, Month. |Yes |Нет данных |
| interval |Задает множитель для частоты.<br/><br/>"Интервал х частоты" определяет частоту создания срезов. Если нужно, чтобы срез в наборе данных создавался каждый час, задайте для параметра <b>frequency</b> значение <b>Hour</b>, а для параметра <b>interval</b> — значение <b>1</b>.<br/><br/>Примечание. Если вы выбрали значение **Minute** для параметра **frequency**, значение интервала должно составлять не менее 15 минут. |Yes |Нет данных |
| style |Указывает, когда выполняется срез: в начале или в конце интервала.<ul><li>StartOfInterval</li><li>EndOfInterval</li></ul>Если для **frequency** задано значение **Month**, а для **style** — **EndOfInterval**, срез данных будет создаваться в последний день месяца. Если для **style** задано значение **StartOfInterval**, срез будет создаваться в первый день месяца.<br/><br/>Если для **frequency** задано значение **Day**, а для **style** — **EndOfInterval**, срез данных будет создаваться в последний час дня.<br/><br/>Если для **frequency** задано значение **Hour**, а для **style** — **EndOfInterval**, срез создается в конце часа. Например, для периода с 13:00 до 14:00 срез создается в 14:00. |Нет  |EndOfInterval |
| anchorDateTime |Определяет момент времени, на основе которого планировщик вычисляет границы среза набора данных. <br/><br/>Примечание. Если это свойство содержит элементы с большей степенью детализации, чем указанное значение frequency, эти элементы игнорируются. Например, если для **интервала** задано значение **ежечасно** (frequency = Hour, interval = 1), а свойство **anchorDateTime** содержит **минуты и секунды**, то минуты и секунды свойства **anchorDateTime** не учитываются. |Нет  |01/01/0001 |
| offset |Интервал времени, на который сдвигаются начало и конец всех срезов данных. <br/><br/>Примечание. Если указаны значения для обоих параметров — **anchorDateTime** и **offset**, сдвиг вычисляется с учетом обоих значений. |Нет  |Нет данных |

### <a name="offset-example"></a>Пример смещения
По умолчанию ежедневные срезы (`"frequency": "Day", "interval": 1`) создаются в 00.00 (в формате UTC). Если требуется начинать их создание 06:00 (UTC), задайте смещение, как показано в следующем фрагменте. 

```json
"availability":
{
    "frequency": "Day",
    "interval": 1,
    "offset": "06:00:00"
}
```
### <a name="anchordatetime-example"></a>Пример для anchorDateTime
В следующем примере набор данных создается каждые 23 часа. Создание первого среза начинается в момент, определяемый параметром **anchorDateTime**, для которого задано значение `2017-04-19T08:00:00` (время в формате UTC).

```json
"availability":    
{    
    "frequency": "Hour",        
    "interval": 23,    
    "anchorDateTime":"2017-04-19T08:00:00"    
}
```

### <a name="offsetstyle-example"></a>Пример для offset и style
Следующий набор данных создается ежемесячно на 3-й день каждого месяца в 08:00 (`3.08:00:00`):

```json
"availability": {
    "frequency": "Month",
    "interval": 1,
    "offset": "3.08:00:00", 
    "style": "StartOfInterval"
}
```

## <a name="Policy"></a>Политика наборов данных
Раздел **policy** в определении набора данных содержит условия, которым должен соответствовать срез данных.

### <a name="validation-policies"></a>Политики проверки
| Имя политики | ОПИСАНИЕ | Применяется к | Обязательно | значение по умолчанию |
| --- | --- | --- | --- | --- |
| minimumSizeMB |Проверяет, соответствуют ли данные в **хранилище BLOB-объектов Azure** требованиям к минимальному размеру (в мегабайтах). |Хранилище больших двоичных объектов Azure |Нет  |Нет данных |
| minimumRows |Проверяет, содержат ли данные в **базе данных SQL Azure** или **таблице Azure** минимально необходимое количество строк. |<ul><li>База данных SQL Azure</li><li>таблицу Azure;</li></ul> |Нет  |Нет данных |

#### <a name="examples"></a>Примеры
**minimumSizeMB:**

```json
"policy":

{
    "validation":
    {
        "minimumSizeMB": 10.0
    }
}
```

**minimumRows:**

```json
"policy":
{
    "validation":
    {
        "minimumRows": 100
    }
}
```

### <a name="external-datasets"></a>Внешние наборы данных
Внешними считаются такие наборы данных, которые не создаются запущенным конвейером в фабрике данных. Если набор данных помечен как **external**, вы можете изменить доступность соответствующих срезов данных с помощью политики **ExternalData**.

Если набор данных не создается фабрикой данных, он должен быть помечен как **external**. Обычно этот параметр относится к входным данным для первого действия в конвейере, если не используется цепочка действий или конвейеров.

| ИМЯ | ОПИСАНИЕ | Обязательно | Значение по умолчанию |
| --- | --- | --- | --- |
| dataDelay |Время задержки проверки на наличие внешних данных для определенного среза. Например, вы можете отложить ежечасную проверку с помощью этого параметра.<br/><br/>Применяется только к настоящему времени.  Например, если сейчас 13:00 и для dataDelay задано значение "10 минут", то проверка начинается в 13:10.<br/><br/>Обратите внимание, что этот параметр не влияет на срезы в прошлом. Срезы, у которых параметры **Slice End Time**  + и **dataDelay**  < **имеют значение раньше текущего времени**, обрабатываются без задержки.<br/><br/>Время после 23:59 необходимо указать в формате `day.hours:minutes:seconds`. Например, чтобы задать 24 часа, не используйте формат 24:00:00. Вместо этого используйте 1.00:00:00. Значение 24:00:00 обозначает 24 дня (24.00:00:00). Чтобы задать 1 день и 4 часа, укажите 1:04:00:00. |Нет  |0 |
| retryInterval |Время ожидания после сбоя до повторной попытки. Этот параметр относится к настоящему времени. Если предыдущая попытка была неудачной, то по истечении периода **retryInterval** предпринимается следующая попытка. <br/><br/>Предположим, что первая попытка началась в 13:00. Если она длится одну минуту и завершается сбоем, то повторная попытка начнется в 13:02 (13:00 + время выполнения первой проверки (1 минута) + интервал повтора (1 минута)). <br/><br/>Срезы в прошлом обрабатываются без задержки. Повторная попытка происходит незамедлительно. |Нет  |00:01:00 (1 минута) |
| retryTimeout |Время ожидания для каждой следующей повторной попытки.<br/><br/>Если это значение составляет 10 минут, проверка должна занимать не более 10 минут. Если проверка длится больше 10 минут, возникает ошибка времени ожидания.<br/><br/>Если такая ошибка возникает во время всех попыток, срез помечается как **TimedOut**. |Нет  |00:10:00 (10 минут) |
| maximumRetry |Максимальное количество попыток проверки доступности внешних данных. Допустимое значение не должно превышать 10. |Нет  |3 |


## <a name="create-datasets"></a>Создание наборов данных
Наборы данных можно создать с помощью одного из указанных ниже инструментов или пакетов SDK. 

- Мастер копирования 
- Портал Azure
- Visual Studio
- PowerShell
- Шаблон диспетчера ресурсов Azure
- ИНТЕРФЕЙС REST API
- .NET API

Пошаговые инструкции по созданию конвейеров и наборов данных с помощью одного из указанных ниже инструментов или пакетов SDK приведены в указанных ниже руководствах.
 
- [Учебник. Создание первого конвейера для преобразования данных с помощью кластера Hadoop](data-factory-build-your-first-pipeline.md)
- [Руководство. Копирование данных из хранилища BLOB-объектов Azure в базу данных SQL с помощью фабрики данных](data-factory-copy-data-from-azure-blob-storage-to-sql-database.md)

После создания и развертывания конвейера вы можете управлять конвейерами и отслеживать их с помощью колонок на портале Azure или приложения для мониторинга и управления. Пошаговые инструкции представлены в указанных ниже статьях. 

- [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью портала Azure и PowerShell](data-factory-monitor-manage-pipelines.md)
- [Мониторинг конвейеров фабрики данных Azure и управление ими с помощью приложения для мониторинга и управления](data-factory-monitor-manage-app.md)


## <a name="scoped-datasets"></a>Контекст наборов данных
С помощью свойства **datasets** вы можете создавать наборы данных, прикрепленные к контексту конкретного конвейера. Такие наборы данных могут использоваться только действиями в пределах указанного конвейера, но не действиями в других конвейерах. В следующем примере определяется конвейер с двумя наборами данных (InputDataset-rdc и OutputDataset-rdc), которые будут использоваться в этом конвейере.  

> [!IMPORTANT]
> Наборы данных с заданной областью поддерживаются только разовыми конвейерами (для которых параметр **pipelineMode** имеет значение **OneTime**). Дополнительные сведения см. в разделе [Однократный конвейер](data-factory-create-pipelines.md#onetime-pipeline).
>
>

```json
{
    "name": "CopyPipeline-rdc",
    "properties": {
        "activities": [
            {
                "type": "Copy",
                "typeProperties": {
                    "source": {
                        "type": "BlobSource",
                        "recursive": false
                    },
                    "sink": {
                        "type": "BlobSink",
                        "writeBatchSize": 0,
                        "writeBatchTimeout": "00:00:00"
                    }
                },
                "inputs": [
                    {
                        "name": "InputDataset-rdc"
                    }
                ],
                "outputs": [
                    {
                        "name": "OutputDataset-rdc"
                    }
                ],
                "scheduler": {
                    "frequency": "Day",
                    "interval": 1,
                    "style": "StartOfInterval"
                },
                "name": "CopyActivity-0"
            }
        ],
        "start": "2016-02-28T00:00:00Z",
        "end": "2016-02-28T00:00:00Z",
        "isPaused": false,
        "pipelineMode": "OneTime",
        "expirationTime": "15.00:00:00",
        "datasets": [
            {
                "name": "InputDataset-rdc",
                "properties": {
                    "type": "AzureBlob",
                    "linkedServiceName": "InputLinkedService-rdc",
                    "typeProperties": {
                        "fileName": "emp.txt",
                        "folderPath": "adftutorial/input",
                        "format": {
                            "type": "TextFormat",
                            "rowDelimiter": "\n",
                            "columnDelimiter": ","
                        }
                    },
                    "availability": {
                        "frequency": "Day",
                        "interval": 1
                    },
                    "external": true,
                    "policy": {}
                }
            },
            {
                "name": "OutputDataset-rdc",
                "properties": {
                    "type": "AzureBlob",
                    "linkedServiceName": "OutputLinkedService-rdc",
                    "typeProperties": {
                        "fileName": "emp.txt",
                        "folderPath": "adftutorial/output",
                        "format": {
                            "type": "TextFormat",
                            "rowDelimiter": "\n",
                            "columnDelimiter": ","
                        }
                    },
                    "availability": {
                        "frequency": "Day",
                        "interval": 1
                    },
                    "external": false,
                    "policy": {}
                }
            }
        ]
    }
}
```

## <a name="next-steps"></a>Дополнительная информация
- Дополнительные сведения о конвейерах см. в статье [Конвейеры и действия в фабрике данных Azure](data-factory-create-pipelines.md). 
- Дополнительные сведения о планировании и выполнении конвейеров см. в статье [Планирование и исполнение с использованием фабрики данных](data-factory-scheduling-and-execution.md). 
