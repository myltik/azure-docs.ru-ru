---
title: "Вызов программ Spark из фабрики данных Azure | Документация Майкрософт"
description: "Узнайте, как вызывать программы Spark из фабрики данных Azure с помощью действия MapReduce."
services: data-factory
documentationcenter: 
author: spelluru
manager: jhubbard
editor: monicar
ms.assetid: fd98931c-cab5-4d66-97cb-4c947861255c
ms.service: data-factory
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/31/2017
ms.author: spelluru
translationtype: Human Translation
ms.sourcegitcommit: 538f282b28e5f43f43bf6ef28af20a4d8daea369
ms.openlocfilehash: 009c6a9c9b09be81e1592f6f4a988eea591e266a
ms.lasthandoff: 04/07/2017


---
# <a name="invoke-spark-programs-from-azure-data-factory-pipelines"></a>Вызов программ Spark из конвейеров фабрики данных Azure

> [!div class="op_single_selector" title1="Transformation Activities"]
> * [Действие Hive](data-factory-hive-activity.md) 
> * [Действие Pig](data-factory-pig-activity.md)
> * [Действие MapReduce](data-factory-map-reduce.md)
> * [Потоковая активность Hadoop](data-factory-hadoop-streaming-activity.md)
> * [Действие Spark](data-factory-spark.md)
> * [Действие выполнения пакета машинного обучения](data-factory-azure-ml-batch-execution-activity.md)
> * [Действие "Обновить ресурс" в службе машинного обучения](data-factory-azure-ml-update-resource-activity.md)
> * [Действие хранимой процедуры](data-factory-stored-proc-activity.md)
> * [Действие U-SQL в Data Lake Analytics](data-factory-usql-activity.md)
> * [Настраиваемое действие .NET](data-factory-use-custom-activities.md)

## <a name="introduction"></a>Введение
Действие Spark — это одно из [действий преобразования данных](data-factory-data-transformation-activities.md), которое поддерживает фабрика данных Azure. Это действие запускает указанную программу Spark в кластере Apache Spark в Azure HDInsight.    

> [!IMPORTANT]
> - Действие Spark не поддерживает кластеры HDInsight Spark, использующие Azure Data Lake Store в качестве основного хранилища.
> - Оно поддерживает только существующие (собственные) кластеры HDInsight Spark. Связанная служба HDInsight по запросу не поддерживается. 

## <a name="walkthrough-create-a-pipeline-with-spark-activity"></a>Пошаговое руководство по созданию конвейера с действием Spark
Ниже приведены стандартные действия, необходимые для создания конвейера фабрики данных с действием Spark.  

1. Создадите фабрику данных.
2. Создайте связанную службу хранилища Azure для связи хранилища Azure, которые связано с кластером HDInsight Spark, с фабрикой данных.     
2. Создайте связанную службу Azure HDInsight, чтобы связать кластер Apache Spark в Azure HDInsight с фабрикой данных.
3. Создайте набор данных, который ссылается на связанную службу хранилища Azure. Затем определите выходной набор данных для действия, даже если выходные данные не выдаются.  
4. Создайте конвейер с действием Spark, который ссылается на связанную службу HDInsight, созданную на шаге 2. Конфигурация действия выполняется на основе набора данных, созданного на предыдущем шаге в качестве выходного набора данных. На основе этого набора настраивается расписание (ежечасно, ежедневно и т. д.). Исходя из сказанного выше, вы должны определить выходной набор данных, даже если действие не выдает выходные данные.

### <a name="prerequisites"></a>Предварительные требования
1. Создайте **учетную запись хранения Azure общего назначения**, следуя указаниям в [этом разделе](../storage/storage-create-storage-account.md#create-a-storage-account).  
2. Создайте **кластер Apache Spark в Azure HDInsight**, следуя инструкциям в [этом руководстве](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md). Свяжите учетную запись хранения Azure, созданную на шаге 1, с этим кластером.  
3. Скачайте и просмотрите файл скрипта Python **test.py**, который расположен по адресу: [https://adftutorialfiles.blob.core.windows.net/sparktutorial/test.py](https://adftutorialfiles.blob.core.windows.net/sparktutorial/test.py).  
3.  Отправьте файл **test.py** в папку **pyFiles** контейнера **adfspark** в хранилище BLOB-объектов Azure. Создайте контейнер и папку, если их нет. 
 
### <a name="create-data-factory"></a>Создание фабрики данных
Начнем с создания фабрики данных.

1. Войдите на [портал Azure](https://portal.azure.com/).
2. Щелкните **Создать** в меню слева, выберите **Данные+аналитика** и щелкните **Фабрика данных**.
3. В колонке **Новая фабрика данных** введите в поле "Имя" **SProcDF**.

   > [!IMPORTANT]
   > Имя фабрики данных Azure должно быть **глобально уникальным**. Если появится сообщение об ошибке **Имя GetStartedDF фабрики данных недоступно**, измените это имя (например, на ваше_имя_SparkDFdate) и попробуйте создать ее снова. Ознакомьтесь со статьей [Фабрика данных Azure — правила именования](data-factory-naming-rules.md) , чтобы узнать о правилах именования артефактов фабрики данных.   
4. Выберите **подписку Azure** , в рамках которой вы хотите создать фабрику данных.
5. Выберите существующую **группу ресурсов** Azure или создайте новую.
6. Кроме того, выберите **Закрепить на панели мониторинга**.  
6. В колонке **Создание фабрики данных** нажмите кнопку **Создать**.

   > [!IMPORTANT]
   > Создавать экземпляры фабрики данных может пользователь с ролью [Участник фабрики данных](../active-directory/role-based-access-built-in-roles.md#data-factory-contributor) на уровне подписки или группы ресурсов.
7. Созданная фабрика данных появится на **панели мониторинга** портала Azure.   
8. Ее содержимое отобразится на соответствующей странице. Если страница фабрики данных не отображается, щелкните плитку вашей фабрики данных на панели мониторинга. 

    ![Колонка "Фабрика данных"](./media/data-factory-spark/data-factory-blade.png)

### <a name="create-linked-services"></a>Создание связанных служб
На этом шаге вы создадите две связанные службы: одну — для связи с фабрикой данных кластера Spark, а вторую — хранилища Azure.  

#### <a name="create-azure-storage-linked-service"></a>Создание связанной службы хранения Azure
На этом шаге вы свяжете учетную запись хранения Azure с фабрикой данных. Набор данных, который вы создадите на следующем шаге этого пошагового руководства, относится к этой связанной службе, как и связанная служба HDInsight, которую вы определите на следующем шаге.  
  
1. Щелкните **Создать и развернуть** в колонке **Фабрика данных** вашей фабрики данных. Откроется редактор фабрики данных.
2. Щелкните **Новое хранилище данных** и выберите пункт **Служба хранилища Azure**.

   !["Новое хранилище данных" — пункт меню "Служба хранилища Azure"](./media/data-factory-spark/new-data-store-azure-storage-menu.png)
3. В редакторе отобразится **скрипт JSON** для создания связанной службы хранилища Azure.

   ![Связанная служба хранения Azure](./media/data-factory-build-your-first-pipeline-using-editor/azure-storage-linked-service.png)
4. Замените **имя учетной записи**  и **ключ учетной записи** значениями имени и ключа учетной записи хранения Azure. Сведения о получении, просмотре, копировании и повторном создании ключей доступа к хранилищу см. в разделе [Управление учетной записью хранения](../storage/storage-create-storage-account.md#manage-your-storage-account).
5. Чтобы развернуть связанную службу, нажмите кнопку **Развернуть** на панели команд. После развертывания связанной службы окно **Draft-1** должно исчезнуть, а в представлении в виде дерева слева отобразится служба **AzureStorageLinkedService**.

#### <a name="create-hdinsight-linked-service"></a>Создание связанной службы HDInsight
На этом шаге вы создадите связанную службу Azure HDInsight, чтобы связать кластер HDInsight Spark с фабрикой данных. В этом примере кластер HDInsight используется для выполнения программы Spark, указанной в действии Spark конвейера.  

1. Нажмите **... Еще** на панели инструментов, выберите **Новое вычисление**, а затем щелкните **Кластер HDInsight**.

    ![Создание связанной службы HDInsight](media/data-factory-spark/new-hdinsight-linked-service.png)
2. Вставьте следующий фрагмент в окно **Draft-1** . В редакторе JSON выполните следующие действия: 
    1. укажите **URI** для кластера HDInsight Spark; Например, `https://<sparkclustername>.azurehdinsight.net/`. 
    2. укажите имя **пользователя**, имеющего доступ к кластеру Spark; 
    3. укажите **пароль** для пользователя; 
    4. укажите **связанную службу хранилища Azure**, которая связана с кластером HDInsight Spark (в этом примере это **AzureStorageLinkedService**). 
    
    ```json
    {
        "name": "HDInsightLinkedService",
        "properties": {
            "type": "HDInsight",
            "typeProperties": {
                "clusterUri": "https://<sparkclustername>.azurehdinsight.net/",
                "userName": "admin",
                "password": "**********",
                "linkedServiceName": "AzureStorageLinkedService"
            }
        }
    }
    ```

    > [!IMPORTANT]
    > - Действие Spark не поддерживает кластеры HDInsight Spark, использующие Azure Data Lake Store в качестве основного хранилища.
    > - Оно поддерживает только существующие (собственные) кластеры HDInsight Spark. Связанная служба HDInsight по запросу не поддерживается. 

    Подробные сведения о связанной службе HDInsight см. [в этом разделе](data-factory-compute-linked-services.md#azure-hdinsight-linked-service). 
3.  Чтобы развернуть связанную службу, нажмите кнопку **Развернуть** на панели команд.  

### <a name="create-output-dataset"></a>Создание выходного набора данных
На основе этого набора настраивается расписание (ежечасно, ежедневно и т. д.). Исходя из сказанного выше, вы должны определить выходной набор данных для действия Spark в конвейере, даже если действие не создает выходные данные. Указание входного набора данных для действия необязательно. 

1. В **редакторе фабрики данных** нажмите кнопку **... Еще** на панели команд, щелкните **Новый набор данных** и выберите **Хранилище больших двоичных объектов Azure**.  
2. Вставьте следующий фрагмент в окно Draft-1. Этот фрагмент кода JSON определяет набор данных с именем **OutputDataset**. Кроме того, нужно указать, что результаты будут храниться в контейнере больших двоичных объектов **adfspark** и в папке **pyFiles/output**. Как упоминалось ранее, это фиктивный набор данных. В этом примере программа Spark не создает никаких выходных данных. В разделе **availability** указывается частота, с которой ежедневно будет создаваться выходной набор данных.  

    ```json
    {
        "name": "OutputDataset",
        "properties": {
            "type": "AzureBlob",
            "linkedServiceName": "AzureStorageLinkedService",
            "typeProperties": {
                "fileName": "sparkoutput.txt",
                "folderPath": "adfspark/pyFiles/output",
                "format": {
                    "type": "TextFormat",
                    "columnDelimiter": "\t"
                }
            },
            "availability": {
                "frequency": "Day",
                "interval": 1
            }
        }
    }
    ```
3. Чтобы развернуть набор данных, нажмите кнопку **Развернуть** на панели команд.


### <a name="create-pipeline"></a>Создание конвейера
На этом шаге создается конвейер с действием **HDInsightSpark**. В настоящее время расписание активируется с помощью выходного набора данных, поэтому его необходимо создать, даже если действие не создает никаких выходных данных. Если действие не принимает никаких входных данных, входной набор данных можно не создавать. Таким образом, в этом примере входной набор данных не указывается. 

1. В **редакторе фабрики данных** щелкните **Еще** и выберите **Новый конвейер**.
2. Замените скрипт в окне Draft-1 следующим скриптом:

    ```json
    {
        "name": "SparkPipeline",
        "properties": {
            "activities": [
                {
                    "type": "HDInsightSpark",
                    "typeProperties": {
                        "rootPath": "adfspark\\pyFiles",
                        "entryFilePath": "test.py",
                        "getDebugInfo": "Always"
                    },
                    "outputs": [
                        {
                            "name": "OutputDataset"
                        }
                    ],
                    "name": "MySparkActivity",
                    "linkedServiceName": "HDInsightLinkedService"
                }
            ],
            "start": "2017-02-05T00:00:00Z",
            "end": "2017-02-06T00:00:00Z"
        }
    }
    ```
    Обратите внимание на следующие моменты. 
    - Свойству **type** присваивается значение **HDInsightSpark**. 
    - Свойству **rootPath** присваивается значение **adfspark\\pyFiles**, где adfspark — контейнер больших двоичных объектов Azure, а pyFiles — папка с файлами в этом контейнере. В этом примере хранилище BLOB-объектов Azure связано с кластером Spark. Файл можно отправить в другое хранилище Azure. Чтобы сделать это, создайте связанную службу хранилища Azure, которая свяжет эту учетную запись хранения с фабрикой данных. Затем укажите имя связанной службы в качестве значения свойства **sparkJobLinkedService**. Сведения об этом свойстве и других свойствах, поддерживаемых действием Spark, см. в [этом разделе](#spark-activity-properties).  
    - Свойству **entryFilePath** присваивается значение **test.py**, которое является файлом Python. 
    - Свойству **getDebugInfo** присваивается значение **Always**. Так файлы журналов будут создаваться постоянно (успешные и неудачные события).    
    
        > [!IMPORTANT]
        > Если вы не устраняете неполадки, советуем не устанавливать для этого свойства значение `Always` в рабочей среде. 
    - В разделе **outputs** содержится один выходной набор данных. Вы должны определить выходной набор данных, даже если программа Spark не выдает выходные данные. На основе этого набора настраивается расписание конвейера (ежечасно, ежедневно и т. д.).  
        
        Сведения о свойствах, поддерживаемых действием Spark, см. в [этом разделе](#spark-activity-properties).
3. Чтобы развернуть конвейер, на панели команд нажмите кнопку **Развернуть**.

### <a name="monitor-pipeline"></a>Отслеживание конвейера
1. Щелкните **X**, чтобы закрыть колонки редактора фабрики данных и вернуться на домашнюю страницу фабрики данных. Щелкните **Мониторинг и управление** для запуска приложения мониторинга на другой вкладке. 

    ![Плитка "Мониторинг и управление"](media/data-factory-spark/monitor-and-manage-tile.png)
2. Вверху укажите для фильтра **Время начала** дату **01.02.2017** и нажмите кнопку **Применить**. 
3. Вы должны видеть только одно окно действия, так как между временем начала (01.02.2017) и окончания (02.02.2017) конвейера всего один день. Убедитесь, что срез данных находится в состоянии **Готово**. 

    ![Мониторинг конвейера](media/data-factory-spark/monitor-and-manage-app.png)    
4. Выберите **окно действия** для просмотра подробной информации о выполнении действия. В случае ошибки в области справа будут отображаться детали.
 
### <a name="verify-the-results"></a>Проверка результатов

1. Запустите **записную книжку Jupyter** для кластера HDInsight Spark, перейдя по адресу: https://имя_кластера.azurehdinsight.net/jupyter. Можно также сначала запустить панель мониторинга для кластера HDInsight Spark, а затем запустить **записную книжку Jupyter**.
2. Щелкните **Создать** -> **PySpark**, чтобы создать новую записную книжку.

    ![Новая записная книжка Jupyter](media/data-factory-spark/jupyter-new-book.png)
3. Выполните следующую команду, скопировав и вставив текст и нажав **SHIFT+ENTER** в конец второй инструкции.  

    ```sql
    %%sql

    SELECT buildingID, (targettemp - actualtemp) AS temp_diff, date FROM hvac WHERE date = \"6/1/13\"
    ```
4. Убедитесь, что вы видите данные из таблицы hvac:  

    ![Результаты запроса Jupyter](media/data-factory-spark/jupyter-notebook-results.png)

Подробные инструкции см. в разделе [Выполнение запроса Spark SQL](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md#run-a-spark-sql-query). 

### <a name="troubleshooting"></a>Устранение неполадок
Так как вы задали для **getDebugInfo** значение **Always**, вы увидите вложенную папку **log** в папке **pyFiles** в контейнере больших двоичных объектов Azure. В файле журнала в папке log содержатся дополнительные сведения. Этот файл журнала особенно полезен в случае возникновения ошибки. В рабочей среде вы можете настроить состояние ошибки **Failure**.

Для дальнейшего устранения неполадок выполните следующие действия: 


1. Перейдите на страницу `https://<CLUSTERNAME>.azurehdinsight.net/yarnui/hn/cluster`.

    ![Приложение пользовательского интерфейса YARN](media/data-factory-spark/yarnui-application.png)  
2. Щелкните **Журналы** для одной из попыток выполнения.

    ![Страница приложения](media/data-factory-spark/yarn-applications.png) 
3. Вы должны увидеть дополнительные сведения об ошибке на странице журнала. 

    ![Описание ошибки в журнале](media/data-factory-spark/yarnui-application-error.png)

В следующих разделах приведены сведения о сущностях фабрики данных, необходимых для использования кластера Apache Spark и действия Spark в фабрике данных.

## <a name="spark-activity-properties"></a>Свойства действия Spark
Ниже приведен пример определения JSON конвейера с действием Spark.    

```json
{
    "name": "SparkPipeline",
    "properties": {
        "activities": [
            {
                "type": "HDInsightSpark",
                "typeProperties": {
                    "rootPath": "adfspark\\pyFiles",
                    "entryFilePath": "test.py",
                    "arguments": [ "arg1", "arg2" ],
                    "sparkConfig": {
                        "spark.python.worker.memory": "512m"
                    }
                    "getDebugInfo": "Always"
                },
                "outputs": [
                    {
                        "name": "OutputDataset"
                    }
                ],
                "name": "MySparkActivity",
                "description": "This activity invokes the Spark program",
                "linkedServiceName": "HDInsightLinkedService"
            }
        ],
        "start": "2017-02-01T00:00:00Z",
        "end": "2017-02-02T00:00:00Z"
    }
}
```

В следующей таблице приведено описание свойств, используемых в определении JSON. 

| Свойство | Описание | Обязательно |
| -------- | ----------- | -------- |
| name | Имя действия в конвейере. | Да |
| description | Описание действия. | Нет |
| type | Для этого свойства необходимо задать значение HDInsightSpark. | Да |
| linkedServiceName (имя связанной службы) | Имя связанной службы HDInsight, в которой выполняется программа Spark. | Да |
| rootPath | Контейнер BLOB-объектов Azure и папка, содержащая файл Spark. В имени файла учитывается регистр знаков. | Да |
| entryFilePath | Относительный путь к корневой папке пакета и кода Spark. | Да |
| className | Основной класс Java или Spark приложения. | Нет | 
| arguments | Список аргументов командной строки для программы Spark. | Нет | 
| proxyUser | Учетная запись пользователя для олицетворения, используемая для выполнения программы Spark. | Нет | 
| sparkConfig | Свойства конфигурации Spark. | Нет | 
| getDebugInfo | Указывает, когда файлы журнала Spark копируются в службу хранилища Azure, используемое кластером HDInsight или определенное sparkJobLinkedService. Допустимые значения: None, Always или Failure. Значение по умолчанию: None. | Нет | 
| sparkJobLinkedService | Связанная служба службы хранилища Azure, в которой хранятся файл задания Spark, зависимости и журналы.  Если значение этого свойства не указано, используется хранилище, связанное с кластером HDInsight. | Нет |

## <a name="folder-structure"></a>Структура папок
Действие Spark не поддерживает встроенный сценарий, в отличие от действий Pig и Hive. Задания Spark также обеспечивают большую гибкость, чем задания Pig и Hive. Для заданий Spark можно указать несколько зависимостей, например пакеты JAR (размещаются в CLASSPATH Java), файлы Python (размещаются в PYTHONPATH) и другие файлы.

Создайте следующую структуру папок в хранилище BLOB-объектов Azure, на которое ссылается связанная служба HDInsight. Затем передайте зависимые файлы в соответствующие вложенные папки в корневой папке, определенной значением **entryFilePath**. Например, передайте файлы Python во вложенную папку pyFiles, а JAR-файлы — во вложенную папку jars, расположенный в корневой папке. Во время выполнения служба фабрики данных ожидает в хранилище BLOB-объектов Azure следующую структуру папок.     

| Путь | Описание | Обязательно | Тип |
| ---- | ----------- | -------- | ---- | 
| .    | Путь к корневому каталогу задания Spark в хранилище связанной службы.    | Да | Папка |
| &lt;Определяется пользователем&gt; | Путь к файлу записи задания Spark. | Да | Файл | 
| ./jars | Все файлы в этой папке передаются и помещаются в папку CLASSPATH Java для кластера. | Нет | Папка |
| ./pyFiles | Все файлы в этой папке передаются и помещаются в папку PYTHONPATH для кластера. | Нет | Папка |
| ./files | Все файлы в этой папке передаются и помещаются в рабочий каталог исполнителя. | Нет | Папка |
| ./archives | Все файлы в этой папке не сжаты. | Нет | Папка |
| ./logs | Папка, в которой хранятся журналы из кластера Spark.| Нет | Папка |

Ниже приведен пример хранилища, содержащего два файла заданий Spark в хранилище BLOB-объектов Azure, на которое ссылается связанная служба HDInsight. 

```
SparkJob1
    main.jar
    files
        input1.txt
        input2.txt
    jars
        package1.jar
        package2.jar
    logs

SparkJob2
    main.py
    pyFiles
        scrip1.py
        script2.py
    logs    
```


