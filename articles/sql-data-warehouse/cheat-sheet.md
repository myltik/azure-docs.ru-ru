---
title: Памятка для хранилища данных SQL Azure | Документация Майкрософт
description: Найдите ссылки и рекомендации по быстрому созданию решений хранилища данных SQL Azure.
services: sql-data-warehouse
author: acomet
manager: craigg-msft
ms.service: sql-data-warehouse
ms.topic: overview
ms.component: design
ms.date: 04/17/2018
ms.author: acomet
ms.reviewer: igorstan
ms.openlocfilehash: a22aadff2d58ace60a980a138035e30a638b08fa
ms.sourcegitcommit: e2adef58c03b0a780173df2d988907b5cb809c82
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/28/2018
ms.locfileid: "32190416"
---
# <a name="cheat-sheet-for-azure-sql-data-warehouse"></a>Памятка для хранилища данных SQL Azure
В этой памятке предоставляются полезные советы и рекомендации по созданию решений хранилища данных SQL Azure. Прежде чем приступить к работе, подробно ознакомьтесь с каждым из шагов в записи блога [Azure SQL Data Warehouse Workload Patterns and Anti-Patterns](https://blogs.msdn.microsoft.com/sqlcat/2017/09/05/azure-sql-data-warehouse-workload-patterns-and-anti-patterns) (Шаблоны и антишаблоны рабочих нагрузок хранилища данных SQL Azure), где объясняется, что такое хранилище данных SQL и чем оно не является.

На рисунке ниже показан процесс проектирования хранилища данных.

![Эскиз]

## <a name="queries-and-operations-across-tables"></a>Запросы и операции для нескольких таблиц

Если заранее известно, какие основные операции и запросы будут выполняться в хранилище данных, можно разработать архитектуру хранилища данных с соответствующими приоритетами. Эти запросы и операции могут включать в себя:
* Соединение одной или двух таблиц фактов и таблиц измерений, фильтрацию объединенной таблицы с последующим добавлением результатов в киоск данных.
* Создание больших или маленьких обновлений с учетом продажи.
* Добавление только данных в таблицы.

Зная тип операций заранее, вы можете оптимизировать структуру таблицы.

## <a name="data-migration"></a>Перенос данных

Сначала загрузите данные в [Azure Data Lake Store](https://docs.microsoft.com/azure/data-factory/connector-azure-data-lake-store) или в хранилище BLOB-объектов Azure. Далее с помощью PolyBase загрузите данные в хранилище данных SQL в промежуточной таблице. Используйте следующую конфигурацию:

| Проектирование | Рекомендации |
|:--- |:--- |
| Дистрибутив | Циклический перебор, |
| Индексация | Куча |
| Секционирование | None |
| Класс ресурсов | largerc или xlargerc |

Подробнее о [переносе данных], [загрузке данных], а также о [процессе извлечения, загрузки и преобразования (ELT)](https://docs.microsoft.com/azure/sql-data-warehouse/design-elt-data-loading). 

## <a name="distributed-or-replicated-tables"></a>Распределенные или реплицируемые таблицы

В зависимости от свойств таблицы используйте следующие стратегии:

| type | Подходит...| Не подходит|
|:--- |:--- |:--- |
| Реплицированный | • Малые таблицы измерения в схеме типа "звезда" с хранилищем размером менее 2 ГБ после сжатия (приблизительно в 5 раз) |• Выполняется большое количество транзакций записей для таблицы (таких как вставка, операция upsert, удаление, обновление)<br></br>• Часто меняется подготовка единиц использования хранилища данных (DWU)<br></br>• Используются только 2–3 столбца, в то время как таблица содержит много столбцов<br></br>•  Индексируется реплицированная таблица |
| Циклический перебор (по умолчанию) | • Временная или промежуточная таблица<br></br> • Нет очевидного ключа соединения или потенциальной колонки |• Производительность снижается из-за перемещения данных |
| Хэш | • Таблицы фактов<br></br>•    Большие таблицы измерений |• Нельзя обновить ключ распределения |

**Советы**
* Начните с циклического перебора, но стремитесь к реализации стратегии распределения хэша, чтобы воспользоваться архитектурой массового параллелизма.
* Убедитесь, что общие ключи хэша имеют одинаковый формат данных.
* Не распределяйте в формате varchar.
* Таблицы измерений с общим ключом хэша к таблице фактов с частыми операциями объединения могут быть распределены по хэшу.
* С помощью *[sys.dm_pdw_nodes_db_partition_stats]* анализируйте любую асимметрию в данных.
* С помощью *[sys.dm_pdw_request_steps]* анализируйте перемещения данных по запросам, контролируйте время трансляции и операций смешения. Это помогает рассмотреть стратегию распределения.

Подробнее о [реплицированных таблицах] и [распределенных таблицах].

## <a name="index-your-table"></a>Индексирование таблицы

Индексирование полезно для быстрого чтения таблицы. Существует уникальный набор технологий, которые можно использовать в зависимости от ваших потребностей.

| type | Подходит... | Не подходит|
|:--- |:--- |:--- |
| Куча | • Промежуточная или временная таблица<br></br>• Маленькие таблицы с небольшой областью поиска |• Любой поиск сканирует всю таблицу |
| Кластеризованный индекс | • Таблицы, содержащие не более 100 млн строк<br></br>• Большие таблицы (более 100 млн строк) с 1–2 используемыми столбцами |• Используется реплицированная таблица<br></br>• Выполняются сложные запросы, включающие несколько операций присоединения и группирования<br></br>• Создаются обновления в индексированных столбцах; это занимает память |
| Кластеризованный индекс columnstore (CCI) (по умолчанию) | • Большие таблицы (более 100 млн строк) | • Используется реплицированная таблица<br></br>•    Выполняются массовые операции обновления в таблице<br></br>• Допущено избыточное секционирование таблицы: группы строк не охватывают разные узлы и секции распределения |

**Советы**
* Возможно, в дополнение к кластеризованному индексу в столбце, активно используемом для фильтрации, необходимо будет добавить некластеризованный индекс. 
* Следите за управлением памятью для таблицы с CCI. Нужно, чтобы при загрузке пользователь (или запрос) использовал большой класс ресурсов. Убедитесь, что избежали обрезки и создания множества маленьких групп сжатых строк.
* На уровне Gen2 таблицы CCI таблиц кэшируются локально на вычислительных узлах, чтобы добиться максимальной производительности.
* При использовании CCI недостаточно эффективное сжатие групп может снизить производительность. В этом случае перестройте или реорганизуйте CCI. На сжатую группу строк потребуется не менее 100 000 строк. Идеальный вариант — 1 млн строк в каждой группе.
* С учетом того, как часто добавляется поэтапная нагрузка, а также ее размера при реорганизации и перестройке индексов можно автоматизировать процессы. Всегда можно использовать очистку Spring.
* Учитывайте различные факторы, когда необходимо обрезать группу строк. Каков размер открытых групп строк? Какой объем данных необходимо загрузить в течение нескольких дней?

Подробнее об [индексах].

## <a name="partitioning"></a>Секционирование
Большие таблицы фактов (более 1 млрд строк) можно разделить на секции. В 99 процентах случаев ключ секции должен быть основан на дате. Старайтесь не допускать избыточного секционирования, особенно если у вас кластеризованный индекс columnstore.

Использовать разделение можно для промежуточных таблиц, которым необходимо извлечение, загрузка и преобразование. Это упрощает управление жизненным циклом данных.
Старайтесь не допустить избыточного секционирования данных, особенно в кластеризованном индексе columnstore.

Подробнее о [секциях].

## <a name="incremental-load"></a>Поэтапная загрузка

Если данные будут загружаться поэтапно, то сначала необходимо убедиться, что для загрузки данных выделены большие классы ресурсов. Для автоматизации конвейеров извлечения, загрузки и преобразования в хранилище данных SQL рекомендуем использовать PolyBase и ADF V2.

Для большого пакета обновлений исторических данных сначала удалите соответствующие данные. Затем можно выполнить массовую вставку новых данных. Такой двухэтапный подход более эффективен.

## <a name="maintain-statistics"></a>Обеспечение статистики
 Пока автоматическая статистика не станет общедоступной, для хранилища данных SQL необходимо вести статистику вручную. Важно также обновлять статистику, так как данные могут быть *существенно* изменены. Это поможет оптимизировать ваши планы запросов. Если ведение статистики занимает слишком много времени, нужно выбирать отдельные столбцы, для которых необходимо создавать статистику. 

Кроме того, вы можете определить частоту обновлений. Например, можно ежедневно обновлять столбцы дат, в которые добавляются новые значения. Статистику рекомендуется вести в столбцах, которые являются частью объединения, используются в предложении WHERE или GROUP BY.

Подробнее о [статистике].

## <a name="resource-class"></a>Класс ресурсов
Чтобы выделить память для выполнения запросов, в хранилище данных SQL используются группы ресурсов. Если для повышения скорости запроса или загрузки вам требуется больше памяти, необходимо выделить более высокие классы ресурсов. С другой стороны, использование больших классов ресурсов влияет на параллелизм. Обратите на это внимание, прежде чем перемещать всех своих пользователей в большой класс ресурсов.

Если вы заметили, что запросы занимают слишком много времени, убедитесь, что пользователи не работают в больших классах ресурсов. Большие классы потребляют значительно количество слотов выдачи. Они могут создать дополнительные запросы в очереди.

Наконец, при использовании хранилища данных SQL уровня Gen2 каждый класс ресурсов получает в 2,5 раза больше памяти, чем на уровне Gen1.

Подробнее о работе с [классами ресурсов и параллелизмом].

## <a name="lower-your-cost"></a>Сокращение расходов
Основная функция хранилища данных SQL — возможность [управлять вычислительными ресурсами](sql-data-warehouse-manage-compute-overview.md). Вы можете приостанавливать работу хранилища данных, когда оно не используется. Счет выставляется только за используемые вычислительные ресурсы. Вы можете масштабировать ресурсы в соответствии со своими требованиями к производительности. Приостановить выполнение можно на [портале Azure](pause-and-resume-compute-portal.md) или при помощи [PowerShell](pause-and-resume-compute-powershell.md). Для масштабирования используйте [портал Azure](quickstart-scale-compute-portal.md), [Powershell](quickstart-scale-compute-powershell.md), [T-SQL](quickstart-scale-compute-tsql.md), или [REST API](sql-data-warehouse-manage-compute-rest-api.md#scale-compute).

Выполняйте автоматическое масштабирование с помощью службы "Функции Azure" в любое время.

<a href="https://ms.portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2FMicrosoft%2Fsql-data-warehouse-samples%2Fmaster%2Farm-templates%2FsqlDwTimerScaler%2Fazuredeploy.json" target="_blank">
<img src="https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/1-CONTRIBUTION-GUIDE/images/deploytoazure.png"/>
</a>

## <a name="optimize-your-architecture-for-performance"></a>Оптимизация архитектуры для производительности

Рекомендуем рассматривать базу данных SQL и Azure Analysis Services в звездообразной архитектуре. Это решение может обеспечить изоляцию рабочей нагрузки между различными группами пользователей наряду с использованием некоторых расширенных функций безопасности базы данных SQL и Azure Analysis Services. Это также поможет обеспечить неограниченный параллелизм для ваших пользователей.

Подробнее о [типичных архитектурах, использующих возможности хранилища данных SQL](https://blogs.msdn.microsoft.com/sqlcat/2017/09/05/common-isv-application-patterns-using-azure-sql-data-warehouse/).

Разверните периферийные зоны в базах данных SQL из хранилища данных SQL одним щелчком.

<a href="https://ms.portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2FMicrosoft%2Fsql-data-warehouse-samples%2Fmaster%2Farm-templates%2FsqlDwSpokeDbTemplate%2Fazuredeploy.json" target="_blank">
<img src="https://raw.githubusercontent.com/Azure/azure-quickstart-templates/master/1-CONTRIBUTION-GUIDE/images/deploytoazure.png"/>
</a>


<!--Image references-->
[Эскиз]:media/sql-data-warehouse-cheat-sheet/picture-flow.png

<!--Article references-->
[загрузке данных]:design-elt-data-loading.md
[deeper guidance]:guidance-for-loading-data.md
[индексах]:sql-data-warehouse-tables-index.md
[секциях]:sql-data-warehouse-tables-partition.md
[статистике]:sql-data-warehouse-tables-statistics.md
[классами ресурсов и параллелизмом]:resource-classes-for-workload-management.md
[реплицированных таблицах]:design-guidance-for-replicated-tables.md
[распределенных таблицах]:sql-data-warehouse-tables-distribute.md

<!--MSDN references-->


<!--Other Web references-->
[typical architectures that take advantage of SQL Data Warehouse]: https://blogs.msdn.microsoft.com/sqlcat/2017/09/05/common-isv-application-patterns-using-azure-sql-data-warehouse/
[is and is not]:https://blogs.msdn.microsoft.com/sqlcat/2017/09/05/azure-sql-data-warehouse-workload-patterns-and-anti-patterns/
[переносе данных]:https://blogs.msdn.microsoft.com/sqlcat/2016/08/18/migrating-data-to-azure-sql-data-warehouse-in-practice/

[Azure Data Lake Store]: ../data-factory/connector-azure-data-lake-store.md
[sys.dm_pdw_nodes_db_partition_stats]: /sql/relational-databases/system-dynamic-management-views/sys-dm-db-partition-stats-transact-sql
[sys.dm_pdw_request_steps]:/sql/relational-databases/system-dynamic-management-views/sys-dm-pdw-request-steps-transact-sql
