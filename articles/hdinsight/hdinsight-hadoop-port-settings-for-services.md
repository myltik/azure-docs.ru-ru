---
title: Порты, используемые службами Hadoop в HDInsight — Azure | Документы Майкрософт
description: Список портов, которые используются службами Hadoop, работающими в кластере HDInsight.
services: hdinsight
documentationcenter: ''
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: dd14aed9-ec25-4bb3-a20c-e29562735a7d
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: conceptual
ms.date: 04/20/2018
ms.author: larryfr
ms.openlocfilehash: 4490ac9bccb406bd2e882fc8afcbaf05aa8ddfab
ms.sourcegitcommit: fa493b66552af11260db48d89e3ddfcdcb5e3152
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/23/2018
ms.locfileid: "31797320"
---
# <a name="ports-used-by-hadoop-services-on-hdinsight"></a>Порты, используемые службами Hadoop в HDInsight

В этом документе представлен список портов, которые используются службами Hadoop, работающими в кластерах HDInsight под управлением Linux. Кроме того, в статье содержатся сведения о портах, которые используются для подключения к кластеру с помощью протокола SSH.

## <a name="public-ports-vs-non-public-ports"></a>Общедоступные и необщедоступные порты

Кластеры HDInsight под управлением Linux предоставляют только три общедоступных порта для трафика Интернета: 22, 23 и 443. Они используются для безопасного доступа к кластеру с помощью протокола SSH и службам, предоставляемым через защищенный протокол HTTPS.

По сути, HDInsight реализуется несколькими виртуальными машинами Azure (узлами кластера), которые работают в виртуальной сети Azure. Из виртуальной сети вы можете получить доступ к портам, недоступным из Интернета. Например, подключившись к одному из головных узлов по протоколу SSH, вы можете получить прямой доступ к службам, работающим на узлах кластера.

> [!IMPORTANT]
> Если не указать виртуальную сеть Azure с помощью параметра конфигурации для HDInsight, она будет создана автоматически. Тем не менее к этой виртуальной сети невозможно присоединить другие компьютеры (например, другие виртуальные машины Azure или клиентский компьютер разработки).


Чтобы присоединить дополнительные компьютеры к виртуальной сети, необходимо сначала создать виртуальную сеть, а затем указать ее при создании кластера HDInsight. Дополнительные сведения см. в статье [Расширение возможностей HDInsight с помощью виртуальной сети Azure](hdinsight-extend-hadoop-virtual-network.md).

## <a name="public-ports"></a>Общедоступные порты

Все узлы в кластере HDInsight расположены в виртуальной сети Azure. Получить доступ к ним напрямую из Интернета невозможно. Общедоступный шлюз обеспечивает интернет-доступ к приведенным ниже портам. Они общие для всех типов кластеров HDInsight.

| Service | Порт | Протокол | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| sshd |22 |SSH |Подключает клиенты к sshd на основном головном узле. Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md). |
| sshd |22 |SSH |Подключает клиенты к SSHD на граничном узле. Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md). |
| sshd |23 |SSH |Подключает клиенты к sshd на дополнительном головном узле. Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md). |
| Ambari |443 |HTTPS |Веб-интерфейс Ambari. См. статью [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md). |
| Ambari |443 |HTTPS |REST API Ambari. См. статью [Управление кластерами HDInsight с помощью REST API Ambari](hdinsight-hadoop-manage-ambari-rest-api.md). |
| WebHCat |443 |HTTPS |REST API HCatalog. См. статьи [Выполнение заданий Pig с помощью Curl с использованием Hadoop в HDInsight](hadoop/apache-hadoop-use-pig-curl.md), [Выполнение заданий Pig с помощью Curl с использованием Hadoop в HDInsight](hadoop/apache-hadoop-use-pig-curl.md) и [Выполнение заданий MapReduce с помощью Curl с использованием Hadoop в HDInsight](hadoop/apache-hadoop-use-mapreduce-curl.md). |
| HiveServer2 |443 |ODBC |Подключение к Hive с помощью ODBC. См. статью [Подключение Excel к Hadoop с помощью драйвера Microsoft Hive ODBC](hadoop/apache-hadoop-connect-excel-hive-odbc-driver.md). |
| HiveServer2 |443 |JDBC |Подключение к Hive с помощью JDBC. См. статью [Подключение к Hive в Azure HDInsight с помощью драйвера Hive JDBC](hadoop/apache-hadoop-connect-hive-jdbc-driver.md). |

Приведенные ниже сведения доступны для определенных типов кластеров.

| Service | Порт | Протокол | Тип кластера | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| Stargate |443 |HTTPS |hbase |REST API HBase. См. статью [Руководство по HBase. Приступая к работе с Apache HBase на Hadoop под управлением Linux в HDInsight](hbase/apache-hbase-tutorial-get-started-linux.md). |
| Livy |443 |HTTPS |Spark |Spark REST API. См. статью [Удаленная отправка заданий Spark в кластер Apache Spark в HDInsight на платформе Linux с помощью Livy](spark/apache-spark-livy-rest-interface.md). |
| Сервер Thrift Spark |443 |HTTPS |Spark |Сервер Thrift Spark, который используется для отправки запросов Hive. См. статью [Использование клиента Beeline с Apache Hive](hadoop/apache-hadoop-use-hive-beeline.md). |
| Storm |443 |HTTPS |Storm |Веб-интерфейс Storm. См. статью [Развертывание топологий Apache Storm в HDInsight под управлением Linux и управление ими](storm/apache-storm-deploy-monitor-topology-linux.md). |

### <a name="authentication"></a>Authentication

Все общедоступные службы в Интернете должны проходить проверку подлинности.

| Порт | Учетные данные |
| --- | --- |
| 22 или 23 |Учетные данные пользователя SSH, указанные при создании кластера. |
| 443 |Имя для входа (по умолчанию — admin) и пароль, указанные при создании кластера. |

## <a name="non-public-ports"></a>Необщедоступные порты

> [!NOTE]
> Некоторые службы доступны только в кластерах определенных типов. Например, служба HBase доступна только на кластерах типа HBase.

> [!IMPORTANT]
> Некоторые службы могут работать только на одном головном узле одновременно. Если вы пытаетесь подключиться к службе на основном головном узле и получаете сообщение об ошибке, повторите попытку, используя вторичный головной узел.

### <a name="ambari"></a>Ambari

| Service | Nodes | Порт | URL-адрес | Протокол | 
| --- | --- | --- | --- | --- |
| Веб-интерфейс Ambari | Головные узлы | 8080 | / | HTTP |
| Ambari REST API | Головные узлы | 8080 | /api/v1 | HTTP |

Примеры:

* Ambari REST API: `curl -u admin "http://10.0.0.11:8080/api/v1/clusters"`

### <a name="hdfs-ports"></a>Порты HDFS

| Service | Nodes | Порт | Протокол | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| Веб-интерфейс узла имен |Головные узлы |30070 |HTTPS |Пользовательский веб-интерфейс для просмотра состояния. |
| Служба метаданных на узле имен |Головные узлы |8020 |IPC |Метаданные файловой системы |
| Узел данных |Все рабочие узлы |30075 |HTTPS |Веб-интерфейс для просмотра состояния, журналов и т. д. |
| Узел данных |Все рабочие узлы |30010 |&nbsp; |Передача данных |
| Узел данных |Все рабочие узлы |30020 |IPC |Операции с метаданными |
| Дополнительный узел имен |Головные узлы |50090 |HTTP |Контрольная точка для метаданных узла имен |

### <a name="yarn-ports"></a>Порты YARN

| Service | Nodes | Порт | Протокол | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| Веб-интерфейс для диспетчера Resource Manager |Головные узлы |8088 |HTTP |Веб-интерфейс для диспетчера Resource Manager |
| Веб-интерфейс для диспетчера Resource Manager |Головные узлы |8090 |HTTPS |Веб-интерфейс для диспетчера Resource Manager |
| Интерфейс администратора для Resource Manager |Головные узлы |8141 |IPC |Для отправки приложений (Hive, Hive Server, Pig и т. д.) |
| Планировщик Resource Manager |Головные узлы |8030 |HTTP |Интерфейс администратора |
| Интерфейс приложения Resource Manager |Головные узлы |8050 |HTTP |Адрес интерфейса диспетчера приложений |
| Диспетчер узлов |Все рабочие узлы |30050 |&nbsp; |Адрес диспетчера контейнеров |
| Веб-интерфейс диспетчера узлов |Все рабочие узлы |30060 |HTTP |Интерфейс Resource Manager |
| Адрес временной шкалы |Головные узлы |10200 |RPC |Служба RPC службы временной шкалы |
| Веб-интерфейс временной шкалы |Головные узлы |8181 |HTTP |Веб-интерфейс службы временной шкалы |

### <a name="hive-ports"></a>Порты Hive

| Service | Nodes | Порт | Протокол | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| HiveServer2 |Головные узлы |10001 |Thrift |Служба для подключения к Hive (с помощью протокола Thrift или JDBC) |
| Метахранилище Hive |Головные узлы |9083 |Thrift |Служба для подключения к метаданным Hive (с помощью протокола Thrift или JDBC) |

### <a name="webhcat-ports"></a>Порты WebHCat

| Service | Nodes | Порт | Протокол | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| Сервер WebHCat |Головные узлы |30111 |HTTP |Веб-API на базе HCatalog и других служб Hadoop |

### <a name="mapreduce-ports"></a>Порты MapReduce

| Service | Nodes | Порт | Протокол | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| Журнал заданий |Головные узлы |19888 |HTTP |Веб-интерфейс журнала заданий MapReduce |
| Журнал заданий |Головные узлы |10020 |&nbsp; |Сервер журнала заданий MapReduce |
| Обработчик перемещений |&nbsp; |13562 |&nbsp; |Передача промежуточных выходных данных сопоставления в адрес запрашивающих редукторов |

### <a name="oozie"></a>Oozie,

| Service | Nodes | Порт | Протокол | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| Сервер Oozie |Головные узлы |11000 |HTTP |URL-адрес службы Oozie |
| Сервер Oozie |Головные узлы |11001 |HTTP |Порт для администрирования Oozie |

### <a name="ambari-metrics"></a>Метрики Ambari

| Service | Nodes | Порт | Протокол | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| Временная шкала (журнал приложения) |Головные узлы |6188 |HTTP |Веб-интерфейс службы временной шкалы |
| Временная шкала (журнал приложения) |Головные узлы |30200 |RPC |Веб-интерфейс службы временной шкалы |

### <a name="hbase-ports"></a>Порты HBase

| Service | Nodes | Порт | Протокол | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| HMaster |Головные узлы |16000 |&nbsp; |&nbsp; |
| Веб-интерфейс информационного сервера HMaster |Головные узлы |16010 |HTTP |Порт для веб-интерфейса на главном узле HBase |
| Региональный сервер |Все рабочие узлы |16020 |&nbsp; |&nbsp; |
| &nbsp; |&nbsp; |2181 |&nbsp; |Порт, используемый клиентами для подключения к ZooKeeper |

### <a name="kafka-ports"></a>Порты Kafka

| Service | Nodes | Порт | Протокол | ОПИСАНИЕ |
| --- | --- | --- | --- | --- |
| Broker |Рабочие узлы |9092 |[Сетевой протокол Kafka](http://kafka.apache.org/protocol.html) |Используется для связи с клиентами |
| &nbsp; |Узлы Zookeeper |2181 |&nbsp; |Порт, используемый клиентами для подключения к ZooKeeper |

### <a name="spark-ports"></a>Порты Spark

| Service | Nodes | Порт | Протокол | URL-адрес | ОПИСАНИЕ |
| --- | --- | --- | --- | --- | --- |
| Серверы Thrift Spark |Головные узлы |10002 |Thrift | &nbsp; | Служба для подключения к Spark SQL (с помощью протокола Thrift или JDBC) |
| Сервер Livy | Головные узлы | 8998 | HTTP | &nbsp; | Служба для запуска инструкций, заданий и приложений |
| Записная книжка Jupyter | Головные узлы | 8001 | HTTP | &nbsp; | Веб-сайт записных книжек Jupyter |

Примеры:

* Livy: `curl -u admin -G "http://10.0.0.11:8998/"`. В этом примере `10.0.0.11` — IP-адрес головного узла, на котором размещена служба Livy.
