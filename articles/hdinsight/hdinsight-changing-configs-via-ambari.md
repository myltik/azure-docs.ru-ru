---
title: Оптимизация конфигураций кластеров с помощью Ambari (Azure HDInsight) | Документация Майкрософт
description: Настройка и оптимизация кластеров HDInsight с помощью пользовательского веб-интерфейса Ambari.
documentationcenter: ''
author: ashishthaps
manager: jhubbard
editor: cgronlun
ms.assetid: ''
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.date: 01/09/2018
ms.author: ashish
ms.openlocfilehash: f3c1edc767ab07bcdd8b09a0e40e291cbd1f3d9a
ms.sourcegitcommit: 9cdd83256b82e664bd36991d78f87ea1e56827cd
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2018
ms.locfileid: "31406190"
---
# <a name="use-ambari-to-optimize-hdinsight-cluster-configurations"></a>Использование Ambari для оптимизации конфигураций кластеров HDInsight

HDInsight предоставляет кластеры Apache Hadoop для приложений крупномасштабной обработки данных. Осуществление управления, мониторинга и оптимизации этих сложных кластеров со множеством узлов может оказаться сложной задачей. [Apache Ambari](http://ambari.apache.org/) — это веб-интерфейс для управления кластерами HDInsight Linux и их мониторинга.  Для кластеров Windows используйте [REST API](hdinsight-hadoop-manage-ambari-rest-api.md) Ambari.

Основные сведения о пользовательском веб-интерфейсе Ambari приведены в разделе [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md).

Войдите в Ambari по адресу `https://CLUSTERNAME.azurehdidnsight.net` с помощью учетных данных кластера. Начальный экран отображает панель мониторинга с общими сведениями.

![Панель мониторинга Ambari](./media/hdinsight-changing-configs-via-ambari/ambari-dashboard.png)

С помощью пользовательского веб-интерфейса Ambari можно управлять узлами, службами, оповещениями, конфигурациями и представлениями. Ambari невозможно использовать для создания кластера HDInsight, обновления служб, управления стеками и версиями, прекращения или возобновления использования узлов, а также для добавления служб в кластер.

## <a name="manage-your-clusters-configuration"></a>Управление конфигурацией кластера

Параметры конфигурации помогают настроить определенную службу. Чтобы изменить параметры конфигурации службы, выберите службу на боковой панели **Services** (Службы) (слева) и перейдите на вкладку **Configs** (Конфигурации) на странице сведений о службе.

![Боковая панель "Services" (Службы)](./media/hdinsight-changing-configs-via-ambari/services-sidebar.png)

### <a name="modify-namenode-java-heap-size"></a>Изменение размера кучи NameNode Java

Размер кучи NameNode Java зависит от многих факторов, например от нагрузки на кластер, числа файлов и числа блоков. По умолчанию ее размер составляет 1 ГБ, что подходит для большинства кластеров, хотя для некоторых рабочих нагрузок может потребоваться больше или меньше памяти. 

Вот как можно изменить размер кучи NameNode Java.

1. Выберите **HDFS** на боковой панели "Services" (Службы) и перейдите на вкладку **Configs** (Конфигурации).

    ![Конфигурация HDFS](./media/hdinsight-changing-configs-via-ambari/hdfs-config.png)

2. Найдите параметр **NameNode Java heap size** (Размер кучи NameNode Java). Можно также использовать текстовое поле **фильтра**, чтобы ввести и найти конкретное значение. Щелкните значок **пера** рядом с именем параметра.

    ![Размер кучи NameNode Java](./media/hdinsight-changing-configs-via-ambari/java-heap-size.png)

3. Введите новое значение в текстовом поле и нажмите клавишу **ВВОД**, чтобы сохранить изменения.

    ![Изменение размера кучи NameNode Java](./media/hdinsight-changing-configs-via-ambari/java-heap-size-edit.png)

4. Размер кучи NameNode Java изменен на 2 ГБ вместо 1 ГБ.

    ![Измененный размер кучи NameNode Java](./media/hdinsight-changing-configs-via-ambari/java-heap-size-edited.png)

5. Сохраните изменения, нажав зеленую кнопку **Save** (Сохранить) в верхней части экрана конфигурации.

    ![Сохранение изменений](./media/hdinsight-changing-configs-via-ambari/save-changes.png)

## <a name="hive-optimization"></a>Оптимизация Hive

В следующих разделах описаны параметры конфигурации, используемые для оптимизации общей производительности Hive.

1. Чтобы изменить параметры конфигурации Hive, выберите **Hive** на боковой панели "Services" (Службы).
2. Перейдите на вкладку **Configs** (Конфигурации).

### <a name="set-the-hive-execution-engine"></a>Настройка подсистемы выполнения Hive

Hive предоставляет две подсистемы выполнения: MapReduce и Tez. Tez работает быстрее, чем MapReduce. По умолчанию в кластерах HDInsight Linux используется подсистема выполнения Tez. Вот как можно изменить подсистему выполнения.

1. На вкладке **Configs** (Конфигурации) Hive в поле фильтра введите **execution engine**.

    ![Поиск подсистемы выполнения](./media/hdinsight-changing-configs-via-ambari/search-execution.png)

2. Свойство **Optimization** (Оптимизация) по умолчанию имеет значение **Tez**.

    ![Оптимизация Tez](./media/hdinsight-changing-configs-via-ambari/optimization-tez.png)

### <a name="tune-mappers"></a>Настройка модулей сопоставления

Hadoop пытается разделить (*сопоставить*) отдельный файл на несколько файлов и параллельно обрабатывать эти файлы. Число модулей сопоставления зависит от того, на сколько файлов разделяется файл. Следующие два параметра конфигурации влияют на число разбиений для подсистемы выполнения Tez:

* `tez.grouping.min-size`: минимальный размер сгруппированного разбиения; значение по умолчанию составляет 16 МБ (16 777 216 байтов);
* `tez.grouping.max-size`: максимальный размер сгруппированного разбиения; значение по умолчанию составляет 1 ГБ (1 073 741 824 байтов).

Для повышения производительности рекомендуется уменьшить значение обоих этих параметров. Это позволит сократить задержку и увеличить пропускную способность.

Например, чтобы задать четыре задачи модуля сопоставления для данных размером в 128 МБ, можно для обоих параметров задать значение 32 МБ (33 554 432 байтов).

1. Чтобы изменить параметры ограничения, перейдите на вкладку **Configs** (Конфигурации) службы Tez. Разверните панель **General** (Общие) и найдите параметры `tez.grouping.max-size` и `tez.grouping.min-size`.

2. Задайте для обоих параметров значение **33 554 432** байтов (32 МБ).

    ![Размеры группирования Tez](./media/hdinsight-changing-configs-via-ambari/tez-grouping-size.png)
 
Эти изменения влияют на все задания Tez на сервере. Чтобы получить оптимальные результаты, выберите соответствующие значения параметров.

### <a name="tune-reducers"></a>Настройка модулей сжатия

ORC и Snappy обеспечивают высокую производительность. Однако в Hive может использоваться слишком мало модулей сжатия по умолчанию, что может приводить к возникновению узких мест.

Предположим, что имеются входные данные размером в 50 ГБ. В формате ORC с использованием сжатия Snappy эти данные имеют размер 1 ГБ. Hive оценивает необходимое количество модулей сжатия по формуле: (число входных байтов для модулей сжатия / `hive.exec.reducers.bytes.per.reducer`).

С параметрами по умолчанию в этом примере используются 4 модуля сжатия.

Параметр `hive.exec.reducers.bytes.per.reducer` задает количество байтов, обрабатываемых модулем сжатия. Значение по умолчанию — 64 МБ. Если уменьшить это значение, это увеличит распараллеливание, что может повысить производительность. Слишком маленькое значение может также привести к использованию слишком большого числа модулей сжатия, что может отрицательно повлиять на производительность. Этот параметр зависит от конкретных требований к обработке данных, параметров сжатия и других факторов среды.

1. Чтобы изменить этот параметр, перейдите на вкладку **Configs** (Конфигурации) Hive и найдите параметр **Data per Reducer** (Данные на модуль сжатия) на странице "Settings" (Параметры).

    ![Параметр "Data per Reducer" (Данные на модуль сжатия)](./media/hdinsight-changing-configs-via-ambari/data-per-reducer.png)
 
2. Выберите **Edit** (Изменить), чтобы изменить значение параметра на 128 МБ (134 217 728 байтов), и нажмите клавишу **ВВОД**, чтобы сохранить изменение.

    ![Измененное значение параметра "Data per Reducer" (Данные на модуль сжатия)](./media/hdinsight-changing-configs-via-ambari/data-per-reducer-edited.png)
  
    При входных данных размером в 1024 МБ и 128 МБ данных на модуль сжатия будут использоваться 8 модулей сжатия (1024 / 128).

3. Неправильное значение параметра **Data per Reducer** (Данные на модуль сжатия) может привести к появлению большого количества модулей сжатия, что отрицательно повлияет на производительность запросов. Чтобы задать максимальное число модулей сжатия, задайте для параметра `hive.exec.reducers.max` соответствующее значение. Значение по умолчанию — 1009.

### <a name="enable-parallel-execution"></a>Включение параллельного выполнения

Запрос Hive выполняется в один или несколько этапов. Если независимые этапы могут выполняться параллельно, это повышает производительность запросов.

1.  Чтобы включить параллельное выполнение запросов, перейдите на вкладку **Configs** (Конфигурации) и найдите свойство `hive.exec.parallel`. По умолчанию для этого параметра используется значение false. Установите значение true и нажмите клавишу **ВВОД**, чтобы сохранить изменения.
 
2.  Чтобы ограничить количество заданий, выполняемых параллельно, измените свойство `hive.exec.parallel.thread.number`. Значение по умолчанию — 8.

    ![Параллельное выполнение в Hive](./media/hdinsight-changing-configs-via-ambari/hive-exec-parallel.png)


### <a name="enable-vectorization"></a>Включение векторизации

Hive обрабатывает данные построчно. Векторизация указывает Hive обрабатывать данные блоками по 1024 строки, а не по одной строке за раз. Векторизация применима только к формату файлов ORC.

1. Чтобы включить векторизированное выполнение запросов, перейдите на вкладку **Configs** (Конфигурации) и найдите параметр `hive.vectorized.execution.enabled`. Для Hive 0.13.0 или более поздних версий значение по умолчанию — true.
 
2. Чтобы включить векторизированное выполнение сжимаемой части запроса, задайте для параметра `hive.vectorized.execution.reduce.enabled` значение true. По умолчанию для этого параметра используется значение false.

    ![Векторизированное выполнение в Hive](./media/hdinsight-changing-configs-via-ambari/hive-vectorized-execution.png)

### <a name="enable-cost-based-optimization-cbo"></a>Включение оптимизации с учетом затрат

По умолчанию Hive выполняет набор правил, чтобы найти один оптимальный план выполнения запроса. Оптимизации с учетом затрат позволяет оценить несколько планов выполнения запроса и назначить затраты для каждого плана, а затем определить наименее затратный план выполнения запроса.

Чтобы включить оптимизацию с учетом затрат, перейдите на вкладку **Configs** (Конфигурации) Hive и найдите `parameter hive.cbo.enable`, затем переключите выключатель в положение **On** (Включено).

![Конфигурация оптимизации с учетом затрат](./media/hdinsight-changing-configs-via-ambari/cbo.png)

Приведенные ниже дополнительные параметры позволяют повысить производительность запросов Hive при использовании оптимизации с учетом затрат.

* `hive.compute.query.using.stats`

    Если задано значение true, служба Hive использует статистические данные, хранящиеся в ее метахранилище, для ответа на такие простые запросы, как `count(*)`.

    ![Статистические данные оптимизации с учетом затрат](./media/hdinsight-changing-configs-via-ambari/hive-compute-query-using-stats.png)

* `hive.stats.fetch.column.stats`

    Статистика по столбцам создается при включении оптимизации с учетом затрат. Hive использует статистику по столбцам, которая хранится в метахранилище, чтобы оптимизировать запросы. Если столбцов много, то получение статистики по столбцам для каждого из них занимает больше времени. Если задано значение false, этот параметр отключает получение статистики по столбцам из метахранилища.

    ![Статистика по столбцам Hive](./media/hdinsight-changing-configs-via-ambari/hive-stats-fetch-column-stats.png)

* `hive.stats.fetch.partition.stats`

    Базовая статистика по секциям, например число строк, размер данных и размер файла, хранится в метахранилище. Если задано значение true, то статистика по секциям получается из метахранилища. Если задано значение false, то размер файла получается из файловой системы, а число строк — из схемы строк.

    ![Статистика по секциям Hive](./media/hdinsight-changing-configs-via-ambari/hive-stats-fetch-partition-stats.png)

### <a name="enable-intermediate-compression"></a>Включение промежуточного сжатия

Задачи сопоставления создают промежуточные файлы, которые используются задачами модуля сжатия. Промежуточное сжатие сокращает размер промежуточных файлов.

Как правило, узким местом заданий Hadoop является ввод-вывод. Сжатие данных может ускорить ввод-вывод и общую передачу данных по сети.

Ниже приведены доступные типы сжатия.

| Формат | Средство | Алгоритм | Расширение файла | Возможность разделения |
| -- | -- | -- | -- | -- |
| GZip | GZip | DEFLATE | .gz | Нет  |
| Bzip2 | Bzip2 | Bzip2 |.bz2 | Yes |
| LZO | Lzop | LZO | .lzo | Да, при индексации. |
| Snappy | Недоступно | Snappy | Snappy | Нет  |

Как правило, поддержка методом сжатия разделения важна. В противном случае будет создано очень мало модулей сопоставления. Если входными данными является текст, то `bzip2` является наилучшим вариантом. Для формата ORC наиболее быстрым методом сжатия является Snappy.

1. Чтобы включить промежуточное сжатие, перейдите на вкладку **Configs** (Конфигурации) Hive, а затем установите для параметра `hive.exec.compress.intermediate` значение true. По умолчанию для этого параметра используется значение false.

    ![Промежуточное сжатие в Hive](./media/hdinsight-changing-configs-via-ambari/hive-exec-compress-intermediate.png)

    > [!NOTE]
    > Чтобы сжимать промежуточные файлы, выберите кодек сжатия с наименьшими затратами мощности ЦП, даже если этот кодек не обеспечивает высокую степень сжатия.

2. Чтобы задать кодек промежуточного сжатия, добавьте пользовательское свойство `mapred.map.output.compression.codec` в файл `hive-site.xml` или `mapred-site.xml`.

3. Вот как можно добавить пользовательский параметр.

    a. Перейдите на вкладку **Configs** (Конфигурации) Hive и выберите вкладку **Advanced** (Дополнительно).

    Б. На вкладке **Advanced** (Дополнительно) найдите и разверните область **Custom hive-site** (Настраиваемый сайт Hive).

    c. Щелкните ссылку **Add Property** (Добавить свойство) в нижней части области "Custom hive-site" (Настраиваемый сайт Hive).

    d. В окне "Add Property" (Добавление свойства) введите ключ `mapred.map.output.compression.codec` и значение `org.apache.hadoop.io.compress.SnappyCodec`.

    д. Щелкните **Добавить**.

    ![Пользовательское свойство Hive](./media/hdinsight-changing-configs-via-ambari/hive-custom-property.png)

    Это позволит сжать промежуточный файл с помощью метода Snappy. После добавления свойство отображается в области "Custom hive-site" (Настраиваемый сайт Hive).

    > [!NOTE]
    > Эта процедура изменяет файл `$HADOOP_HOME/conf/hive-site.xml`.

### <a name="compress-final-output"></a>Сжатие окончательных выходных данных

Окончательные выходные данные Hive также могут быть сжаты.

1. Чтобы включить сжатие окончательных выходных данных Hive, перейдите на вкладку **Configs** (Конфигурации) Hive, а затем установите для параметра `hive.exec.compress.output` значение true. По умолчанию для этого параметра используется значение false.

2. Чтобы выбрать кодек для сжатия выходных данных, добавьте пользовательское свойство `mapred.output.compression.codec` в область "Custom hive-site" (Настраиваемый сайт Hive), как описано на шаге 3 в предыдущем разделе.

    ![Пользовательское свойство Hive](./media/hdinsight-changing-configs-via-ambari/hive-custom-property2.png)

### <a name="enable-speculative-execution"></a>Включение спекулятивного выполнения

При спекулятивном выполнении запускается определенное число повторяющихся задач, чтобы обнаружить и внести в список запрещенных медленные модули отслеживания задач. Это позволяет улучшить общее выполнение задания за счет оптимизации результатов выполнения отдельных задач.

Спекулятивное выполнение не следует включать для длительных задач MapReduce с большим количеством входных данных.

* Чтобы включить спекулятивное выполнение, перейдите на вкладку **Configs** (Конфигурации) Hive, а затем установите для параметра `hive.mapred.reduce.tasks.speculative.execution` значение true. По умолчанию для этого параметра используется значение false.

    ![Спекулятивное выполнение задач сопоставления со сжатием в Hive](./media/hdinsight-changing-configs-via-ambari/hive-mapred-reduce-tasks-speculative-execution.png)

### <a name="tune-dynamic-partitions"></a>Настройка динамических секций

Hive позволяет создавать динамические секции при вставке записей в таблицу без предварительного определения каждой секции. Это мощная функция, хотя она может привести к созданию большого числа секций и большого числа файлов в каждой из секций.

1. Чтобы в Hive использовались динамические секции, параметр `hive.exec.dynamic.partition` должен иметь значение true (это значение по умолчанию).

2. Измените режим динамических секций на *strict* (Строгий). В строгом режиме хотя бы одна секция должна быть статической. Это предотвращает выполнение запросов без фильтра секций в предложении WHERE, то есть *строгий* режим предотвращает выполнение запросов, которые проверяют все секции. Перейдите на вкладку **Configs** (Конфигурации) Hive, а затем задайте для параметра `hive.exec.dynamic.partition.mode` значение **strict** (Строгий). По умолчанию используется значение **nonstrict** (Нестрогий).
 
3. Чтобы ограничить число создаваемых динамических секций, измените параметр hive.exec.max.dynamic.partitions. Его значение по умолчанию — 5000.
 
4. Чтобы ограничить общее число динамических секций на узел, измените параметр `hive.exec.max.dynamic.partitions.pernode`. По умолчанию используется значение 2000.

### <a name="enable-local-mode"></a>Включение локального режима

Локальный режим позволяет Hive выполнять все задачи задания на одном компьютере или даже в одном процессе. Это может повысить производительность запроса, если входные данные имеют небольшой размер и затраты на запуск задач для запросов составляют значительную часть общих затрат на выполнение запроса.

Чтобы включить локальный режим, добавьте параметр `hive.exec.mode.local.auto` в область "Custom hive-site" (Настраиваемый сайт Hive), как описано на шаге 3 в разделе [Включение промежуточного сжатия](#enable-intermediate-compression).

![Автоматический локальный режим выполнения в Hive](./media/hdinsight-changing-configs-via-ambari/hive-exec-mode-local-auto.png)

### <a name="set-single-mapreduce-multigroup-by"></a>Настройка отдельного запроса MapReduce MultiGROUP BY

Если это свойство имеет значение true, то запрос MultiGROUP BY с общими ключами group-by создает отдельное задание MapReduce.  

Чтобы включить этот режим, добавьте параметр `hive.multigroupby.singlereducer` в область "Custom hive-site" (Настраиваемый сайт Hive), как описано на шаге 3 в разделе [Включение промежуточного сжатия](#enable-intermediate-compression).

![Настройка отдельного запроса MapReduce MultiGROUP BY в Hive](./media/hdinsight-changing-configs-via-ambari/hive-multigroupby-singlereducer.png)

### <a name="additional-hive-optimizations"></a>Дополнительные оптимизации Hive

В следующих разделах описаны дополнительные оптимизации Hive, которые можно применить.

#### <a name="join-optimizations"></a>Оптимизация соединений

По умолчанию в Hive используется *соединение в случайном порядке*. В Hive специальные модули сопоставления считывают входные данные и создают пару "ключ-значение" соединения в промежуточном файле. Hadoop сортирует и объединяет эти пары на этапе обработки в случайном порядке. Этот этап обработки в случайном порядке является высокозатратным. Выбор правильного соединения в соответствии с вашими данными может значительно повысить производительность.

| Тип соединения | Если | Как | Параметры Hive | Комментарии |
| -- | -- | -- | -- | -- |
| Соединение в случайном порядке. | <ul><li>Выбор по умолчанию.</li><li>Всегда работает.</li></ul> | <ul><li>Считывает данные из части одной из таблиц.</li><li>Объединяет и сортирует данные по ключу соединения.</li><li>Отправляет один контейнер в каждый модуль сжатия.</li><li>Соединение выполняется на стороне модуля сжатия.</li></ul> | Не требуется значительная настройка Hive. | Работает каждый раз. |
| Соединение с сопоставлением | <ul><li>В памяти может поместиться одна таблица.</li></ul> | <ul><li>Небольшая таблица считывается в хэш-таблицу памяти.</li><li>Осуществляется потоковая передача посредством части большого файла.</li><li>Выполняется соединение каждой записи из хэш-таблицы.</li><li>Соединение выполняет исключительно модуль сопоставления.</li></ul> | `hive.auto.confvert.join=true` | Очень быстрый метод, но ограниченный. |
| Сортировка, слияние, объединение | Если обе таблицы: <ul><li>отсортированы одинаково;</li><li>одинаково разделены на контейнеры (объединены);</li><li>соединяются по отсортированному или объединенному столбцу.</li></ul> | Каждый процесс: <ul><li>считывает контейнер из каждой таблицы;</li><li>обрабатывает строку с наименьшим значением.</li></ul> | `hive.auto.convert.sortmerge.join=true` | Очень эффективный метод. |

#### <a name="execution-engine-optimizations"></a>Оптимизации подсистемы выполнения

Дополнительные рекомендации по оптимизации подсистемы выполнения Hive.

| Параметр | Рекомендуется | Значение по умолчанию HDInsight |
| -- | -- | -- |
| `hive.mapjoin.hybridgrace.hashtable` | True — более безопасное и медленное выполнение, false — более быстрое выполнение. | false |
| `tez.am.resource.memory.mb` | Верхняя граница составляет 4 ГБ для большинства сценариев. | Автоматическая настройка. |
| `tez.session.am.dag.submit.timeout.secs` | Более 300 | 300 |
| `tez.am.container.idle.release-timeout-min.millis` | Более 20 000 | 10 000 |
| `tez.am.container.idle.release-timeout-max.millis` | Более 40 000 | 20 000 |

## <a name="pig-optimization"></a>Оптимизация Pig

С помощью пользовательского веб-интерфейса Ambari можно настроить свойства Pig, чтобы настроить запросы Pig. Непосредственное изменение свойств Pig из Ambari изменяет свойства Pig в файле `/etc/pig/2.4.2.0-258.0/pig.properties`.

1. Чтобы изменить свойства Pig, перейдите на вкладку **Configs** (Конфигурации) Pig, а затем разверните область **Advanced pig-properties** (Дополнительные свойства Pig).

2. Найдите, раскомментируйте и измените значение свойства, которое требуется изменить.

3. Щелкните **Save** (Сохранить) в верхней правой части окна, чтобы сохранить новое значение. Изменение некоторых свойств может потребовать перезапуска службы.

    ![Дополнительные свойства Pig](./media/hdinsight-changing-configs-via-ambari/advanced-pig-properties.png)
 
> [!NOTE]
> Любые параметры уровня сеанса переопределяют значения свойств в файле `pig.properties`.

### <a name="tune-execution-engine"></a>Настройка подсистемы выполнения

Доступны две подсистемы выполнения для выполнения сценариев Pig: MapReduce и Tez. Tez — это оптимизированная подсистема, она работает намного быстрее, чем MapReduce.

1. Чтобы изменить подсистему выполнения, в области **Advanced pig-properties** (Дополнительные свойства Pig) найдите свойство `exectype`.

2. По умолчанию используется значение **MapReduce**. Измените его на **Tez**.


### <a name="enable-local-mode"></a>Включение локального режима

Как и в Hive, локальный режим используется для ускорения выполнения заданий со сравнительно небольшими объемами данных.

1. Чтобы включить локальный режим, для параметра `pig.auto.local.enabled` задайте значение **true**. По умолчанию для этого параметра используется значение false.

2. Задания с размером входных данных меньшим, чем значение свойства `pig.auto.local.input.maxbytes`, считаются небольшими заданиями. Значение этого свойства по умолчанию — 1 ГБ.


### <a name="copy-user-jar-cache"></a>Копирование кэша JAR-файлов пользователя

Pig копирует JAR-файлы, необходимые для определяемых пользователем функций, в распределенный кэш, чтобы сделать их доступными для узлов задач. Эти JAR-файлы не меняются часто. Если параметр `pig.user.cache.enabled` включен, JAR-файлы можно поместить в кэш для повторного использования заданиями, выполняемыми тем же пользователем. Это немного повышает производительность заданий.

1. Чтобы включить эту функцию, задайте для параметра `pig.user.cache.enabled` значение true. Его значение по умолчанию — false.

2. Чтобы задать базовый путь к кэшированным JAR-файлам, задайте его в параметре `pig.user.cache.location`. Значение по умолчанию — `/tmp`.


### <a name="optimize-performance-with-memory-settings"></a>Оптимизация производительности с помощью параметров памяти

Приведенные ниже параметры памяти позволяют оптимизировать производительность сценариев Pig.

* `pig.cachedbag.memusage`: объем памяти, выделяемой для контейнера. Контейнер представляет собой набор кортежей. Кортеж — это упорядоченный набор полей, а поле — это фрагмент данных. Если данные в контейнере превышают выделенный объем памяти, они сбрасываются на диск. Значение по умолчанию — 0,2. Это означает 20 процентов доступной памяти. Эта память используется совместно всеми контейнерами в приложении.

* `pig.spill.size.threshold`: контейнеры, чей размер превышает это пороговое значение размера сброса (в байтах), сбрасываются на диск. Значение по умолчанию — 5 МБ.


### <a name="compress-temporary-files"></a>Сжатие временных файлов

Pig создает временные файлы во время выполнения заданий. Сжатие временных файлов позволяет повысить производительность дисковых операций чтения и записи файлов. Для сжатия временных файлов можно использовать следующие параметры.

* `pig.tmpfilecompression`: если имеет значение true, включает сжатие временных файлов. По умолчанию для этого параметра используется значение false.

* `pig.tmpfilecompression.codec`: кодек для сжатия временных файлов. Рекомендуемые кодеки — LZO и Snappy, так как они требуют меньше ресурсов ЦП.

### <a name="enable-split-combining"></a>Включение объединения небольших файлов

Если эта функция включена, небольшие файлы объединяются, чтоб уменьшить число задач сопоставления. Это повышает эффективность заданий с множеством небольших файлов. Чтобы включить эту функцию, задайте для параметра `pig.noSplitCombination` значение true. По умолчанию для этого параметра используется значение false.


### <a name="tune-mappers"></a>Настройка модулей сопоставления

Число модулей сопоставления можно определить, изменив свойство `pig.maxCombinedSplitSize`. Оно задает размер данных, обрабатываемых отдельной задачей сопоставления. Значение по умолчанию равно размеру блока по умолчанию в файловой системе. Увеличение этого значения уменьшит количество задач сопоставления.


### <a name="tune-reducers"></a>Настройка модулей сжатия

Количество модулей сжатия вычисляется на основе параметра `pig.exec.reducers.bytes.per.reducer`. Этот параметр задает количество байтов, обрабатываемых модулем сжатия. По умолчанию он имеет значение 1 ГБ. Чтобы задать максимальное число модулей сжатия, задайте для свойства `pig.exec.reducers.max` соответствующее значение. По умолчанию оно имеет значение 999.


## <a name="hbase-optimization-with-the-ambari-web-ui"></a>Оптимизация HBase с помощью пользовательского веб-интерфейса Ambari

Изменить конфигурацию HBase можно на вкладке **HBase Configs** (Конфигурации HBase). В следующих разделах описаны некоторые важные настройки, которые влияют на производительность HBase.

### <a name="set-hbaseheapsize"></a>Настройка параметра HBASE_HEAPSIZE

Размер кучи HBase определяет максимальный объем кучи в мегабайтах для сервера *региона* и *главного* сервера. Значение по умолчанию — 1000 МБ. Этот параметр должен быть настроен в соответствии с рабочей нагрузкой кластера.

1. Чтобы изменить этот параметр, перейдите в область **Advanced HBase-env** (Дополнительные параметры среды HBase) на вкладке **Configs** (Конфигурации) HBase, а затем найдите параметр `HBASE_HEAPSIZE`.

2. Измените значение по умолчанию на 5000 МБ.

    ![HBASE_HEAPSIZE](./media/hdinsight-changing-configs-via-ambari/hbase-heapsize.png)


### <a name="optimize-read-heavy-workloads"></a>Оптимизация рабочих нагрузок с интенсивными операциями чтения

Приведенные ниже настройки важны для повышения производительности рабочих нагрузок с интенсивными операциями чтения.

#### <a name="block-cache-size"></a>Размер кэша блоков

Кэш блоков является кэшем чтения. Его размер задает параметр `hfile.block.cache.size`. Его значение по умолчанию — 0,4. Это означает 40 % от общего объема памяти сервера региона. Чем больше размер кэша блоков, тем быстрее будут выполняться операции произвольного чтения.

1. Чтобы изменить этот параметр, перейдите на вкладку **Settings** (Параметры) на вкладке **Configs** (Конфигурации) HBase, а затем найдите параметр **% of RegionServer Allocated to Read Buffers** (% памяти сервера региона, выделяемой для буферов чтения).

    ![Размер кэша блоков HBase](./media/hdinsight-changing-configs-via-ambari/hbase-block-cache-size.png)
 
2. Чтобы изменить значение, щелкните значок **Edit** (Изменить).


#### <a name="memstore-size"></a>Размер Memstore

Все изменения сохраняются в буфере памяти, который называется *Memstore*. Это увеличивает общий объем данных, которые могут быть записаны на диск отдельной операцией, и ускоряет последующий доступ к последним изменениям. Размер Memstore определяют следующие два параметра:

* `hbase.regionserver.global.memstore.UpperLimit`: определяет максимальный процент памяти сервера региона, доступной для объединенного буфера Memstore;

* `hbase.regionserver.global.memstore.LowerLimit`: определяет минимальный процент памяти сервера региона, доступной для объединенного буфера Memstore.

Чтобы оптимизировать операции произвольного чтения, можно уменьшить максимальный и минимальный размеры Memstore.


#### <a name="number-of-rows-fetched-when-scanning-from-disk"></a>Число получаемых строк при проверке данных на диске

Параметр `hbase.client.scanner.caching` определяет количество строк, считываемых с диска, когда для сканера вызывается метод `next`.  По умолчанию используется значение 100. Чем больше значение этого параметра, тем меньше удаленных вызовов выполняется от клиента к серверу региона, что позволяет ускорить проверку. Тем не менее это также увеличит использование памяти на клиенте.

![Число получаемых строк в HBase](./media/hdinsight-changing-configs-via-ambari/hbase-num-rows-fetched.png)

> [!IMPORTANT]
> Не задавайте значение таким образом, чтобы время между вызовом следующего метода для сканера превышало время ожидания сканера. Время ожидания сканера определяет свойство `hbase.regionserver.lease.period`.


### <a name="optimize-write-heavy-workloads"></a>Оптимизация рабочих нагрузок с интенсивными операциями записи

Приведенные ниже настройки важны для повышения производительности рабочих нагрузок с интенсивными операциями записи.


#### <a name="maximum-region-file-size"></a>Максимальный размер файла для региона

HBase хранит данные во внутреннем формате файла, *HFile*. Свойство `hbase.hregion.max.filesize` определяет размер одного файла HFile для региона.  Регион разделяется на два региона, если сумма размеров всех файлов HFile в регионе превышает значение этого параметра.
 
![Максимальный размер файла для региона в HBase](./media/hdinsight-changing-configs-via-ambari/hbase-hregion-max-filesize.png)

Чем больше размер файла для региона, тем меньше число разделений. Можно увеличить размер файла, чтобы определить значение, обеспечивающее максимальную производительность записи.


#### <a name="avoid-update-blocking"></a>Избегание блокировки обновлений

* Свойство `hbase.hregion.memstore.flush.size` определяет размер, по достижении которого содержимое Memstore освобождается на диск. Его значение по умолчанию составляет 128 МБ.

* Множитель блокирования для региона в Hbase определяет параметр `hbase.hregion.memstore.block.multiplier`. Значение по умолчанию — 4. Максимально допустимое значение равно 8.

* HBase блокирует обновления, если Memstore содержит (`hbase.hregion.memstore.flush.size` * `hbase.hregion.memstore.block.multiplier`) байтов.

    При значениях размера освобождения и множителя блокирования по умолчанию обновления блокируются, когда размер Memstore составляет 128 * 4 = 512 МБ. Чтобы уменьшить количество блокируемых обновлений, увеличьте значение `hbase.hregion.memstore.block.multiplier`.

![Множитель блокирования для региона в HBase](./media/hdinsight-changing-configs-via-ambari/hbase-hregion-memstore-block-multiplier.png)


### <a name="define-memstore-size"></a>Определение размера Memstore

Размер Memstore определяют параметры `hbase.regionserver.global.memstore.UpperLimit` и `hbase.regionserver.global.memstore.LowerLimit`. Если задать для них одинаковое значение, это уменьшит паузы между операциям записи (а также приведет к более частому сбросу данных на диск) и повысит производительность записи.


### <a name="set-memstore-local-allocation-buffer"></a>Настройка локального буфера выделения Memstore

Использование локального буфера выделения Memstore определяет свойство `hbase.hregion.memstore.mslab.enabled`. Если эта функция включена (параметр имеет значение true), она предотвращает фрагментацию кучи во время операций записи большого объема данных. По умолчанию используется значение true.
 
![hbase.hregion.memstore.mslab.enabled](./media/hdinsight-changing-configs-via-ambari/hbase-hregion-memstore-mslab-enabled.png)


## <a name="next-steps"></a>Дополнительная информация

* [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](hdinsight-hadoop-manage-ambari.md)
* [Ambari REST API](hdinsight-hadoop-manage-ambari-rest-api.md)
