---
title: Потоковая передача в нужном масштабе в Azure HDInsight | Документация Майкрософт
description: Инструкции по использованию потоковой передачи данных с масштабируемыми кластерами HDInsight.
services: hdinsight
documentationcenter: ''
tags: azure-portal
author: raghavmohan
manager: jhubbard
editor: cgronlun
ms.assetid: ''
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.date: 01/19/2018
ms.author: ramoha
ms.openlocfilehash: 4f1a0873ccdffde7e3567d7e3c50336b20749116
ms.sourcegitcommit: 9cdd83256b82e664bd36991d78f87ea1e56827cd
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2018
ms.locfileid: "31408676"
---
# <a name="streaming-at-scale-in-hdinsight"></a>Потоковая передача в нужном масштабе в HDInsight

Решения для больших данных в реальном времени действуют на передаваемые данные. Как правило эти данные наиболее полезны во время поступления. Если входной поток данных становится большим, чем можно обработать в данный момент, может потребоваться регулирование ресурсов. Кроме того, кластер HDInsight может масштабироваться путем добавления узлов по запросу в соответствии с требованиями решения потоковой передачи.

В приложении потоковой передачи один или несколько источников данных создают события (иногда миллионы в секунду), которые нужно быстро принять без потери полезной информации. Входящие события обрабатываются с помощью *потоковой буферизации*, называемой также *очередью событий*, такими службами как [Kafka](kafka/apache-kafka-introduction.md) или [концентраторы событий](https://azure.microsoft.com/services/event-hubs/). После сбора событий можно проанализировать данные в пределах уровня *обработки потока* с помощью системы аналитики в реальном времени, такой как [Storm](storm/apache-storm-overview.md) или [потоковая передача Spark](spark/apache-spark-streaming-overview.md). Обработанные данные могут храниться в долгосрочном хранилище данных, таком как [Azure Data Lake Store](https://azure.microsoft.com/services/data-lake-store/) и отображаться в режиме реального времени на панели мониторинга бизнес-аналитики, такой как [Power BI](https://powerbi.microsoft.com), Tableau или настраиваемой веб-странице.

![Шаблоны потоковой передачи HDInsight](./media/hdinsight-streaming-at-scale-overview/HDInsight-streaming-patterns.png)

## <a name="apache-kafka"></a>Apache Kafka

Apache Kafka предоставляет службу очередей сообщений с высокой пропускной способностью и низкими показателями задержки и теперь является частью набора программного обеспечения с открытым кодом Apache. Kafka использует модель обмена сообщениями с помощью публикаций и подписки и безопасно сохраняет потоки секционированных данных в распределенном реплицируемом кластере. С увеличением пропускной способности Kafka линейно масштабируется.

Дополнительные сведения см. в статье по [началу работы с Apache Kafka в HDInsight](kafka/apache-kafka-introduction.md).

## <a name="apache-storm"></a>Apache Storm

Apache Storm — это распределенная отказоустойчивая вычислительная система с открытым кодом, оптимизированная для обработки данных в реальном времени с использованием Hadoop. Основная единица данных входящего события — кортеж, который является неизменяемым набором пар "ключ — значение". Неограниченная последовательность кортежей формирует поток, который поступает из spout. Spout помещает источник потоковой передачи данных (например, Kafka) в оболочку и выдает кортежи. Топология Storm — это последовательность преобразований в этих потоках.

Дополнительные сведения см. в статье [Основные сведения об Apache Storm в Azure HDInsight](storm/apache-storm-overview.md).

## <a name="spark-streaming"></a>Потоковая передача Spark

Потоковая передача Spark — это расширение Spark, которое позволяет повторно использовать тот же код, который использовался для пакетной обработки. Вы можете объединить пакетные и интерактивные запросы в одном приложении. В отличие от Storm потоковая передача Spark предоставляет семантику обработки с отслеживанием состояния только один раз. При использовании в сочетании с [Kafka Direct API ](http://spark.apache.org/docs/latest/streaming-kafka-integration.html), гарантирующим, что решение потоковой передачи Spark получает все данные Kafka только один раз, можно добиться соответствующей гарантии. Одним из преимуществ потоковой передачи Spark является ее отказоустойчивость, быстрое восстановление узлов с ошибками, когда несколько узлов используются в кластере.

Дополнительные сведения см. в статье [Общие сведения о потоковой передаче Spark](hdinsight-spark-streaming-overview.md).

## <a name="scaling-a-cluster"></a>Масштабирование кластера

Количество узлов указывается во время создания кластера. Тем не менее рабочая нагрузка может меняться, и тогда возникает необходимость увеличить или уменьшить размер кластера. Все кластеры HDInsight позволяют [изменять количество узлов в кластере](hdinsight-administer-use-management-portal.md#scale-clusters). Кластеры Spark можно удалить без потери данных, так как все данные хранятся в службе хранилища Azure или Data Lake Store.

В разделении технологий есть преимущества. Например, Kafka — это технология буферизации событий, поэтому в ней есть большое количество операций ввода-вывода и не требуется большой вычислительной мощности. Для сравнения обработчики потоков, например потоковая передача Spark, потребляют много ресурсов и им требуются более мощные виртуальные машины. Если эти технологии разделены по разным кластерам, их можно масштабировать независимо друг от друга и оптимизировать использование виртуальных машин.

### <a name="scale-the-stream-buffering-layer"></a>Масштабирование на уровне буферизации потоковой передачи

И технологии буферизации потоковой передачи концентраторов событий, и Kafka используют секционирование, а объекты-получатели читают эти разделы. Масштабирование пропускной способности ввода требует увеличения числа секций, что в свою очередь повышает уровень параллелизма. В концентраторах событий после развертывания невозможно изменить количество секций, поэтому необходимо начинать, представляя целевой масштаб. С помощью Kafka можно [добавлять секции](https://kafka.apache.org/documentation.html#basic_ops_cluster_expansion) даже когда Kafka обрабатывает данные. Kafka предоставляет средство для переназначения секций, `kafka-reassign-partitions.sh`. HDInsight предоставляет [средство перераспределения реплик секции](https://github.com/hdinsight/hdinsight-kafka-tools), `rebalance_rackaware.py`. Средство перераспределения вызывает средство `kafka-reassign-partitions.sh` таким образом, что каждая реплика помещается в отдельный домен сбоя и домен обновления, оповещая стойку Kafka и увеличивая отказоустойчивость.

### <a name="scale-the-stream-processing-layer"></a>Масштабирование на уровне обработки потоковой передачи

И Apache Storm, и потоковая передача Spark поддерживают добавление рабочих узлов в кластеры даже при обработке данных.

Чтобы воспользоваться преимуществами новых узлов, добавленных с помощью масштабирования Storm, необходимо повторно сбалансировать топологии Storm, запущенные до увеличения размера кластера. Это перераспределение можно выполнить с помощью пользовательского веб-интерфейса Storm или CLI. Дополнительные сведения см. в [документации по Apache Storm.](http://storm.apache.org/documentation/Understanding-the-parallelism-of-a-Storm-topology.html)

В Apache Spark используется три ключевых параметра при настройке среды в зависимости от требований к приложению: `spark.executor.instances`, `spark.executor.cores` и `spark.executor.memory`. *Исполнитель* — это процесс, запущенный для приложения Spark. Он выполняется на рабочем узле и отвечает за выполнение задач этого приложения. Число исполнителей по умолчанию и размеры исполнителя для каждого кластера определяются с учетом числа рабочих узлов и размера каждого рабочего узла. Эти числа хранятся в файле `spark-defaults.conf` на каждом головном узле кластера.

Эти три параметра можно настроить на уровне кластера (для всех приложений, работающих в кластере) или для каждого отдельного приложения. Дополнительные сведения см. в статье [Управление ресурсами для кластера Apache Spark в Azure HDInsight](spark/apache-spark-resource-manager.md).

## <a name="next-steps"></a>Дополнительная информация

* [Начало работы с Apache Storm в HDInsight с использованием примеров storm-starter](storm/apache-storm-tutorial-get-started-linux.md)
* [Примеры топологий и компонентов Storm для Apache Storm в HDInsight](storm/apache-storm-example-topology.md)
* [Общие сведения о Spark в HDInsight](spark/apache-spark-overview.md)
* [Приступая к работе с Apache Kafka в HDInsig](kafka/apache-kafka-get-started.md)
