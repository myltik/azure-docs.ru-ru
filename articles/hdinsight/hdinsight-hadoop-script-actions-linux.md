---
title: Разработка действий сценариев с помощью кластера HDInsight под управлением Linux (Azure) | Документация Майкрософт
description: Узнайте, как настраивать кластеры HDInsight под управлением Linux с помощью bash-сценариев. Действия сценариев в HDInsight позволяют выполнять сценарии во время или после создания кластера. С помощью сценария можно изменить параметры конфигурации кластера или установить дополнительное программное обеспечение.
services: hdinsight
documentationcenter: ''
author: Blackmist
manager: cgronlun
editor: cgronlun
ms.assetid: cf4c89cd-f7da-4a10-857f-838004965d3e
ms.service: hdinsight
ms.custom: hdinsightactive
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: conceptual
ms.date: 04/10/2018
ms.author: larryfr
ms.openlocfilehash: d5df67021e997df3a6344701f50be4871a11386d
ms.sourcegitcommit: 9cdd83256b82e664bd36991d78f87ea1e56827cd
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2018
---
# <a name="script-action-development-with-hdinsight"></a>Разработка действий сценариев с помощью HDInsight

Узнайте, как настроить кластер HDInsight с помощью сценариев Bash. Действия сценариев предназначены для настройки HDInsight во время или после создания кластера.

> [!IMPORTANT]
> Для выполнения действий, описанных в этом документе, необходим кластер HDInsight под управлением Linux. Linux — это единственная операционная система, используемая для работы с HDInsight 3.4 или более поздних версий. Дополнительные сведения см. в разделе [Приближается дата прекращения сопровождения HDI версии 3.3](hdinsight-component-versioning.md#hdinsight-windows-retirement).

## <a name="what-are-script-actions"></a>Что такое действия сценариев?

Действия сценариев — это сценарии Bash, которые Azure выполняет на узлах кластера, чтобы вносить изменения в конфигурацию или устанавливать программное обеспечение. Действие сценария выполняется от имени привилегированного пользователя и предоставляет права полного доступа к узлам кластера.

Действия сценариев могут применяться следующими способами:

| Этот метод используется для применения сценария… | При создании кластера… | В работающем кластере… |
| --- |:---:|:---:|
| Портал Azure |✓ |✓ |
| Azure PowerShell |✓ |✓ |
| Azure CLI 1.0 |&nbsp; |✓ |
| Пакет SDK для HDInsight .NET |✓ |✓ |
| Шаблон Azure Resource Manager |✓ |&nbsp; |

Дополнительные сведения об использовании этих методов см. в статье [Настройка кластеров HDInsight с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md).

## <a name="bestPracticeScripting"></a>Рекомендации по разработке сценариев

При разработке пользовательского сценария для кластера HDInsight следует иметь в виду некоторые рекомендации.

* [Выбор версии Hadoop](#bPS1)
* [Выбор версии ОС](#bps10)
* [Предоставление стабильных ссылок на ресурсы сценария](#bPS2)
* [Использование предварительно скомпилированных ресурсов](#bPS4)
* [Обеспечение идемпотентности сценария настройки кластера](#bPS3)
* [Обеспечение высокого уровня доступности кластера](#bPS5)
* [Настройка пользовательских компонентов для использования хранилища больших двоичных объектов Azure](#bPS6)
* [Запись информации в STDOUT и STDERR](#bPS7)
* [Сохранение файлов в формате ASCII с использованием LF в качестве символа завершения строки](#bps8)
* [Использование логики повтора для восстановления после временных ошибок](#bps9)

> [!IMPORTANT]
> Действия сценария должны завершиться в течение 60 минут. В противном случае процесс завершиться ошибкой. Во время подготовки узла данный сценарий выполняется одновременно с другими процессами установки и настройки. Конкуренция за ресурсы, такие как ЦП или пропускная способность сети, может привести к затягиванию выполнения сценария по сравнению со временем его выполнения в среде разработки.

### <a name="bPS1"></a>Выбор целевой версии Hadoop

В различных версиях HDInsight используются различные версии служб Hadoop и компонентов. Если сценарий предполагает наличие определенной версии службы или компонента, то такой сценарий следует использовать только с версией HDInsight, включающей необходимые компоненты. Сведения о версиях компонентов, включенных в HDInsight, можно найти в документе [Версии компонентов HDInsight](hdinsight-component-versioning.md) .

### <a name="bps10"></a> Выбор версии ОС

HDInsight под управлением Linux основан на дистрибутиве Ubuntu под управлением Linux. Для разных версий HDInsight используются разные версии Ubuntu. Это может изменить поведение сценария. Например, HDInsight версии 3.4 и более ранних версий основан на версии Ubuntu, в которой используется Upstart. Версия 3.5 и более поздние версии основана на Ubuntu версии 16.04, в которой используется Systemd. Systemd и Upstart используют разные команды, поэтому сценарий нужно написать таким образом, чтобы он был совместим и с тем, и с другим.

Еще одно важное различие между HDInsight версии 3.4 и 3.5 заключается в том, что теперь `JAVA_HOME` указывает на Java 8.

Чтобы проверить версию операционной системы, используйте `lsb_release`. В следующем коде показано, как определить версию Ubuntu (14 или 16), в которой выполняется сценарий:

```bash
OS_VERSION=$(lsb_release -sr)
if [[ $OS_VERSION == 14* ]]; then
    echo "OS verion is $OS_VERSION. Using hue-binaries-14-04."
    HUE_TARFILE=hue-binaries-14-04.tgz
elif [[ $OS_VERSION == 16* ]]; then
    echo "OS verion is $OS_VERSION. Using hue-binaries-16-04."
    HUE_TARFILE=hue-binaries-16-04.tgz
fi
...
if [[ $OS_VERSION == 16* ]]; then
    echo "Using systemd configuration"
    systemctl daemon-reload
    systemctl stop webwasb.service    
    systemctl start webwasb.service
else
    echo "Using upstart configuration"
    initctl reload-configuration
    stop webwasb
    start webwasb
fi
...
if [[ $OS_VERSION == 14* ]]; then
    export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64
elif [[ $OS_VERSION == 16* ]]; then
    export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
fi
```

Полный скрипт, который содержит эти фрагменты кода, находится здесь: https://hdiconfigactions.blob.core.windows.net/linuxhueconfigactionv02/install-hue-uber-v02.sh.

Сведения о версии Ubuntu, используемой в HDInsight, см. в документе [HDInsight component version](hdinsight-component-versioning.md) (Версия компонента HDInsight).

Сведения о различиях между Systemd и Upstart см. в статье [Systemd for Upstart users](https://wiki.ubuntu.com/SystemdForUpstartUsers) (Systemd для пользователей Upstart).

### <a name="bPS2"></a>Предоставление стабильных ссылок на ресурсы сценария

Сценарии и связанные ресурсы должны оставаться доступными на протяжении жизненного цикла кластера. Эти ресурсы необходимы, если во время операций масштабирования в кластер добавляются новые узлы.

Мы советуем скачивать и архивировать все данные в свою учетную запись хранения Azure.

> [!IMPORTANT]
> Используемая учетная запись хранения должна быть учетной записью хранения по умолчанию для кластера или общедоступным и открытым только для чтения контейнером в другой учетной записи хранения.

К слову, примеры, предоставляемые корпорацией Майкрософт, хранятся в учетной записи хранения по адресу [https://hdiconfigactions.blob.core.windows.net/](https://hdiconfigactions.blob.core.windows.net/). Это открытый и доступный только для чтения контейнер, который поддерживает команда HDInsight.

### <a name="bPS4"></a>Использование предварительно скомпилированных ресурсов

Чтобы сократить время выполнения сценария, избегайте операций, компилирующих ресурсы из исходного кода. Например, заранее скомпилируйте и сохраните ресурсы в BLOB-объекте учетной записи хранения Azure в том же центре обработки данных, что и кластер HDInsight.

### <a name="bPS3"></a>Обеспечение идемпотентности сценария настройки кластера

Сценарии должны быть идемпотентными. Имеется в виду, что при многократном выполнении в каждом случае сценарий должен обеспечивать возврат кластера к одному и тому же состоянию.

Например, сценарий, который изменяет файлы конфигурации, не должен добавлять повторяющиеся записи в случае многократного выполнения.

### <a name="bPS5"></a>Обеспечение высокого уровня доступности кластера

В кластерах HDInsight под управлением Linux есть два головных узла, активных в пределах кластера. Действия сценария выполняются на обоих узлах. Если устанавливаемым компонентам требуется только один головной узел, не устанавливайте компоненты не обоих головных узлах кластера.

> [!IMPORTANT]
> Службы, устанавливаемые вместе с HDInsight, выполняют отработку отказа между двумя узлами. Эта функциональность не распространяется на пользовательские компоненты, устанавливаемые при выполнении действий сценария. Если требуется высокий уровень доступности пользовательских компонентов, необходимо реализовать собственный механизм отработки отказа.

### <a name="bPS6"></a>Настройка пользовательских компонентов для использования хранилища больших двоичных объектов Azure

Компоненты, устанавливаемые на кластере, могут по умолчанию использовать хранилище распределенной файловой системы Hadoop (HDFS). В качестве хранилища по умолчанию HDInsight использует хранилище Azure или Data Lake Store. Это обеспечивает совместимую с HDFS файловую систему, которая сохраняет данные даже после удаления кластера. Может потребоваться настроить устанавливаемые компоненты для использования WASB или ADL вместо HDFS.

Для большинства операций не требуется указывать файловую систему. Пример ниже копирует файл giraph-examples.jar из локальной файловой системы в хранилище кластера.

```bash
hdfs dfs -put /usr/hdp/current/giraph/giraph-examples.jar /example/jars/
```

В этом примере команда `hdfs` прозрачно использует хранилище кластера по умолчанию. Для некоторых операций может потребоваться указать URI. Например, `adl:///example/jars` для Data Lake Store или `wasb:///example/jars` для хранилища Azure.

### <a name="bPS7"></a>Запись информации в STDOUT и STDERR

HDInsight заносит в журнал выходные данные сценария, которые записываются в поток STDOUT и STDERR. Эти данные можно просмотреть с помощью веб-интерфейса Ambari.

> [!NOTE]
> Веб-интерфейс Ambari доступен только в том случае, если кластер успешно создан. Если во время создания кластера используется действие сценария и создание завершается ошибкой, ознакомьтесь с другими способами доступа к данным журнала в разделе по устранению неполадок [Настройка кластеров HDInsight с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md#troubleshooting) .

Большинство программ и пакетов установки добавляют данные в STDOUT и STDERR по умолчанию, однако вам может потребоваться добавить дополнительные записи в журнал. Для отправки текста в STDOUT используйте `echo`. Например: 

```bash
echo "Getting ready to install Foo"
```

По умолчанию ключевое слово `echo` отправляет строку в STDOUT. Чтобы направить строку в STDERR, добавьте `>&2` перед `echo`. Например: 

```bash
>&2 echo "An error occurred installing Foo"
```

Информация, записываемая в STDOUT, перенаправляется STDERR (2). Дополнительные сведения о перенаправлении операций ввода и вывода см. здесь: [http://www.tldp.org/LDP/abs/html/io-redirection.html](http://www.tldp.org/LDP/abs/html/io-redirection.html).

Дополнительные сведения о просмотре журналов, созданных действиями сценариев, см. в статье [Настройка кластеров HDInsight с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md#troubleshooting).

### <a name="bps8"></a> Сохранение файлов в формате ASCII с использованием LF в качестве символа завершения строки

Сценарии Bash должны храниться в формате ASCII. Для завершения строк в этом файле используется символ LF. Если в файлах используется кодировка UTF-8 или используется CRLF в качестве конца строки, сценарий может завершиться следующей ошибкой:

```
$'\r': command not found
line 1: #!/usr/bin/env: No such file or directory
```

### <a name="bps9"></a> Использование логики повтора для восстановления после временных ошибок

При скачивании файлов, установке пакетов с помощью apt-get или других действиях, которые передают данные через Интернет, операция может завершиться ошибкой из-за временной ошибки сети. Например, удаленный ресурс, с которым вы обмениваетесь данными, может находиться в процессе отработки отказа на резервный узел.

Чтобы сделать свой сценарий устойчивым к временным ошибкам, можно реализовать логику повтора. Приведенная ниже функция демонстрирует реализацию логику повтора. Она повторяет операцию три раза до сбоя.

```bash
#retry
MAXATTEMPTS=3

retry() {
    local -r CMD="$@"
    local -i ATTMEPTNUM=1
    local -i RETRYINTERVAL=2

    until $CMD
    do
        if (( ATTMEPTNUM == MAXATTEMPTS ))
        then
                echo "Attempt $ATTMEPTNUM failed. no more attempts left."
                return 1
        else
                echo "Attempt $ATTMEPTNUM failed! Retrying in $RETRYINTERVAL seconds..."
                sleep $(( RETRYINTERVAL ))
                ATTMEPTNUM=$ATTMEPTNUM+1
        fi
    done
}
```

В следующих примерах показано, как использовать эту функцию.

```bash
retry ls -ltr foo

retry wget -O ./tmpfile.sh https://hdiconfigactions.blob.core.windows.net/linuxhueconfigactionv02/install-hue-uber-v02.sh
```

## <a name="helpermethods"></a>Вспомогательные методы для пользовательских сценариев

Вспомогательные методы действий сценариев — это служебные программы, которые можно использовать при создании пользовательских сценариев. Эти методы содержатся в скрипте [https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh](https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh). Чтобы скачать и использовать их как часть сценария, используйте следующую команду:

```bash
# Import the helper method module.
wget -O /tmp/HDInsightUtilities-v01.sh -q https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh && source /tmp/HDInsightUtilities-v01.sh && rm -f /tmp/HDInsightUtilities-v01.sh
```

Эта команда открывает доступ к следующим вспомогательным приложениям, доступным для использования в сценарии:

| Назначение вспомогательного приложения | ОПИСАНИЕ |
| --- | --- |
| `download_file SOURCEURL DESTFILEPATH [OVERWRITE]` |Скачивает файл из исходного универсального кода ресурса (URI) и сохраняет его в указанное расположение. По умолчанию существующий файл не перезаписывается. |
| `untar_file TARFILE DESTDIR` |Извлекает TAR-файл (с помощью `-xf`) в папку назначения. |
| `test_is_headnode` |При запуске на головном узле кластера возвращает значение 1, в противном случае — 0. |
| `test_is_datanode` |Если текущий узел является узлом данных (рабочим узлом), то возвращается значение 1, в противном случае — 0. |
| `test_is_first_datanode` |Если текущий узел является первым узлом данных (рабочим узлом с именем workernode0), возвращается значение 1, в противном случае — 0. |
| `get_headnodes` |Возвращает полное доменное имя головных узлов в кластере. Имена содержат разделители-запятые. При возникновении ошибки возвращается пустая строка. |
| `get_primary_headnode` |Возвращает полное доменное имя основного головного узла. При возникновении ошибки возвращается пустая строка. |
| `get_secondary_headnode` |Возвращает полное доменное имя дополнительного головного узла. При возникновении ошибки возвращается пустая строка. |
| `get_primary_headnode_number` |Возвращает числовой суффикс основного головного узла. При возникновении ошибки возвращается пустая строка. |
| `get_secondary_headnode_number` |Возвращает числовой суффикс дополнительного головного узла. При возникновении ошибки возвращается пустая строка. |

## <a name="commonusage"></a>Общие варианты использования

В этом разделе содержится руководство по реализации некоторых общих вариантов использования, которые могут понадобиться при написании пользовательского сценария.

### <a name="passing-parameters-to-a-script"></a>Передача параметров в сценарий

В некоторых случаях для сценария требуется указывать параметры. Например, при использовании интерфейса Ambari REST API может потребоваться пароль администратора кластера.

Параметры, передаваемые в сценарий, называются *позиционными параметрами*, т. е. `$1` соответствует первому параметру, `$2` — второму и т.д. Значение `$0` содержит имя самого сценария.

Значения, передаваемые в сценарий в качестве параметров, должны быть заключены в одинарные кавычки ('). В этом случае переданное значение рассматривается как литерал.

### <a name="setting-environment-variables"></a>Настройка переменных среды

Настройка переменной среды выполняется следующим образом:

    VARIABLENAME=value

Где VARIABLENAME — имя переменной. Для доступа к переменной используйте `$VARIABLENAME`. Например, чтобы присвоить значение позиционного параметра переменной среды с именем PASSWORD, воспользуйтесь следующей инструкцией:

    PASSWORD=$1

Для последующего доступа к данным используйте `$PASSWORD`.

Переменные среды, заданные в сценарии, существуют только в пределах области сценария. В некоторых случаях может потребоваться добавить переменные среды, которые значимы на уровне системы и значение которых сохранится после выполнения сценария. Чтобы добавить переменные среды уровня системы, добавьте переменную в `/etc/environment`. Например, следующий оператор добавляет `HADOOP_CONF_DIR`:

```bash
echo "HADOOP_CONF_DIR=/etc/hadoop/conf" | sudo tee -a /etc/environment
```

### <a name="access-to-locations-where-the-custom-scripts-are-stored"></a>Доступ к расположениям, в которых хранятся пользовательские сценарии

Сценарии, используемые для настройки кластера, должны храниться в одном из следующих расположений:

* __учетной записи хранения Azure__, связанной с кластером;

* __дополнительной учетной записи хранения__, связанной с кластером;

* __ресурсе с общедоступным URI__. Например, URL-адрес к данным, хранящимся в OneDrive, Dropbox или других службах размещения файлов.

* __учетной записи Azure Data Lake Store__, связанной с кластером HDInsight. Дополнительные сведения об использовании Azure Data Lake Store с HDInsight см. в статье [Создание кластера HDInsight с хранилищем озера данных с помощью портала Azure](../data-lake-store/data-lake-store-hdinsight-hadoop-use-portal.md).

    > [!NOTE]
    > Кластер HDInsight субъекта-службы с доступом к Data Lake Store должен иметь доступ к сценарию с правами на чтение.

Ресурсы, используемые сценарием, также должны быть общедоступными.

Сохранение файлов в учетной записи хранения Azure или Azure Data Lake Store поможет обеспечить быстрый доступ к файлам, так как оба хранилища находятся в сети Azure.

> [!NOTE]
> Формат универсального кода ресурса (URI), используемый для ссылки на скрипт, отличается в зависимости от используемой службы. Для учетной записи хранения, связанной с кластером HDInsight, используйте `wasb://` или `wasbs://`, для общедоступного универсального кода ресурса (URI) — `http://` или `https://`, а для Data Lake Store — `adl://`.

### <a name="checking-the-operating-system-version"></a>Проверка версии операционной системы

Для разных версий HDInsight используются конкретные версии Ubuntu. В сценарии следует проверить различия между версиями ОС. Например, может потребоваться установить двоичный файл, привязанный к версии Ubuntu.

Чтобы проверить версию операционной системы, используйте `lsb_release`. Например, ниже показано, как создать ссылку на конкретный TAR-файл в зависимости от версии операционной системы:

```bash
OS_VERSION=$(lsb_release -sr)
if [[ $OS_VERSION == 14* ]]; then
    echo "OS verion is $OS_VERSION. Using hue-binaries-14-04."
    HUE_TARFILE=hue-binaries-14-04.tgz
elif [[ $OS_VERSION == 16* ]]; then
    echo "OS verion is $OS_VERSION. Using hue-binaries-16-04."
    HUE_TARFILE=hue-binaries-16-04.tgz
fi
```

## <a name="deployScript"></a>Контрольный список для развертывания действия сценария

Ниже приведены шаги для подготовки к развертыванию сценария:

* Поместите файлы, содержащие пользовательские сценарии, в месте, доступном из узлов кластера во время развертывания. Например, в хранилище по умолчанию для кластера. Файлы также могут храниться в общедоступных службах размещения.
* Скрипт должен быть идемпотентным. Это обеспечит многократное выполнение сценария на одном узле.
* Используйте папку для временных файлов, например /tmp, чтобы хранить скачанные файлы, используемый сценариями. После выполнения сценариев очистите эту папку.
* В случае изменений параметров на уровне операционной системы или файлов конфигурации службы Hadoop может потребоваться перезапуск служб HDInsight.

## <a name="runScriptAction"></a>Как запустить действие сценария

Действия сценариев можно использовать для настройки кластеров HDInsight с помощью следующих методов:

* Портал Azure
* Azure PowerShell
* Шаблоны Azure Resource Manager
* Пакет SDK для HDInsight .NET.

Дополнительные сведения об использовании каждого метода см. в разделе по [использованию действия сценария](hdinsight-hadoop-customize-cluster-linux.md).

## <a name="sampleScripts"></a>Примеры пользовательских сценариев

Корпорация Майкрософт предоставляет примеры сценариев для установки компонентов в кластере HDInsight. Дополнительные примеры действий сценариев доступны по приведенным ниже ссылкам.

* [Установка и использование Hue в кластерах HDInsight](hdinsight-hadoop-hue-linux.md)
* [Установка и использование Solr в кластерах HDInsight](hdinsight-hadoop-solr-install-linux.md)
* [Установка и использование Giraph в кластерах HDInsight](hdinsight-hadoop-giraph-install-linux.md)
* [Установка и обновление Mono в кластерах HDInsight](hdinsight-hadoop-install-mono.md)

## <a name="troubleshooting"></a>Устранение неполадок

Ниже перечислены ошибки, которые могут возникнуть при использовании ваших сценариев.

**Ошибка**: `$'\r': command not found`. Иногда дополняется фразой `syntax error: unexpected end of file`.

*Причина.*Эта ошибка возникает, когда для завершения строк в сценарии используется символ CRLF. В системах UNIX для завершения строк допускается только символ LF.

Зачастую эта проблема возникает при написании сценария в среде Windows, так как в текстовых редакторах для этой системы CRLF является стандартным символом завершения строки.

*Решение.*Если в вашем текстовом редакторе имеется функция выбора формата Unix или использования символа LF для завершения строк, воспользуйтесь ею. Кроме того, в системе Unix вы можете использовать следующие команды изменения CRLF на LF.

> [!NOTE]
> Для замены символов CRLF на LF могут использоваться следующие аналогичные команды. Выберите подходящий вариант в зависимости от наличия в системе соответствующих служебных программ.

| Get-Help | Заметки |
| --- | --- |
| `unix2dos -b INFILE` |Для исходного файла будет создана резервная копия с расширением BAK. |
| `tr -d '\r' < INFILE > OUTFILE` |В файле OUTFILE для окончания строк будут использоваться только символы LF. |
| `perl -pi -e 's/\r\n/\n/g' INFILE` | Изменяет файл напрямую. |
| ```sed 's/$'"/`echo \\\r`/" INFILE > OUTFILE``` |В файле OUTFILE для окончания строк будут использоваться только символы LF. |

**Ошибка**: `line 1: #!/usr/bin/env: No such file or directory`.

*Причина.*Эта ошибка возникает, если сценарий сохранен в кодировке UTF-8 с меткой порядка байтов (BOM).

*Решение.*Сохраните файл в формате ASCII или UTF-8 без метки порядка байтов. Кроме того, для создания файла без метки порядка байтов в системе Linux или Unix вы можете использовать следующую команду:

    awk 'NR==1{sub(/^\xef\xbb\xbf/,"")}{print}' INFILE > OUTFILE

Замените `INFILE` на файл с меткой порядка байтов. `OUTFILE` должно быть новым именем файла, который будет содержать сценарий без метки порядка байтов.

## <a name="seeAlso"></a>Дальнейшие действия

* Узнайте, как [Настройка кластеров HDInsight с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md)
* Используйте [справочник по пакету SDK .NET для HDInsight](https://msdn.microsoft.com/library/mt271028.aspx) , чтобы узнать больше о создании приложений .NET, которые управляют HDInsight.
* Используйте [REST API HDInsight](https://msdn.microsoft.com/library/azure/mt622197.aspx) , чтобы узнать, как использовать REST для выполнения операций управления кластерами HDInsight.
