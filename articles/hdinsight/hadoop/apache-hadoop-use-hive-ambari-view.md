---
title: "Использование представлений Ambari для работы с Hive в HDInsight (Hadoop) — Azure | Документы Майкрософт"
description: "Узнайте, как использовать представление Hive в веб-браузере для отправки запросов Hive. Представление Hive — это компонент веб-интерфейса Ambari, поставляемого с кластером HDInsight на основе Linux."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 1abe9104-f4b2-41b9-9161-abbc43de8294
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 10/23/2017
ms.author: larryfr
ms.openlocfilehash: 8293da8c77725d051f295826d9a78bf81055dcb3
ms.sourcegitcommit: f8437edf5de144b40aed00af5c52a20e35d10ba1
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 11/03/2017
---
# <a name="use-ambari-hive-view-with-hadoop-in-hdinsight"></a>Использование представления Hive с Hadoop в HDInsight

[!INCLUDE [hive-selector](../../../includes/hdinsight-selector-use-hive.md)]

Узнайте, как выполнять запросы Hive с помощью представления Hive в Ambari. Ambari — это служебная программа для управления и мониторинга, предоставляемая с кластерами HDInsight под управлением Linux. Одна из возможностей Ambari — это веб-интерфейс, который можно использовать для выполнения запросов Hive.

> [!NOTE]
> У Ambari много разных функций, которые не рассматриваются в этом документе. Дополнительные сведения см. в статье [Управление кластерами HDInsight с помощью веб-интерфейса Ambari](../hdinsight-hadoop-manage-ambari.md).

## <a name="prerequisites"></a>Предварительные требования

* Кластер HDInsight под управлением Linux. Сведения о создании кластера см. в статье [Руководство по Hadoop. Приступая к работе с Hadoop в HDInsight](apache-hadoop-linux-tutorial-get-started.md).

> [!IMPORTANT]
> Для выполнения действий, описанных в этом документе, требуется кластер Azure HDInsight, использующий Linux. Linux — это единственная операционная система, используемая для работы с HDInsight 3.4 или более поздних версий. Дополнительные сведения см. в разделе [Приближается дата прекращения сопровождения HDI версии 3.3](../hdinsight-component-versioning.md#hdinsight-windows-retirement).

## <a name="open-the-hive-view"></a>Открытие представления Hive

Представления Ambari можно открыть на портале Azure. Выберите свой кластер HDInsight, а затем в разделе **Быстрые ссылки** выберите **Просмотры Ambari**.

![Раздел портала с быстрыми ссылками](./media/apache-hadoop-use-hive-ambari-view/quicklinks.png)

В списке представлений выберите __Представление Hive__.

![Выбрано представление Hive](./media/apache-hadoop-use-hive-ambari-view/select-hive-view.png)

> [!NOTE]
> При открытии сайта Ambari вы получите запрос на проверку подлинности. Введите имя и пароль учетной записи администратора (по умолчанию — `admin`), используемые при создании кластера.

Вы должны увидеть страницу, аналогичную показанной ниже.

![Изображение листа запроса для представления Hive](./media/apache-hadoop-use-hive-ambari-view/ambari-hive-view.png)

## <a name="run-a-query"></a>Выполнение запроса

Чтобы выполнить запрос Hive, выполните следующие действия в представлении Hive.

1. На вкладке __Запрос__ вставьте в лист следующие инструкции HiveQL:

    ```hiveql
    DROP TABLE log4jLogs;
    CREATE EXTERNAL TABLE log4jLogs(t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string)
    ROW FORMAT DELIMITED FIELDS TERMINATED BY ' '
    STORED AS TEXTFILE LOCATION '/example/data/';
    SELECT t4 AS sev, COUNT(*) AS cnt FROM log4jLogs WHERE t4 = '[ERROR]' GROUP BY t4;
    ```

    Эти операторы выполняют следующие действия:

   * `DROP TABLE` — удаляет таблицу и файл данных, если таблица уже существует.

   * `CREATE EXTERNAL TABLE` — создает "внешнюю" таблицу в Hive.
   Внешние таблицы хранят только определение таблицы в Hive. Данные остаются в исходном расположении.

   * `ROW FORMAT` — показывает настройку форматирования данных. В данном случае поля всех журналов разделены пробелом.

   * `STORED AS TEXTFILE LOCATION` — показывает место хранения данных и их формат (текст).

   * `SELECT` — выбирает подсчет количества строк, в которых столбец t4 содержит значение [ERROR].

     > [!NOTE]
     > Внешние таблицы необходимо использовать в тех случаях, когда ожидается, что исходные данные будут обновляться внешним источником, таким как автоматизированный процесс передачи данных или другой операцией MapReduce. Удаление внешней таблицы *не* приводит к удалению данных, будет удалено только определение таблицы.

    > [!IMPORTANT]
    > Оставьте для параметра __База данных__ значение __по умолчанию__. В примерах в этом документе используется база данных по умолчанию, входящая в состав HDInsight.

2. Чтобы выполнить запрос, нажмите кнопку **Выполнить** под листом. Кнопка станет оранжевой, а текст изменится на **Остановить**.

3. Когда запрос будет выполнен, на вкладке **Результаты** появятся результаты этой операции. Вот пример результата запроса:

        sev       cnt
        [ERROR]   3

    Просмотреть сведения, регистрируемые в процессе выполнения задания, можно на вкладке **Журналы**.

   > [!TIP]
   > Скачайте или сохраните результаты в диалоговом окне с раскрывающимся списком **Save results** (Сохранение результатов) в верхнем левом углу раздела **Query Process Results** (Результаты обработки запроса).

4. Выберите четыре первые строки запроса, а затем — команду **Выполнить**. Обратите внимание на отсутствие результатов после выполнения задания. Если нажать кнопку **Выполнить**, выбрав часть запроса, запрос выполняется только с использованием выбранных инструкций. В нашем примере не выбрана последняя инструкция, которая извлекает строки из таблицы. Если выбрать только эту строку, а затем нажать кнопку **Выполнить**, отобразятся ожидаемые результаты.

5. Чтобы добавить новый лист, нажмите кнопку **Новый лист** в нижней части **редактора запросов**. На новом листе введите указанные ниже инструкции HiveQL.

    ```hiveql
    CREATE TABLE IF NOT EXISTS errorLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string) STORED AS ORC;
    INSERT OVERWRITE TABLE errorLogs SELECT t1, t2, t3, t4, t5, t6, t7 FROM log4jLogs WHERE t4 = '[ERROR]';
    ```

  Эти операторы выполняют следующие действия:

   * **CREATE TABLE IF NOT EXISTS** — создает таблицу, если она до этого не существовала. Так как ключевое слово **EXTERNAL** не используется, создается внутренняя таблица. Внутренняя таблица хранится в хранилище данных Hive и полностью обслуживается Hive. В отличие от внешних таблиц, удаление внутренней таблицы приводит к удалению базовых данных.

   * **STORED AS ORC**: хранение данных в формате ORC (Optimized Row Columnar). Это высокооптимизированный и эффективный формат для хранения данных Hive.

   * **INSERT OVERWRITE ... SELECT** — выбирает из таблицы **log4jLogs** строки, содержащие значение `[ERROR]`, а затем вставляет данные в таблицу **errorLogs**.

Нажмите кнопку **Выполнить**, чтобы выполнить этот запрос. На вкладке **Результаты** не отображаются сведения, если запрос не возвращает строки. По завершении запроса должно отображаться состояние **Успешно**.

### <a name="visual-explain"></a>Визуальное объяснение

Чтобы отобразить визуализацию плана запроса, выберите под листом вкладку **Visual Explain** (Визуальное пояснение).

Представление запроса **Visual Explain** (Визуальное объяснение) помогает разобраться в потоке сложных запросов. Вы можете просмотреть текстовый эквивалент этого представления, нажав кнопку **Explain** (Объяснить) в редакторе запросов.

### <a name="tez-ui"></a>Пользовательский интерфейс Tez

Чтобы отобразить пользовательский интерфейс Tez для запроса, выберите под листом вкладку **Tez**.

> [!IMPORTANT]
> Tez используется не для всех запросов. Многие запросы можно разрешить и без применения Tez. 

Если Tez использовался для разрешения запроса, отображается направленный ациклический граф (DAG) . Чтобы просмотреть DAG для ранее выполненных запросов или выполнить отладку процесса Tez, используйте [представление Tez](../hdinsight-debug-ambari-tez-view.md).

## <a name="view-job-history"></a>Просмотр журнала заданий

На вкладке __Задания__ отображается журнал запросов Hive.

![Изображение журнала заданий](./media/apache-hadoop-use-hive-ambari-view/job-history.png)

## <a name="database-tables"></a>Таблицы базы данных

Вкладку __Таблицы__ можно использовать для работы с таблицами в базе данных Hive.

![Изображение вкладки "Таблицы"](./media/apache-hadoop-use-hive-ambari-view/tables.png)

## <a name="saved-queries"></a>Сохраненные запросы

На вкладке **Запрос** можно при желании сохранять запросы. После сохранения запроса можно повторно использовать его из вкладки __Saved Queries__ (Сохраненные запросы).

![Изображение вкладки "Сохраненные запросы"](./media/apache-hadoop-use-hive-ambari-view/saved-queries.png)

## <a name="user-defined-functions"></a>Определяемые пользователем функции

Инфраструктуру Hive также можно расширить с помощью определяемых пользователем функций (UDF). Они позволяют реализовать функции или логику, сложно моделируемые в HiveQL.

Объявлять и сохранять наборы определяемых пользователем функций можно с помощью вкладки **UDF** вверху представления Hive. Эти функции могут использоваться в **редакторе запросов**.

![Изображение вкладки "Определяемая пользователем функция"](./media/apache-hadoop-use-hive-ambari-view/user-defined-functions.png)

После добавления в представление Hive UDF в нижней части **редактора запросов** появляется кнопка **Insert udfs** (Вставить определяемые пользователем функции). Нажав эту кнопку, вы увидите раскрывающийся список функций, определенных в представлении Hive. Выбирая определяемую пользователем функцию, вы добавляете в запрос соответствующие инструкции HiveQL.

Например, вы определили функцию со следующими свойствами:

* имя ресурса — myudfs;

* путь к ресурсу — /myudfs.jar;

* имя определяемой пользователем функции — myawesomeudf;

* имя класса определяемой пользователем функции — com.myudfs.Awesome.

Нажав кнопку **Insert udfs** (Вставить определяемые пользователем функции), вы увидите запись с именем **myudfs**, содержащую раскрывающийся список для каждой функции, определяемой для этого ресурса. В данном случае это **myawesomeudf**. Если вы выберете эту запись, в начало запроса будет добавлен следующий код:

```hiveql
add jar /myudfs.jar;
create temporary function myawesomeudf as 'com.myudfs.Awesome';
```

Затем вы можете использовать эту функцию в своем запросе. Например, `SELECT myawesomeudf(name) FROM people;`.

Дополнительные сведения об использовании определяемых пользователем функций с Hive в HDInsight см. в следующих статьях:

* [Использование Python с Hive и Pig в HDInsight](python-udf-hdinsight.md)
* [Добавление пользовательских UDF Hive в HDInsight](http://blogs.msdn.com/b/bigdatasupport/archive/2014/01/14/how-to-add-custom-hive-udfs-to-hdinsight.aspx)

## <a name="hive-settings"></a>Параметры Hive

Вы можете изменять различные настройки Hive. Например, для изменения механизма выполнения для Hive с Tez (значение по умолчанию) на MapReduce.

## <a id="nextsteps"></a>Дальнейшие действия

Общая информация о Hive в HDInsight:

* [Использование Hive с Hadoop в HDInsight](hdinsight-use-hive.md)

Дополнительная информация о других способах работы с Hadoop в HDInsight.

* [Использование Pig с Hadoop в HDInsight](hdinsight-use-pig.md)
* [Использование MapReduce с Hadoop в HDInsight](hdinsight-use-mapreduce.md)
