---
title: Использование Apache Hive как средства для извлечения, преобразования и загрузки (Azure HDInsight) | Документация Майкрософт
description: Apache Hive можно использовать в Azure HDInsight для извлечения, преобразования и загрузки данных.
services: hdinsight
documentationcenter: ''
author: ashishthaps
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: ''
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.date: 11/14/2017
ms.author: ashishth
ms.openlocfilehash: 06e06d87abd66c80deb2c8731f68bb8171da574b
ms.sourcegitcommit: 9cdd83256b82e664bd36991d78f87ea1e56827cd
ms.translationtype: HT
ms.contentlocale: ru-RU
ms.lasthandoff: 04/16/2018
ms.locfileid: "31399592"
---
# <a name="use-apache-hive-as-an-extract-transform-and-load-etl-tool"></a>Использование Apache Hive как средства для извлечения, преобразования и загрузки

Обычно перед загрузкой входных данных в целевое назначение для аналитики вам нужно очистить и преобразовать эти данные. Операции извлечения, преобразования и загрузки используются для подготовки данных и загрузки в целевое назначение.  Hive в HDInsight умеет принимать неструктурированные данные, обрабатывать их по определенным правилам и передавать в реляционное хранилище данных, чтобы их могли использовать системы поддержки принятия решений. При таком подходе данные извлекаются из источника и хранятся в масштабируемом хранилище, например в хранилище BLOB-объектов Azure или Azure Data Lake Store. Затем данные преобразуются набором запросов Hive и размещаются в Hive в ожидании массовой загрузки в целевое хранилище данных.

## <a name="use-case-and-model-overview"></a>Обзор модели и примера использования

На следующем рисунке представлена схема примера использования и модель для автоматизации процессов извлечения, преобразования и загрузки. Входные данные преобразуются в выходные данные определенного формата.  В процессе этой трансформации может изменяться форма данных, тип и даже язык.  Процессы извлечения, преобразования и загрузки могут переводить имперские единицы измерения в метрические, изменять часовые пояса и повышать точность данных, чтобы новые данные в точности соответствовали тем, которые уже существуют в целевом хранилище.  Процессы извлечения, преобразования и загрузки можно даже применить для объединения новых и существующих данных, чтобы поддерживать актуальность отчетов или повышать информативность существующих данных.  После такой обработки приложения и службы, например средства создания отчетов, смогут получить данные в удобном для них формате.

![Apache Hive в роли средства извлечения, преобразования и загрузки](./media/apache-hadoop-using-apache-hive-as-an-etl-tool/hdinsight-etl-architecture.png)

Обычно Hadoop используется для процессов извлечения, преобразования и загрузки, если нужно передать большое число текстовых файлов (например, CSV) или файлы с часто изменяющимся содержимым.  Hive — это прекрасный инструмент для подготовки данных перед отправкой в целевое назначение.  Hive позволяет создать схему для CSV и применять язык запросов, близкий к SQL, чтобы создавать программы MapReduce для взаимодействия с данными. 

Ниже приведены типичные шаги при работе с Hive для задач извлечения, преобразования и загрузки.

1. Передайте данные в Azure Data Lake Store или в хранилище BLOB-объектов Azure.
2. Создайте базу данных для хранения метаданных (на основе Базы данных SQL Azure), в которой Hive будет хранить схемы данных.
3. Создайте кластер HDInsight и подключите хранилище данных.
4. Определите схему, которая будет применяться в хранилище данных при считывании данных.

    ```
    DROP TABLE IF EXISTS hvac;

    --create the hvac table on comma-separated sensor data stored in Azure Storage blobs
    
    CREATE EXTERNAL TABLE hvac(`date` STRING, time STRING, targettemp BIGINT,
        actualtemp BIGINT, 
        system BIGINT, 
        systemage BIGINT, 
        buildingid BIGINT)
    ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' 
    STORED AS TEXTFILE LOCATION 'wasb://{container}@{storageaccount}.blob.core.windows.net/HdiSamples/SensorSampleData/hvac/';
    ```

5. Преобразуйте данные и передайте их в целевое расположение.  Есть несколько способов применить Hive для преобразования и загрузки.

    * Выполните с помощью Hive запросы и подготовку данных, затем сохраните данные в формате CSV в Azure Data Lake Store или в хранилище BLOB-объектов Azure.  После этого вы сможете применить внешнее средство, например SQL Server Integration Services (SSIS), для получения данных в формате CSV и их передачи в реляционную базу данных, такую как SQL Server.
    * Выполняйте запросы непосредственно из Excel или C# с помощью драйвера Hive ODBC.
    * Используйте [Apache Sqoop](apache-hadoop-use-sqoop-mac-linux.md) для чтения подготовленных неструктурированных CSV-файлов и передачи данных в целевую реляционную базу данных.

## <a name="data-sources"></a>Источники данных

Источниками данных обычно являются внешние данные, которые можно сопоставить с существующими данными в хранилище данных, например:

* социальные сети, файлы журналов, данные от датчиков и приложений, которые создают файлы данных;
* наборы данных от поставщиков данных, например статистика погоды или продаж;
* данные потоковой передачи, собранные, отфильтрованные и обработанные с помощью соответствующих средств или платформ.

<!-- TODO: (see Collecting and loading data into HDInsight). -->

## <a name="output-targets"></a>Целевые назначения

С помощью Hive можно выводить данные в разные целевые объекты, в том числе:

* реляционные базы данных, например SQL Server или Базу данных SQL Azure;
* службы хранилища данных, например хранилище данных SQL Microsoft Azure;
* Excel;
* хранилища Azure для таблиц и больших двоичных объектов;
* приложения или службы, которым нужны данные в определенных форматах или в виде файлов с определенным типом структуры информации;
* хранилища документов JSON, такие как <a href="https://azure.microsoft.com/services/cosmos-db/">CosmosDB</a>.

## <a name="considerations"></a>Рекомендации

Модель извлечения, преобразования и загрузки обычно используется в следующих ситуациях.

* Для загрузки потоковых или очень объемных данных (частично структурированных или неструктурированных) из внешних источников в существующую базу данных или информационную систему.
* Для очистки, преобразования и проверки данных перед загрузкой, возможно с неоднократным проходом через кластер для преобразования.
* Для составления регулярно обновляемых отчетов и визуализаций.  Например, если создание отчета занимает слишком много времени и не может выполняться в течение дня, вы можете генерировать его по расписанию в ночное время.  Вы можете автоматизировать запросы Hive с помощью планировщика Microsoft Azure и PowerShell.

Если целевое назначение не является базой данных, прямо внутри запроса вы можете сохранить данные в файле соответствующего формата, например в CSV-файле. Затем этот файл можно затем в Microsoft Excel или Power BI.

Если в процессе извлечения, преобразования и загрузки вам нужно выполнять несколько операций с данными, уделите внимание координации этих действий. Если операции управляются внешней программой, а не внутренним рабочим процессом, важно оценить возможность параллельного выполнения некоторых операций и правильно определять, когда завершается каждое задание. Зачастую проще применить механизм управления рабочим процессом, например Oozie в среде Hadoop, чем самостоятельно распределять последовательность операций внешними скриптами или программами. Дополнительные сведения о средстве Oozie вы найдете в статье [об оркестрации рабочих процессов и заданий](https://msdn.microsoft.com/library/dn749829.aspx).

## <a name="next-steps"></a>Дополнительная информация

* [ETL в масштабе](apache-hadoop-etl-at-scale.md)
* [Ввод в эксплуатацию конвейера данных](../hdinsight-operationalize-data-pipeline.md)
<!-- * [ETL Deep Dive](../hdinsight-etl-deep-dive.md) -->
