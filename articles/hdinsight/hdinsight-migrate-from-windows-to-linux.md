---
title: "Миграция из кластера HDInsight под управлением Windows на кластер HDInsight под управлением Linux | Документация Майкрософт"
description: "Узнайте, как выполнить миграцию из кластера HDInsight под управлением Windows на кластер HDInsight под управлением Linux."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: ff35be59-bae3-42fd-9edc-77f0041bab93
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 04/12/2017
ms.author: larryfr
translationtype: Human Translation
ms.sourcegitcommit: 7f469fb309f92b86dbf289d3a0462ba9042af48a
ms.openlocfilehash: f2c4956ba296781907498226a18708684281692b
ms.lasthandoff: 04/13/2017


---
# <a name="migrate-from-a-windows-based-hdinsight-cluster-to-a-linux-based-cluster"></a>Миграция из кластера HDInsight под управлением Windows на кластер под управлением Linux

Этот документ содержит сведения о различиях между HDInsight в Windows и Linux и руководство по миграции существующих рабочих нагрузок на кластер под управлением Linux.

Хотя HDInsight на основе Windows упрощает использование Hadoop в облаке, вам может потребоваться перейти на кластер под управлением Linux. Например, чтобы воспользоваться преимуществами инструментов и технологий на основе Linux, которые необходимы для вашего решения. Многие компоненты в экосистеме Hadoop разрабатываются в системах под управлением Linux, и они могут быть недоступны в HDInsight под управлением Windows. Кроме того, во многих книгах, видеороликах и других учебных материалах предполагается, что при работе с Hadoop вы используете Linux.

> [!NOTE]
> В кластерах HDInsight в качестве операционной системы узлов используется Ubuntu Long Term Support (LTS). Сведения о версии Ubuntu с поддержкой HDInsight, а также другие сведения об управлении версиями компонента см. в описании [версий компонента HDInsight](hdinsight-component-versioning.md).

## <a name="migration-tasks"></a>Задачи миграции

Общий рабочий процесс для миграции выглядит следующим образом.

![Схема рабочего процесса миграции](./media/hdinsight-migrate-from-windows-to-linux/workflow.png)

1. Прочитайте каждый раздел этого документа, чтобы понять, какие изменения могут потребоваться для миграции существующего рабочего процесса, заданий и т. д. на кластер под управлением Linux.

2. Создайте кластер под управлением Linux как среду тестирования и контроля качества. Дополнительные сведения о создании кластера под управлением Linux см. в статье [Создание кластеров под управлением Linux в HDInsight](hdinsight-hadoop-provision-linux-clusters.md).

3. Скопируйте в новую среду существующие задания, источники данных и приемники.

4. Выполните проверочное тестирование, чтобы убедиться, что задания должным образом работают новом кластере.

Убедившись, что все работает правильно, запланируйте время простоя для миграции. Во время этого простоя выполните следующие действия.

1. Создайте резервную копию всех временных данных, хранящихся локально на узлах кластера. Например, к ним могут относиться данные, которые хранятся непосредственно на головном узле.

2. Удалите кластер под управлением Windows.

3. Создайте кластер под управлением Linux, используя то же хранилище данных по умолчанию, которое использовалось кластером под управлением Windows. Кластер Linux может продолжить работу с существующими рабочими данными.

4. Импортируйте все временные данные из резервной копии.

5. Запустите задания и продолжите обработку с помощью нового кластера.

### <a name="copy-data-to-the-test-environment"></a>Копирование данных в среду тестирования

Существует множество методов для копирования данных и заданий. В этом разделе рассматриваются два простейших метода перемещения файлов непосредственно в кластер тестирования.

#### <a name="hdfs-copy"></a>Копирование HDFS

Чтобы скопировать данные из рабочего кластера в тестовый кластер, выполните приведенные ниже действия. Для их выполнения используется служебная программа `hdfs dfs`, которая входит в состав HDInsight.

1. Определите учетную запись хранения и контейнер по умолчанию для существующего кластера. В следующем примере для извлечения этой информации используется PowerShell.

    ```powershell
    $clusterName="Your existing HDInsight cluster name"
    $clusterInfo = Get-AzureRmHDInsightCluster -ClusterName $clusterName
    write-host "Storage account name: $clusterInfo.DefaultStorageAccount.split('.')[0]"
    write-host "Default container: $clusterInfo.DefaultStorageContainer"
    ```

2. Чтобы создать среду тестирования, выполните действия, описанные в документе "Создание кластеров под управлением Linux в HDInsight". Остановитесь перед созданием кластера и вместо этого выберите **Необязательная конфигурация**.

3. В колонке "Необязательная конфигурация" выберите **Связанные учетные записи хранения**.

4. Выберите **Добавить ключ к хранилищу данных**и при появлении запроса выберите учетную запись хранения, которая была определена с помощью сценария PowerShell на шаге 1. Щелкните **Выбрать** на каждой колонке. Наконец, создайте кластер.

5. После создания кластера подключитесь к нему с помощью протокола **SSH**. Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md).

6. В сеансе SSH используйте следующую команду для копирования файлов из связанной учетной записи хранения в новую учетную запись хранения по умолчанию. Замените CONTAINER данными контейнера, возвращенными PowerShell. Замените __ACCOUNT__ именем учетной записи. Замените путь к данным на путь к файлу данных.

    ```bash
    hdfs dfs -cp wasbs://CONTAINER@ACCOUNT.blob.core.windows.net/path/to/old/data /path/to/new/location
    ```

    > [!NOTE]
    > Если структура каталогов, которая содержит данные, не существует в тестовой среде, ее можно создать с помощью следующей команды.

    ```bash
    hdfs dfs -mkdir -p /new/path/to/create
    ```

    При указании параметра `-p` будут созданы все каталоги в пути.

#### <a name="direct-copy-between-blobs-in-azure-storage"></a>Прямое копирование между большими двоичными объектами в службе хранилища Azure

При желании также можно использовать командлет Azure PowerShell `Start-AzureStorageBlobCopy`, чтобы скопировать большие двоичные объекты между учетными записями хранения вне HDInsight. Дополнительные сведения см. в разделе "Управление большими двоичными объектами Azure" статьи "Использование Azure PowerShell с хранилищем Azure".

## <a name="client-side-technologies"></a>Технологии на стороне клиента

Клиентские технологии, в том числе [командлеты Azure PowerShell](/powershell/azureps-cmdlets-docs), [Azure CLI](../cli-install-nodejs.md) или [пакет SDK .NET для Hadoop](https://hadoopsdk.codeplex.com/), продолжают работать в кластерах Linux. Эти технологии основаны на интерфейсах REST API, которые одинаковы для обоих типов ОС кластера.

## <a name="server-side-technologies"></a>Технологии на стороне сервера

В следующей таблице приведены рекомендации по переносу серверных компонентов, относящихся к Windows.

| Если вы используете эту технологию... | Выполните это действие... |
| --- | --- |
| **PowerShell** (сценарии на стороне сервера, включая действия сценариев, используемые во время создания кластера) |Перепишите эти сценарии как скрипты Bash. Сведения о действиях сценариев см. в разделах [Настройка кластеров HDInsight под управлением Linux с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md) и [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md). |
| **Azure CLI** (сценарии на стороне сервера) |Хотя интерфейс командной строки Azure доступен в Linux, он не предустановлен на головных узлах кластера HDInsight. Дополнительные сведения об установке Azure CLI см. в статье [Get started with Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli) (Приступая к работе с Azure CLI 2.0). |
| **Компоненты .NET** |.NET поддерживается в кластерах HDInsight под управлением Linux посредством [Mono](https://mono-project.com). Дополнительные сведения см. в разделе [Перенос решений .NET из HDInsight под управлением Windows в HDInsight под управлением Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md). |
| **Компоненты Win32 или другая технология, которая существует только для Windows** |Точные действия зависят от компонента или технологии. Возможно, вам удастся найти версию, которая совместима с Linux; возможно, потребуется найти альтернативное решение или переписать этот компонент. |

> [!IMPORTANT]
> Пакет SDK для управления HDInsight не полностью совместим с Mono. В настоящее время он не должен использоваться в решениях, развернутых в кластере HDInsight.

## <a name="cluster-creation"></a>Создание кластера

В этом разделе приведены сведения о различиях при создании кластера.

### <a name="ssh-user"></a>Пользователь SSH

Кластеры HDInsight под управлением Linux используют протокол **Secure Shell (SSH)** для предоставления удаленного доступа к узлам кластера. В отличие клиентов удаленного рабочего стола для кластеров Windows, большинство SSH-клиентов не обеспечивает графический пользовательский интерфейс. Вместо этого SSH-клиенты предоставляют командную строку, которая позволяет выполнять команды в кластере. Некоторые клиенты (например, [MobaXterm](http://mobaxterm.mobatek.net/)) в дополнение к удаленной командной строке предоставляют графический проводник файловой системы.

Во время создания кластера необходимо указать имя пользователя SSH и **пароль** или **сертификат открытого ключа** для аутентификации.

Мы рекомендуем использовать сертификат открытого ключа, так как он более безопасен по сравнению с паролем. При использовании сертификата создается пара подписанных ключей (открытый и закрытый), после чего открытый ключ указывается при создании кластера. При подключении к серверу с помощью SSH проверка подлинности подключения выполняется с помощью закрытого ключа на клиентском компьютере.

Дополнительные сведения см. в статье [Использование SSH с Hadoop на основе Linux в HDInsight из Linux, Unix или OS X](hdinsight-hadoop-linux-use-ssh-unix.md).

### <a name="cluster-customization"></a>Настройка кластера

**Действия сценария**, используемые в кластерах под управлением Linux, должны быть записаны в сценарий Bash. Действия сценариев можно использовать не только во время создания кластера, но и для настройки после запуска кластера (для кластеров под управлением Linux). Дополнительные сведения см. в разделах [Настройка кластеров HDInsight под управлением Linux с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md) и [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md).

Еще одна возможность настройки — **начальная загрузка**. Для кластеров Windows эта функция позволяет указать расположение дополнительных библиотек для использования с Hive. После создания кластера эти библиотеки автоматически становятся доступными для Hive без необходимости использования `ADD JAR`.

Для кластеров под управлением Linux функция начальной загрузки не предоставляет такой возможности. Вместо этого используйте действие сценария, указанное в статье [Добавление библиотек Hive во время создания кластера HDInsight](hdinsight-hadoop-add-hive-libraries.md).

### <a name="virtual-networks"></a>Виртуальные сети

Кластеры HDInsight под управлением Windows работают только с классическими виртуальными сетями, а для кластеров HDInsight под управлением Linux требуются виртуальные сети Resource Manager. Если в классической виртуальной сети имеются ресурсы, к которым должен подключаться кластер HDInsight под управлением Linux, обратитесь к разделу [Подключение классических виртуальных сетей к новым виртуальным сетям](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).

Дополнительные сведения о требованиях к конфигурации при использовании виртуальных сетей Azure в HDInsight см. в статье [Расширение возможностей HDInsight с помощью виртуальной сети Azure](hdinsight-extend-hadoop-virtual-network.md).

## <a name="management-and-monitoring"></a>Управление и мониторинг

Многие веб-интерфейсы, которыми вы могли пользоваться в HDInsight под управлением Windows, например журнал заданий или пользовательский интерфейс Yarn, доступны в Ambari. Кроме того, представление Hive Ambari позволяет выполнять запросы Hive с помощью веб-браузера. Пользовательский веб-интерфейс Ambari доступен в кластерах HDInsight на платформе Linux по адресу: https://CLUSTERNAME.azurehdinsight.net.

Дополнительные сведения о работе с Ambari см. в следующих документах:

* [Веб-интерфейс Ambari](hdinsight-hadoop-manage-ambari.md)
* [Ambari REST API](hdinsight-hadoop-manage-ambari-rest-api.md)

### <a name="ambari-alerts"></a>Предупреждения Ambari

Ambari имеет систему предупреждений, которые могут сообщить вам о возможных проблемах с кластером. Предупреждения выделяются красным или желтым цветом в веб-интерфейсе Ambari. Их также можно получить с помощью интерфейса API REST.

> [!IMPORTANT]
> Предупреждения Ambari указывают на то, что проблема *возможна*, а не на то, что она уже *присутствует*. Например, может появиться предупреждение о том, что сервер HiveServer2 недоступен. При этом вы можете обратиться к нему обычным образом.
>
> Многие предупреждения реализованы в качестве запросов к службе и ожидают ответа в течение определенного промежутка времени. Поэтому предупреждение не обязательно означает, что служба не работает — оно означает лишь то, что служба не возвратила результаты в течение ожидаемого интервала времени.

Перед выполнением каких-либо действий с оповещением следует оценить, появлялось ли оно в течение продолжительного периода времени или отражает проблемы в работе пользователей, о которых уже сообщалось.

## <a name="file-system-locations"></a>Структура файловой системы

Для кластеров под управлением Linux структура файловой системы отличается от кластеров HDInsight под управлением Windows. Используйте следующую таблицу для поиска часто используемых файлов.

| Необходимо найти... | Это находится в папке... |
| --- | --- |
| Конфигурация |`/etc`. Например, `/etc/hadoop/conf/core-site.xml` |
| Файлы журналов |`/var/logs` |
| Платформа данных Hortonworks Data Platform (HDP) |`/usr/hdp`. Здесь расположены два каталога — каталог с текущей версией HDP и каталог `current`. Каталог `current` содержит символьные ссылки на файлы и папки, размещенные в каталоге номера версии. Каталог `current` предоставляется для удобного доступа к файлам HDP, так как при обновлении версии HDP номер версии меняется. |
| hadoop-streaming.jar |`/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar` |

В общем случае, если вам известно имя файла, можно выполнить следующую команду в сеансе SSH, чтобы определить путь к файлу:

    find / -name FILENAME 2>/dev/null

В имени файла также можно использовать подстановочные знаки. Например, `find / -name *streaming*.jar 2>/dev/null` возвращает путь ко всем JAR-файлам, содержащим слово streaming в имени файла.

## <a name="hive-pig-and-mapreduce"></a>Hive, Pig и MapReduce

Рабочие нагрузки Pig и MapReduce на кластерах Linux похожи. Однако кластеры HDInsight под управлением Linux можно создать с помощью более новых версий Hadoop, Hive и Pig. Эти отличия версий могут повлиять на функционирование существующих решений. Дополнительные сведения о версиях компонентов в составе HDInsight см. в разделе [Что представляют собой различные компоненты Hadoop, доступные в HDInsight?](hdinsight-component-versioning.md)

Кластеры HDInsight под управлением Linux не предоставляют функцию удаленного рабочего стола. Вместо этого можно использовать протокол SSH для удаленного подключения к головным узлам кластера. Дополнительные сведения см. в следующих документах:

* [Использование Hive с Hadoop в HDInsight с применением Beeline](hdinsight-hadoop-use-hive-ssh.md)
* [Использование Pig с SSH](hdinsight-hadoop-use-pig-ssh.md)
* [Использование MapReduce с SSH](hdinsight-hadoop-use-mapreduce-ssh.md)

### <a name="hive"></a>Hive

> [!IMPORTANT]
> При использовании внешнего хранилища метаданных Hive следует создать резервную копию этого хранилища, прежде чем использовать его с HDInsight под управлением Linux. В HDInsight под управлением Linux используются более новые версии Hive, что может привести к проблемам совместимости с хранилищами метаданных, созданными с использованием предыдущих версий.

Следующая схема содержит рекомендации по переносу рабочих нагрузок Hive.

| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| **редактор Hive;** |[используйте представление Hive в Ambari](hdinsight-hadoop-use-hive-ambari-view.md) |
| `set hive.execution.engine=tez;` для включения Tez. |Tez — ядро выполнения по умолчанию для кластеров под управлением Linux, поэтому инструкция set больше не требуется. |
| Определяемые пользователем функции C# | Сведения о проверке компонентов C# с помощью HDInsight под управлением Linux см. в разделе [Перенос решений .NET из HDInsight под управлением Windows в HDInsight под управлением Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md). |
| CMD-файлами или сценариями на сервере, вызываемыми как часть задания Hive |используйте скрипты Bash |
| `hive` из удаленного рабочего стола. |используйте [Beeline](hdinsight-hadoop-use-hive-beeline.md) или [Hive из сеанса SSH](hdinsight-hadoop-use-hive-ssh.md). |

### <a name="pig"></a>Pig,

| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| Определяемые пользователем функции C# | Сведения о проверке компонентов C# с помощью HDInsight под управлением Linux см. в разделе [Перенос решений .NET из HDInsight под управлением Windows в HDInsight под управлением Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md). |
| CMD-файлы или сценарии на сервере, вызываемые как часть задания Hive |используйте скрипты Bash |

### <a name="mapreduce"></a>MapReduce

| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| Компоненты C# для сопоставления и редукции | Сведения о проверке компонентов C# с помощью HDInsight под управлением Linux см. в разделе [Перенос решений .NET из HDInsight под управлением Windows в HDInsight под управлением Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md). |
| CMD-файлами или сценариями на сервере, вызываемыми как часть задания Hive |используйте скрипты Bash |

## <a name="oozie"></a>Oozie

> [!IMPORTANT]
> При использовании внешнего хранилища метаданных Oozie следует создать резервную копию этого хранилища, прежде чем использовать его с HDInsight под управлением Linux. В HDInsight под управлением Linux используются более новые версии Oozie, что может привести к проблемам совместимости с хранилищами метаданных, созданными с использованием предыдущих версий.

Рабочие процессы Oozie позволяют использовать действия оболочки. Эти действия используют оболочку по умолчанию операционной системы для выполнения команд командной строки. Если имеются рабочие процессы Oozie, зависящие от оболочки Windows, необходимо переписать их, использовав оболочку Linux (Bash). Дополнительные сведения об использовании действий оболочки с Oozie см. в разделе [Oozie shell action extension](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html) (Расширение действий оболочки Oozie).

Если имеются рабочие процессы Oozie, зависящие от приложений C#, вызываемых с помощью действий оболочки, необходимо проверить эти приложения в среде Linux. Дополнительные сведения см. в разделе [Перенос решений .NET из HDInsight под управлением Windows в HDInsight под управлением Linux](hdinsight-hadoop-migrate-dotnet-to-linux.md).

## <a name="storm"></a>Storm

| В кластерах под управлением Windows я пользуюсь... | В кластерах под управлением Linux... |
| --- | --- |
| Панель мониторинга Storm |Панель мониторинга Storm недоступна. Сведения об отправке топологий приведены в разделе [Развертывание и управление топологиями Storm в HDInsight под управлением Linux](hdinsight-storm-deploy-monitor-topology-linux.md) . |
| Пользовательский интерфейс Storm |Пользовательский интерфейс Storm доступен по адресу https://<имя_кластера>.azurehdinsight.net/stormui. |
| Visual Studio для создания, развертывания и управления C# или гибридными топологиями |Visual Studio можно использовать для создания, развертывания и управления топологиями C# (SCP.NET) или гибридными топологиями в кластерах Storm в HDInsight под управлением Linux, созданных после 28 октября 2016 года. |

## <a name="hbase"></a>HBase

На кластерах под управлением Linux родительским Z-узлом для HBase является `/hbase-unsecure`. Задайте это значение в конфигурации для всех клиентских приложений Java, которые используют собственный API Java для HBase.

Пример клиента, который устанавливает это значение, см. в разделе [Использование Maven для сборки приложений Java, которые используют HBase с HDInsight (Hadoop)](hdinsight-hbase-build-java-maven.md).

## <a name="spark"></a>Spark

Кластеры Spark были доступны в кластерах Windows на этапе предварительной версии. Общедоступная версия Spark доступна только в кластерах Linux. Способа миграции кластера Spark под управлением Windows в предварительной версии в кластер Spark под управлением Linux основной версии не существует.

## <a name="known-issues"></a>Известные проблемы

### <a name="azure-data-factory-custom-net-activities"></a>Пользовательские действия .NET фабрики данных Azure

Пользовательские действия .NET фабрики данных Azure в настоящее время не поддерживаются в кластерах HDInsight под управлением Linux. Вместо этого следует использовать один из следующих методов для реализации пользовательских действий в рамках конвейера ADF.

* Выполните действия .NET в пуле пакетной службы Azure. Ознакомьтесь с разделом "Использование связанной пакетной службы Azure" статьи [Использование настраиваемых действий в конвейере фабрики данных Azure](../data-factory/data-factory-use-custom-activities.md).
* Реализуйте действие как действие MapReduce. Дополнительные сведения см. в разделе [Вызов программы MapReduce из фабрики данных](../data-factory/data-factory-map-reduce.md).

### <a name="line-endings"></a>Символы конца строки

Как правило, в качестве символов конца строки в Windows используется CRLF, а в Linux — LF. Если вы формируете или ожидаете получить данные с символами конца строки CRLF, может потребоваться изменить производителей или потребителей данных для работы с символами конца строки LF.

Например, при выполнении запроса к HDInsight с использованием Azure PowerShell в кластере под управлением Windows будут возвращены данные с символами конца строки CRLF. Тот же запрос к кластеру под управлением Linux возвратит данные с символами конца строки LF. Вы должны проверить, вызывает ли символ конца строки ошибки в работе решения, прежде чем переходить на кластер Linux.

Если у вас есть сценарии, выполняемые непосредственно на узлах кластера Linux, следует всегда использовать символы конца строки LF. Если использовать CRLF, могут возникнуть ошибки при выполнении сценариев в кластере под управлением Linux.

Если вы знаете, что в сценариях нет строк, содержащих символы CR, можно выполнить массовую замену символов конца строк с помощью одного из следующих методов:

* **Перед передачей в кластер**: используйте следующие инструкции PowerShell для замены символов конца строк с CRLF на LF перед передачей сценариев в кластер.

    ```powershell
    $original_file ='c:\path\to\script.py'
    $text = [IO.File]::ReadAllText($original_file) -replace "`r`n", "`n"
    [IO.File]::WriteAllText($original_file, $text)
    ```

* **После передачи в кластер**: используйте приведенную ниже команду в сеансе SSH-подключения к кластеру Linux для изменения сценария.

    ```bash
    hdfs dfs -get wasbs:///path/to/script.py oldscript.py
    tr -d '\r' < oldscript.py > script.py
    hdfs dfs -put -f script.py wasbs:///path/to/script.py
    ```

## <a name="next-steps"></a>Дальнейшие действия

* [Узнайте, как создавать кластеры HDInsight под управлением Linux](hdinsight-hadoop-provision-linux-clusters.md)
* [Подключитесь к HDInsight с помощью протокола SSH](hdinsight-hadoop-linux-use-ssh-unix.md).
* [Выполняйте управление кластером под управлением Linux с помощью Ambari](hdinsight-hadoop-manage-ambari.md)

